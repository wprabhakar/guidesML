{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## Keras\n",
    "Keras Introduction: https://keras.io/\n",
    "\n",
    "Keras Cheatsheet: https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf\n",
    "\n",
    "Keras FAQ: https://keras.io/getting-started/faq/\n",
    "\n",
    "Keras Sequential API: https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about Tensorflow?\n",
    "\n",
    "Tensorflow is available as a \"backend\" for Keras. By default, Keras will use Tensorflow to perform deep learning operations.\n",
    "\n",
    "More about backends here: https://keras.io/backend/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Differences between Keras and Scikit-Learn\n",
    "\n",
    "|Sklearn|Keras|\n",
    "|--|--|\n",
    "|Use for Machine Learning and limited Deep Learning (MLPClassifier, MLPRegressor)|Use only for Deep Learning|\n",
    "|Scope: Linear Regression, Logistic Regression, Support Vector Machines, KMeans, PCA, etc|Scope: Deep Learning layers such as Dense, Convolutional, Recurrent|\n",
    "|Only SGDRegressor, SGDClassifier,  MLP* do gradient descent|Exclusively uses gradient descent and back propagation|\n",
    "|Not designed for long-haul training|Designed for long-haul training, supports saving and resuming training|\n",
    "|Limited support for incremental fit|Always fits incrementally, unless you recompile network|\n",
    "|Does not support GPU|Supports GPU|\n",
    "|Does not support Tensorflow|Supports Tensorflow through a backend|\n",
    "|Provides learning_curve() function for learning curve|Uses [Tensorboard](https://www.tensorflow.org/guide/summaries_and_tensorboard) for learning curve|\n",
    "|Provides cross_validate() function for cross validation|Cross-validation is not supported, use validation split that is built into fit()|\n",
    "|Supports fit with univariate y output only|Supports fit with univariate and multi-variate y output. For classification, y must be one-hot (more in the workshop)|\n",
    "\n",
    "There are other minor differences between how the two libraries work. We'll highlight it along the way.\n",
    "\n",
    "**Caution**: always consult documentation (don't assume Keras works like Scikit-learn, otherwise you waste time debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Machine Learning Workflow\n",
    "\n",
    "1. Problem Definition\n",
    "    - Same as you normally would for any machine learning problem. The key difference with Keras is in the choice of neural networks as the model.\n",
    "\n",
    "2. Data Engineering\n",
    "    - Use pandas as you normally would\n",
    "\n",
    "3. Feature Engineering\n",
    "    - Use sklearn as you normally would\n",
    "\n",
    "4. Model Engineering\n",
    "    \n",
    "    a. Define initial neural net\n",
    "        - Define model architecture, such as the input shapes, output shapes, and neural network layers\n",
    "        - model.compile to pick optimiser, loss function, metrics\n",
    "\n",
    "    b. Setup training callbacks:\n",
    "        - Learning curve using Tensorboard\n",
    "        - Early stopping\n",
    "        - [Optional] Model checkpoints to automatically save weights after every epoch\n",
    "    \n",
    "    c. Train model:\n",
    "        - model.fit(): Unlike sklearn, fit() is cumulative (continues progress if you it call repeatedly)\n",
    "\n",
    "        sklearn:\n",
    "        ```\n",
    "            model = SGDRegressor()\n",
    "            model.fit(X_train, y_train)\n",
    "            model.fit(X_train, y_train) # RESTARTS from scratch\n",
    "        ```\n",
    "\n",
    "         Keras:\n",
    "         ```\n",
    "             model.compile()\n",
    "             model.fit(X_train, y_train) \n",
    "             model.fit(X_train, y_train) # RESUMES training from previously\n",
    "         ```\n",
    "         \n",
    "5. Evaluation metrics\n",
    "    - Keras: model.evaluate() - similar to model.score() in sklearn\n",
    "    - Evaluation metrics in sklearn are more comprehensive. Use them here (e.g. classification_report)\n",
    "\n",
    "6. Deployment\n",
    "    - model.save()\n",
    "    - load_model()\n",
    "    - model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we'll walk through a simple Keras example to understand how to use it:\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "#tfe.enable_eager_execution()\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "from MyTotoResearchv4 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Keras includes some built-in datasets that are useful for learning and practice.\n",
    "\n",
    "https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'D', 'N1','N2','N3','N4','N5','N6','N7','L','M','S','R','E','A','V' ,'J','U']\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MyTotoResearch algo_no:  1\n",
      "1521\n"
     ]
    }
   ],
   "source": [
    "mtr = MyTotoResearch(algo_no=1)\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "X = mtr.modified_dataset(getAllData(df)) #\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "Z = scaler.transform(X)\n",
    "\n",
    "X_train = X\n",
    "Y = mtr.getTargets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1521, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uqapp/anaconda3/envs/mldss/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1521,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = mtr.get_result_n_encoded(1)\n",
    "y_train = mtr.getTarget(3)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1521.000000\n",
       "mean       17.443130\n",
       "std         6.783946\n",
       "min         3.000000\n",
       "25%        12.000000\n",
       "50%        17.000000\n",
       "75%        22.000000\n",
       "max        41.000000\n",
       "Name: N, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.astype(object)\n",
    "y_train.unique().shape\n",
    "scaler = MinMaxScaler()\n",
    "y_train.describe()\n",
    "#scaler.fit(y_train)\n",
    "#keras.utils.to_categorical(28, 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras requires the targets to be categorical (one-hot)\n",
    "# vectors rather than class (label) vectors\n",
    "# This means that we need to convert the target\n",
    "# before passing it to fit() if doing multi-class classification\n",
    "\n",
    "# convert class vectors to categorical vectors\n",
    "# 5 to [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]\n",
    "\n",
    "#num_classes = y_train.unique().shape[0]\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "This is an example dataset, so not much feature engineering is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model engineering\n",
    "\n",
    "To run tensorboard for viewing the Learning Curve\n",
    "\n",
    "- Launch another Anaconda Prompt (because tensorboard will run in its own console):\n",
    "\n",
    "```\n",
    "(base) conda activate mldds\n",
    "(mldds) cd folder\\to\\this\\notebook\n",
    "(mldds)tensorboard --logdir=logs --host=0.0.0.0\n",
    "```\n",
    "\n",
    "If this is the first time you are launching Tensorboard, you will not see any sessions until you call model.fit():\n",
    "\n",
    "```\n",
    "tensorboard = TensorBoard(log_dir='./logs/mnist_mlp/%d' % time.time())\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "                    callbacks=[tensorboard], validation_split=.25)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1521,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "#y_train.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 49)                539       \n",
      "=================================================================\n",
      "Total params: 619\n",
      "Trainable params: 619\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "\n",
    "# from tensorflow.python.eager.context import context, EAGER_MODE, GRAPH_MODE\n",
    "# def switch_to(mode):\n",
    "#     ctx = context()._eager_context\n",
    "#     ctx.mode = mode\n",
    "#     ctx.is_eager = mode == EAGER_MODE\n",
    "\n",
    "# switch_to(GRAPH_MODE)\n",
    "\n",
    "model = Sequential([\n",
    "  Dense(10, input_shape=(X.shape[1],)),  # must declare input shape\n",
    "  Dense(49)\n",
    "])\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# input: 784, output: 512 => 784 x 512 weights + 512 bias\n",
    "# (512 neurons)\n",
    "# model.add(Dense(16, activation='relu', input_shape=(X.shape[1],)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "# model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# input: 512, output: 512 => 512 x 512 weights + 512 bias\n",
    "# (512 neurons)\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# input: 512, output: 10 => 512 x 10 weights\n",
    "# (10 neurons)\n",
    "# softmax converts a set of outputs to probabilities that add up to 1\n",
    "# model.add(Dense(49, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "# Param # is W + bias\n",
    "# Dense: input_shape x output_shape + output_shape\n",
    "#  (where input_shape = previous layer's output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "#switch_to(EAGER_MODE)\n",
    "def multi_targets_scorer_function(y_true, y_pred):    \n",
    "    y_true = tf.map_fn(lambda x: x, mtr.getTargets())\n",
    "#    tf.map_fn(mtr.getTargets())\n",
    "    y_pred = tf.map_fn(lambda x: x, y_pred)\n",
    "\n",
    "    y_true_excluding_zeros = y_true ; #[np.array(v)[np.array(v)!=0] for v in tf.map_fn(lambda x: x, y_true)]\n",
    "\n",
    "    l = zip(tf.map_fn(lambda x: x, y_true_excluding_zeros), tf.map_fn(lambda x: x, y_pred))\n",
    "    matched_index = [t.__contains__(p) for (t,p) in tf.map_fn(lambda x,y:  l)]\n",
    "    print(sum(matched_index)/len(y_true_excluding_zeros), ' ', sum(sample_weight))\n",
    "    return sum(matched_index)/len(y_true_excluding_zeros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "map_fn() missing 1 required positional argument: 'elems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1de966abc286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#               loss='sparse_categorical_crossentropy',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmulti_targets_scorer_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#              metrics=['accuracy']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#              metrics=multi_targets_scorer_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mldss/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mldss/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-4f8adffd71fc>\u001b[0m in \u001b[0;36mmulti_targets_scorer_function\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_excluding_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmatched_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_excluding_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_excluding_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: map_fn() missing 1 required positional argument: 'elems'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2000\n",
    "\n",
    "#switch_to(EAGER_MODE)\n",
    "\n",
    "\n",
    "#tensorboard = TensorBoard(log_dir='./logs/mnist_mlp/%d' % time.time())\n",
    "model.compile(\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "              loss = (multi_targets_scorer_function),\n",
    "              optimizer=Adam(1e-3),\n",
    "#              metrics=['accuracy']\n",
    "#              metrics=multi_targets_scorer_function\n",
    "             ) # Tensorboard will display\n",
    "                                    # acc in addition to loss\n",
    "\n",
    "#switch_to(GRAPH_MODE)\n",
    "    # Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks, # Early stopping\n",
    "                    verbose=1)\n",
    "#                    callbacks=[tensorboard],\n",
    "#                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.get_config())\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for display, un-flatten to 28x28\n",
    "plt.imshow(X_test[7].reshape(28, 28))\n",
    "\n",
    "# argmax converts one-hot to the value (which is the maximum index)\n",
    "# [0 .... 0 1] => 9 (9 is the 9th index in the one-hot array)\n",
    "print(y_test[7].argmax())\n",
    "\n",
    "# need the flattened (784) shape for predict because the model\n",
    "# expects it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before feeding into Keras, we need to reshape\n",
    "# input into (batch_index, 784)\n",
    "\n",
    "# Typical error when forgetting to reshape:\n",
    "#\n",
    "# ValueError: Error when checking input: expected dense_7_input \n",
    "# to have shape (784,) but got array with shape (1,)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to (1, anything)\n",
    "pred = model.predict(X_test[7].reshape(1, -1)) # can also .reshape(1, 784)\n",
    "pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(X_test[7].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test) # return labels so that\n",
    "                                       # sklearn metrics work\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truth needs to be converted from one-hot to labels again\n",
    "# so that sklearn metrics work\n",
    "y_test.argmax(axis=1) # column-wise, axis=1 (10 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
