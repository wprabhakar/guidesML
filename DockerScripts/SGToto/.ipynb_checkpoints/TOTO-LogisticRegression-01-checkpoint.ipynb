{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:923: DeprecationWarning: builtin type EagerTensor has no __module__ attribute\n",
      "  EagerTensor = c_api.TFE_Py_InitEagerTensor(_EagerTensorBase)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4785: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/walter/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
      "  _config = json.load(open(_config_path))\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!conda install -n mldds -c anaconda joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Cores: \", num_cores)\n",
    "\n",
    "import time\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': num_cores} )\n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from MyTotoResearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_prediction(mrt, model, f):\n",
    "    def getAllData(df):\n",
    "        drop_cols = ['T', 'L','M','S','R','E','A','V' ,'J','U','K']\n",
    "        X = df.drop(drop_cols, axis=1)\n",
    "        return X\n",
    "\n",
    "    test_data = mtr.get_test_data()\n",
    "    X = mtr.modified_dataset(getAllData(test_data)) #\n",
    "#    X = getAdjustedDataF(test_data,f)\n",
    "\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X)\n",
    "    Z = scaler.transform(X)\n",
    "\n",
    "#    Z = X\n",
    "    predictions = model.predict(Z)\n",
    "    dfResult= pd.DataFrame(predictions, columns=['N1', 'N2', 'N3', 'N4', 'N5','N6', 'N7'])\n",
    "#    mtr.print_predictions(dfResult)\n",
    "\n",
    "    global df_predictions\n",
    "    global prev_r\n",
    "    r = mtr.getAccuracyCount(np.array(dfResult)) ;\n",
    "    if ( r > prev_r ):\n",
    "#        df_predictions = []\n",
    "        df_predictions.append(dfResult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MyTotoResearch algo_no:  1\n",
      "1521\n",
      "MultiOutputClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
      "          intercept_scaling=1, max_iter=5000, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l1', random_state=None, solver='saga',\n",
      "          tol=0.0001, verbose=0, warm_start=False),\n",
      "           n_jobs=7)\n",
      "1.0  Time taken:  1.3000000000928935e-05  \n",
      "Done.\n",
      "67.9245283018868\n",
      "20180514   [17 24 29 45 46 49  5]   [16.  6. 16. 26. 45. 27.]   [45]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [16.  6. 34. 26. 44. 27.]   []\n",
      "20180521   [ 8 10 16 30 37 44 17]   [16.  6. 28. 26. 39. 27.]   [16]\n",
      "20180524   [11 25 26 34 36 42 16]   [16.  6. 16. 26. 45. 27.]   [16 26]\n",
      "20180528   [ 5  9 27 28 30 44  2]   [16.  6. 18. 18. 22. 38.]   []\n",
      "20180531   [11 13 24 26 47 49 33]   [16.  6. 28. 26. 29. 43.]   [26]\n",
      "20180604   [20 22 31 37 43 45 27]   [ 5.  6. 28. 26. 39. 38.]   []\n",
      "20180607   [12 20 29 31 37 39 42]   [ 5.  6. 28. 26. 39. 41.]   [39]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 5.  6. 28. 38. 39. 38.]   []\n",
      "20180614   [ 4 29 31 35 42 48  1]   [16.  6. 18. 26. 33. 36.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [ 5.  6. 16. 29. 22. 36.]   [22]\n",
      "20180621   [ 4  6 15 24 30 35 46]   [12.  7. 21. 32. 41. 44.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [15. 18. 23. 28. 37. 42.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [12. 12. 23. 27. 37. 44.]   [27]\n",
      "20180702   [12 13 26 33 35 38 23]   [12. 12. 17. 32. 37. 44.]   [12]\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 8. 18. 23. 28. 37. 44.]   [ 8 28]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [12. 21. 27. 28. 40. 40.]   []\n",
      "20180712   [ 4 15 25 32 40 41 10]   [12.  8. 27. 37. 40. 40.]   [40]\n",
      "20180716   [ 4  8 19 24 32 47 22]   [10. 23. 27. 28. 39. 44.]   []\n",
      "20180719   [13 14 23 35 37 46 45]   [ 7. 26. 21. 38. 39. 44.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [12. 12. 33. 32. 31. 44.]   [12]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11. 26. 21. 32. 40. 45.]   [40]\n",
      "20180730   [ 8 10 19 20 41 43  7]   [ 7. 12. 19. 36. 31. 44.]   [ 7 19]\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 7. 10. 28. 38. 39. 43.]   [10]\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 7. 12. 23. 30. 41. 42.]   [7]\n",
      "20180809   [13 16 20 23 39 42 28]   [13. 12. 24. 27. 35. 42.]   [13 42]\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 4. 18. 20. 27. 35. 43.]   []\n",
      "20180816   [22 23 25 32 33 36 20]   [ 7.  9. 23. 38. 34. 42.]   [23]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [15.  8. 30. 37. 43. 43.]   []\n",
      "20180823   [ 2  3 23 30 39 41 19]   [ 4. 11. 13. 20. 33. 41.]   [41]\n",
      "20180827   [ 5  6 16 24 26 29 38]   [13. 17. 31. 27. 29. 45.]   [29]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 5. 16. 28. 37. 39. 42.]   []\n",
      "20180903   [ 4  5 13 18 39 40  3]   [15. 20. 30. 38. 36. 42.]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [13. 16. 29. 27. 38. 45.]   [45]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [20. 17. 25. 34. 35. 41.]   []\n",
      "20180913   [ 6 16 17 40 44 48 34]   [11. 18. 17. 34. 40. 45.]   [17 34 40]\n",
      "20180917   [16 21 22 24 25 27  1]   [11. 23. 19. 41. 31. 44.]   []\n",
      "20180920   [ 5 12 18 30 32 38 22]   [11. 26. 29. 25. 35. 40.]   []\n",
      "20180924   [ 6  8 17 24 29 47 34]   [17. 12. 33. 33. 36. 41.]   [17]\n",
      "20180927   [ 2 25 29 33 42 45 20]   [11. 18. 30. 26. 42. 47.]   [42]\n",
      "20181001   [11 15 23 24 32 40 43]   [11. 18. 17. 37. 31. 44.]   [11]\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 7. 16. 32. 22. 31. 40.]   [32]\n",
      "20181008   [17 18 23 39 43 49  2]   [ 9. 11. 15. 31. 33. 42.]   []\n",
      "20181011   [ 1 16 18 24 29 46 35]   [ 9. 13. 17. 24. 33. 44.]   [24]\n",
      "20181015   [ 1  4 24 32 35 48 20]   [10. 13. 26. 34. 35. 44.]   [35]\n",
      "20181018   [ 5 14 17 31 46 48 47]   [17. 20. 30. 27. 36. 45.]   [17]\n",
      "20181022   [ 5 22 24 40 43 48  2]   [17. 10. 30. 34. 38. 42.]   []\n",
      "20181025   [ 7  8 13 15 35 48 30]   [11. 10. 12. 37. 26. 44.]   []\n",
      "20181029   [ 2  6 10 20 28 31 30]   [ 8. 20. 30. 17. 35. 41.]   [20 30]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [ 8. 15. 27. 27. 34. 41.]   [15 27 41]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 8. 20. 29. 32. 41. 45.]   [8]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [13. 20. 31. 28. 35. 41.]   [13 28]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 8. 20. 30. 29. 36. 33.]   [33]\n",
      "20181115  Predicted:  [ 8. 20. 30. 29. 40. 33.]  \n",
      "20181119  Predicted:  [23. 26. 27. 35. 45. 31.]  \n",
      "20181122  Predicted:  [ 9. 24. 35. 42. 40. 39.]  \n",
      "20181126  Predicted:  [ 6. 12. 13. 21. 22. 36.]  \n",
      "20181129  Predicted:  [15.  8. 36. 18. 22. 41.]  \n",
      "20181203  Predicted:  [16. 24. 23. 36. 34. 36.]  \n",
      "20181206  Predicted:  [ 6. 24. 26. 36. 34. 40.]  \n",
      "20181210  Predicted:  [ 6. 18. 26. 39. 35. 40.]  \n",
      "20181213  Predicted:  [16. 24. 30. 25. 44. 33.]  \n",
      "20181217  Predicted:  [19. 24. 26. 25. 30. 34.]  \n",
      "20181220  Predicted:  [15. 18. 28. 35. 37. 44.]  \n",
      "20181224  Predicted:  [ 2. 24. 35. 35. 46. 34.]  \n",
      "20181227  Predicted:  [22. 23. 31. 20. 28. 38.]  \n",
      "20181231  Predicted:  [16.  9. 38. 19. 30. 46.]  \n"
     ]
    }
   ],
   "source": [
    "from keras.models import Input, Model\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "import json as simplejson\n",
    "from keras import regularizers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier, LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, Ridge, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}\n",
    "\n",
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'D', 'N1','N2','N3','N4','N5','N6','N7','L','M','S','R','E','A','V' ,'J','U','K']\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "    return X\n",
    "\n",
    "df_predictions = []\n",
    "\n",
    "prev_r = 0\n",
    "\n",
    "mtr = MyTotoResearch(algo_no=1)\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "#Deep Neuro Network\n",
    "for n in range(1,2):\n",
    "    X = mtr.modified_dataset(getAllData(df)) #\n",
    "    f = 1.0 #365/27.58\n",
    "#    X = getAdjustedDataF(df,f)\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(X)\n",
    "    Z = scaler.transform(X)\n",
    "\n",
    "#    Z = X\n",
    "\n",
    "#    classifier = MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "    clf = LogisticRegression(multi_class='multinomial', penalty='l1', fit_intercept=False, max_iter=5000, solver='saga') #, class_weight='balanced')\n",
    "#    clf = RidgeClassifier(random_state=42, solver='cholesky', normalize=False, class_weight='balanced')\n",
    "#    clf =  SVC(kernel='poly', coef0=0.06, probability=True, degree=2, random_state=42, tol=1e-05, shrinking=False)\n",
    "\n",
    "\n",
    "\n",
    "#     param_grid = {\n",
    "#                 'C': [1, 2] \n",
    "#                   ,'tol': [1e-6, 1e-05]\n",
    "#                   , 'max_iter': [15000]\n",
    "# #                  , 'random_state': [ 10, 20, 30, 40 ]\n",
    "#                   , 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "#                  }\n",
    "#     classifier = GridSearchCV(classifier, param_grid, cv=3)\n",
    "# GridSearchCV(cv=None,\n",
    "#        estimator=LogisticRegression(C=1.0, intercept_scaling=1, dual=False, fit_intercept=True,\n",
    "#           penalty='l2', tol=0.0001),\n",
    "#        fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
    "#        param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "#        pre_dispatch='2*n_jobs', refit=True, score_func=None, verbose=0)\n",
    "\n",
    "    model = MultiOutputClassifier(clf, n_jobs=7)\n",
    "    model.fit(Z, mtr.getTargets()) \n",
    "    print(model)\n",
    "    s = model.score(Z, mtr.getTargets())\n",
    "    if(model.score(Z, mtr.getTargets()) == 1.0):\n",
    "        print( str(f), ' ', str(s))\n",
    "    store_prediction(mtr, model, f)\n",
    "    start = time.clock()\n",
    "    print(str(f), \" Time taken: \", (time.clock() - start),  \" \")\n",
    "\n",
    "print(\"Done.\")\n",
    "# mtr = MyTotoResearch(algo_no=1)\n",
    "# lresult, df = mtr.load_totodata()\n",
    "\n",
    "# test_data = mtr.get_test_data()\n",
    "\n",
    "for n in range(len(df_predictions)):\n",
    "    print( mtr.getAccuracyCount(np.array(df_predictions[n])))\n",
    "    mtr.print_predictions(df_predictions[n])\n",
    "\n",
    "\n",
    "#69.81 => MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='relu', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#75.47 =>  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#64.15 =>  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='adam', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#62  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='lbfgs', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#71.69 => MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='logistic', learning_rate='adaptive', solver='lbfgs', verbose=0,  random_state=42,tol=0.000000001)\n",
    "\n",
    "#75.47 => SVC(kernel='poly', coef0=0.05, probability=True, degree=2, random_state=42, tol=1e-03)\n",
    "\n",
    "\n",
    "\n",
    "#69.81 => SVC(random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(classifier.estimator)\n",
    "# Nov 26\n",
    "# 16 22 28 31 38 46 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "20180514   [17 24 29 45 46 49  5]   [ 8. 22. 16. 19. 39. 43.]   []\n",
    "20180517   [ 7 21 25 29 35 37 13]   [16.  6. 34. 40. 35. 43.]   [35]\n",
    "20180521   [ 8 10 16 30 37 44 17]   [ 5.  9. 16. 26. 24. 43.]   [16]\n",
    "20180524   [11 25 26 34 36 42 16]   [ 5.  9. 16. 26. 45. 36.]   [16 26 36]\n",
    "20180528   [ 5  9 27 28 30 44  2]   [ 5.  9. 16. 38. 39. 43.]   [5 9]\n",
    "20180531   [11 13 24 26 47 49 33]   [20.  9. 23. 26. 34. 43.]   [26]\n",
    "20180604   [20 22 31 37 43 45 27]   [ 5.  9. 16. 26. 22. 43.]   [22 43]\n",
    "20180607   [12 20 29 31 37 39 42]   [ 8.  9. 16. 27. 22. 41.]   []\n",
    "20180611   [16 25 30 37 44 49 34]   [ 5. 20. 25. 38. 44. 42.]   [25 44]\n",
    "20180614   [ 4 29 31 35 42 48  1]   [18.  6. 18. 26. 32. 36.]   []\n",
    "20180618   [11 15 22 23 26 43 25]   [18.  6. 16. 26. 22. 36.]   [22 26]\n",
    "201806\n",
    "\n",
    "75.47169811320755\n",
    "20180514   [17 24 29 45 46 49  5]   [ 2. 35. 30. 17. 25. 27.]   [17]\n",
    "20180517   [ 7 21 25 29 35 37 13]   [ 5. 33. 36. 16. 25. 31.]   [25]\n",
    "20180521   [ 8 10 16 30 37 44 17]   [ 5. 27. 30. 18. 33. 38.]   [30]\n",
    "20180524   [11 25 26 34 36 42 16]   [ 5. 26. 30. 18. 29. 45.]   [26]\n",
    "20180528   [ 5  9 27 28 30 44  2]   [ 5.  7. 12. 18. 22. 38.]   [5]\n",
    "20180531   [11 13 24 26 47 49 33]   [ 5. 35. 12. 38. 33. 41.]   [33]\n",
    "20180604   [20 22 31 37 43 45 27]   [ 5.  7. 12. 18. 24. 38.]   []\n",
    "20180607   [12 20 29 31 37 39 42]   [ 5. 35. 12. 38. 22. 40.]   [12]\n",
    "20180611   [16 25 30 37 44 49 34]   [22. 27. 28. 38. 33. 38.]   []\n",
    "20180614   [ 4 29 31 35 42 48  1]   [ 5. 36. 30. 23. 24. 31.]   [31]\n",
    "20180618   [11 15 22 23 26 43 25]   [13. 36. 30. 17. 22. 36.]   [22]\n",
    "20180621   [ 4  6 15 24 30 35 46]   [10. 20. 23. 28. 32. 42.]   []\n",
    "20180625   [ 2  5 25 38 44 48  9]   [15. 18. 20. 27. 41. 40.]   []\n",
    "20180628   [ 2  7 22 27 40 47 48]   [12. 15. 27. 35. 41. 43.]   [27]\n",
    "20180702   [12 13 26 33 35 38 23]   [ 8.  7. 19. 35. 41. 43.]   [35]\n",
    "20180705   [ 8 11 28 30 32 34 39]   [ 9. 18. 17. 28. 37. 42.]   [28]\n",
    "20180709   [ 6 23 31 38 39 43 33]   [12. 23. 26. 28. 36. 40.]   [23]\n",
    "20180712   [ 4 15 25 32 40 41 10]   [ 5. 23. 35. 29. 32. 45.]   [32]\n",
    "20180716   [ 4  8 19 24 32 47 22]   [ 8. 19. 27. 24. 31. 38.]   [ 8 19 24]\n",
    "20180719   [13 14 23 35 37 46 45]   [10. 17. 27. 32. 40. 41.]   []\n",
    "20180723   [ 2 23 26 28 39 40 12]   [23. 23. 33. 28. 31. 43.]   [23 28]\n",
    "20180726   [ 1  9 13 17 28 40 37]   [11. 28. 30. 32. 34. 39.]   [28]\n",
    "20180730   [ 8 10 19 20 41 43  7]   [ 8. 23. 26. 24. 35. 38.]   [8]\n",
    "20180802   [ 1 10 15 27 41 46 35]   [ 3.  9. 25. 29. 40. 48.]   []\n",
    "20180806   [ 7 18 20 27 36 40 15]   [ 6. 15. 24. 30. 35. 45.]   [15]\n",
    "20180809   [13 16 20 23 39 42 28]   [11. 22. 23. 27. 35. 43.]   [23]\n",
    "20180813   [ 1  3  6 16 22 36 17]   [ 4. 18. 31. 35. 42. 44.]   []\n",
    "20180816   [22 23 25 32 33 36 20]   [ 7. 18. 34. 31. 34. 44.]   []\n",
    "20180820   [ 9 10 25 38 40 42  2]   [ 9. 18. 26. 27. 39. 44.]   [9]\n",
    "20180823   [ 2  3 23 30 39 41 19]   [ 8. 18. 23. 37. 43. 44.]   [23]\n",
    "20180827   [ 5  6 16 24 26 29 38]   [ 8. 17. 23. 27. 41. 44.]   []\n",
    "20180830   [ 3  9 27 29 31 40 46]   [ 8. 18. 27. 32. 41. 44.]   [27]\n",
    "20180903   [ 4  5 13 18 39 40  3]   [10. 18. 22. 27. 36. 42.]   [18]\n",
    "20180906   [ 2 15 17 20 23 30 45]   [ 7. 18. 23. 27. 41. 44.]   [23]\n",
    "20180910   [ 2  6  9 15 40 43 18]   [ 7. 18. 19. 27. 41. 44.]   [18]\n",
    "20180913   [ 6 16 17 40 44 48 34]   [11. 18. 17. 27. 41. 44.]   [17 44]\n",
    "20180917   [16 21 22 24 25 27  1]   [ 7. 18. 17. 27. 41. 44.]   [27]\n",
    "20180920   [ 5 12 18 30 32 38 22]   [11. 18. 22. 27. 41. 44.]   [18 22]\n",
    "20180924   [ 6  8 17 24 29 47 34]   [ 7. 18. 19. 31. 38. 45.]   []\n",
    "20180927   [ 2 25 29 33 42 45 20]   [11. 18. 23. 31. 41. 44.]   []\n",
    "20181001   [11 15 23 24 32 40 43]   [11. 18. 17. 31. 41. 44.]   [11]\n",
    "20181004   [ 5 12 23 32 37 42 43]   [ 7. 18. 22. 27. 41. 44.]   []\n",
    "20181008   [17 18 23 39 43 49  2]   [ 4. 11. 22. 30. 30. 45.]   []\n",
    "20181011   [ 1 16 18 24 29 46 35]   [ 9. 18. 23. 32. 41. 43.]   [18]\n",
    "20181015   [ 1  4 24 32 35 48 20]   [ 7. 18. 17. 31. 35. 45.]   [35]\n",
    "20181018   [ 5 14 17 31 46 48 47]   [ 5. 13. 17. 31. 40. 45.]   [ 5 17 31]\n",
    "20181022   [ 5 22 24 40 43 48  2]   [ 5. 15. 25. 31. 38. 42.]   [5]\n",
    "20181025   [ 7  8 13 15 35 48 30]   [14. 17. 22. 34. 38. 42.]   []\n",
    "20181029   [ 2  6 10 20 28 31 30]   [ 6. 15. 19. 31. 40. 44.]   [ 6 31]\n",
    "20181101   [ 6 27 28 41 44 48 15]   [ 6. 15. 23. 27. 41. 44.]   [ 6 15 27 41 44]\n",
    "20181101   [ 6 27 28 41 44 48 15]   [ 8. 15. 29. 27. 34. 41.]   [15 27 41]\n",
    "\n",
    "20181105   [ 3  8 14 28 43 49 26]   [11. 18. 23. 31. 41. 44.]   []\n",
    "20181108   [ 8 13 16 26 28 38 46]   [ 7. 17. 23. 31. 38. 45.]   [38]\n",
    "20181112   [ 4 12 21 34 41 47 33]   [ 8. 12. 22. 31. 41. 44.]   [12 41]\n",
    "20181115  Predicted:  [10. 18. 22. 27. 40. 44.]  \n",
    "20181119  Predicted:  [ 9. 18. 19. 27. 35. 45.]  \n",
    "20181122  Predicted:  [ 9. 18. 22. 27. 35. 41.]  \n",
    "20181126  Predicted:  [ 6. 18. 23. 27. 38. 44.]  \n",
    "20181129  Predicted:  [ 7. 18. 23. 30. 35. 44.]  \n",
    "20181203  Predicted:  [ 7. 18. 17. 31. 41. 45.]  \n",
    "20181206  Predicted:  [ 7. 18. 17. 27. 35. 44.]  \n",
    "20181210  Predicted:  [ 6. 18. 17. 31. 41. 45.]  \n",
    "20181213  Predicted:  [ 7. 18. 17. 31. 41. 44.]  \n",
    "20181217  Predicted:  [ 7. 18. 19. 27. 35. 44.]  \n",
    "20181220  Predicted:  [ 7. 18. 23. 31. 41. 44.]  \n",
    "20181224  Predicted:  [ 7. 18. 22. 27. 41. 44.]  \n",
    "20181227  Predicted:  [ 8. 18. 23. 27. 41. 44.]  \n",
    "20181231  Predicted:  [ 9. 18. 23. 27. 41. 44.]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521\n",
      "1\n",
      "62.264150943396224\n",
      "20180514   [17 24 29 45 46 49  5]   [16. 21. 22. 24. 25. 27.]   [24]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [16. 17. 34. 40. 44. 48.]   []\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 6.  9. 15. 18. 40. 43.]   []\n",
      "20180524   [11 25 26 34 36 42 16]   [15. 17. 20. 23. 30. 45.]   []\n",
      "20180528   [ 5  9 27 28 30 44  2]   [ 4.  5. 13. 18. 39. 40.]   [5]\n",
      "20180531   [11 13 24 26 47 49 33]   [ 9. 27. 29. 31. 40. 46.]   []\n",
      "20180604   [20 22 31 37 43 45 27]   [ 6. 16. 24. 26. 29. 38.]   []\n",
      "20180607   [12 20 29 31 37 39 42]   [ 3. 19. 23. 30. 39. 41.]   [39]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 9. 10. 25. 38. 40. 42.]   [25]\n",
      "20180614   [ 4 29 31 35 42 48  1]   [22. 23. 25. 32. 33. 36.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [ 3.  6. 16. 17. 22. 36.]   [22]\n",
      "20180621   [ 4  6 15 24 30 35 46]   [16. 20. 23. 28. 39. 42.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [15. 18. 20. 27. 36. 40.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [10. 15. 27. 35. 41. 46.]   [27]\n",
      "20180702   [12 13 26 33 35 38 23]   [ 8. 10. 19. 20. 41. 43.]   []\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 9. 13. 17. 28. 37. 40.]   [28]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [12. 23. 26. 28. 39. 40.]   [23 39]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [14. 23. 35. 37. 45. 46.]   []\n",
      "20180716   [ 4  8 19 24 32 47 22]   [ 8. 19. 22. 24. 32. 47.]   [ 8 19 22 24 32 47]\n",
      "20180719   [13 14 23 35 37 46 45]   [10. 15. 25. 32. 40. 41.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [23. 31. 33. 38. 39. 43.]   [23 39]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11. 28. 30. 32. 34. 39.]   [28]\n",
      "20180730   [ 8 10 19 20 41 43  7]   [13. 23. 26. 33. 35. 38.]   []\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 3.  9. 25. 38. 44. 48.]   []\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 6. 15. 24. 30. 35. 46.]   [15]\n",
      "20180809   [13 16 20 23 39 42 28]   [15. 22. 23. 25. 26. 43.]   [23]\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 4. 29. 31. 35. 42. 48.]   []\n",
      "20180816   [22 23 25 32 33 36 20]   [25. 30. 34. 37. 44. 49.]   [25]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [20. 29. 31. 37. 39. 42.]   [42]\n",
      "20180823   [ 2  3 23 30 39 41 19]   [22. 27. 31. 37. 43. 45.]   []\n",
      "20180827   [ 5  6 16 24 26 29 38]   [13. 24. 26. 33. 47. 49.]   [24 26]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 5.  9. 27. 28. 30. 44.]   [ 9 27]\n",
      "20180903   [ 4  5 13 18 39 40  3]   [16. 25. 26. 34. 36. 42.]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [10. 16. 17. 30. 37. 44.]   [17 30]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [13. 21. 25. 29. 35. 37.]   []\n",
      "20180913   [ 6 16 17 40 44 48 34]   [17. 24. 29. 45. 46. 49.]   [17]\n",
      "20180917   [16 21 22 24 25 27  1]   [17.  5. 25. 29. 23. 44.]   [25]\n",
      "20180920   [ 5 12 18 30 32 38 22]   [ 9. 10. 25. 28. 36. 37.]   []\n",
      "20180924   [ 6  8 17 24 29 47 34]   [20. 15. 24. 29. 46. 39.]   [24 29]\n",
      "20180927   [ 2 25 29 33 42 45 20]   [11. 17. 30. 45. 46. 47.]   [45]\n",
      "20181001   [11 15 23 24 32 40 43]   [14.  5. 25. 45. 46. 44.]   []\n",
      "20181004   [ 5 12 23 32 37 42 43]   [13. 21. 25. 28. 31. 44.]   []\n",
      "20181008   [17 18 23 39 43 49  2]   [ 9. 18. 32. 34. 41. 45.]   [18]\n",
      "20181011   [ 1 16 18 24 29 46 35]   [13. 18. 17. 22. 22. 44.]   [18]\n",
      "20181015   [ 1  4 24 32 35 48 20]   [19. 10. 12. 16. 41. 37.]   []\n",
      "20181018   [ 5 14 17 31 46 48 47]   [ 5. 14. 11. 40. 41. 44.]   [ 5 14]\n",
      "20181022   [ 5 22 24 40 43 48  2]   [17.  7. 20. 28. 41. 43.]   [43]\n",
      "20181025   [ 7  8 13 15 35 48 30]   [10.  7. 37. 34. 41. 41.]   [7]\n",
      "20181029   [ 2  6 10 20 28 31 30]   [10. 14. 16. 30. 40. 39.]   [10 30]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [10. 15. 27. 30. 34. 42.]   [15 27]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 8.  7. 18. 21. 27. 44.]   [8]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [ 8. 19. 25. 28. 31. 42.]   [ 8 28]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 8. 12. 18. 29. 22. 42.]   [12]\n",
      "20181115  Predicted:  [10.  7. 18. 38. 40. 41.]  \n",
      "20181119  Predicted:  [ 8. 15. 27. 35. 34. 44.]  \n",
      "20181122  Predicted:  [ 9. 14. 18. 26. 40. 48.]  \n",
      "20181126  Predicted:  [10. 17. 14. 21. 28. 42.]  \n",
      "20181129  Predicted:  [ 7. 14. 38. 30. 34. 36.]  \n",
      "20181203  Predicted:  [ 8. 19. 11. 21. 42. 45.]  \n",
      "20181206  Predicted:  [ 2. 14. 20. 23. 45. 46.]  \n",
      "20181210  Predicted:  [ 9. 21. 30. 31. 27. 42.]  \n",
      "20181213  Predicted:  [ 9. 10. 30. 31. 44. 44.]  \n",
      "20181217  Predicted:  [ 9. 28. 32. 35. 42. 44.]  \n",
      "20181220  Predicted:  [ 9. 16. 36. 37. 46. 47.]  \n",
      "20181224  Predicted:  [ 4. 15. 27. 23. 46. 34.]  \n",
      "20181227  Predicted:  [ 9. 19. 31. 22. 41. 49.]  \n",
      "20181231  Predicted:  [ 9. 18. 38. 23. 46. 47.]  \n"
     ]
    }
   ],
   "source": [
    "#Keep track of all results\n",
    "#df_predictions = []\n",
    "\n",
    "#print(df_predictions)\n",
    "#mtr = MyTotoResearch(algo_no=1)\n",
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'L','M','S','R','E','A','V' ,'J','U','K']\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "    return X\n",
    "\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "test_data = mtr.get_test_data()\n",
    "X = mtr.modified_dataset(getAllData(test_data)) #\n",
    "\n",
    "print(len(df_predictions))\n",
    "for n in range(len(df_predictions)):\n",
    "    print( mtr.getAccuracyCount(np.array(df_predictions[n])))\n",
    "    mtr.print_predictions(df_predictions[n])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dOld = dfResult\n",
    "#2 9 14 36 46 48 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
