{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/TotoResearch/MyTotoResearch.py:140: DeprecationWarning: invalid escape sequence \\s\n",
      "  test_df = pd.read_csv('../input/TestResult.csv', sep='\\s+', header=None, names=['D','N1','N2','N3','N4','N5','N6','N7'])\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!conda install -n mldds -c anaconda joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Cores: \", num_cores)\n",
    "\n",
    "import time\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': num_cores} )\n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from MyTotoResearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'D', 'N1','N2','N3','N4','N5','N6','N7','L','M','S','R','E','A','V' ,'J','U','K']\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_prediction(mrt, model, f, scaler=None, name='unnamed'):\n",
    "    def getAllData(df):\n",
    "        drop_cols = ['T', 'L','M','S','R','E','A','V' ,'J','U','K']\n",
    "        X = df.drop(drop_cols, axis=1)\n",
    "        return X\n",
    "\n",
    "    test_data = mtr.get_test_data()\n",
    "    X = mtr.modified_dataset(getAllData(test_data)) #\n",
    "#    X = getAdjustedDataF(test_data,f)\n",
    "\n",
    "\n",
    "    if ( scaler == None ):\n",
    "        Z = X\n",
    "    else:\n",
    "        scaler.fit(X)\n",
    "        Z = scaler.transform(X)\n",
    "\n",
    "    predictions = model.predict(Z)\n",
    "\n",
    "    dfResult= pd.DataFrame(predictions, columns=['N1', 'N2', 'N3', 'N4', 'N5','N6', 'N7'])\n",
    "#    mtr.print_predictions(dfResult)\n",
    "\n",
    "    global df_predictions\n",
    "    global prev_r\n",
    "    r = mtr.getAccuracyCount(np.array(dfResult)) ;\n",
    "#    if ( r > prev_r ):\n",
    "#        df_predictions = []\n",
    "    df_predictions.append(dfResult)\n",
    "    g_all_pred.update({name : dfResult})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MyTotoResearch algo_no:  1\n",
      "1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from keras.models import Input, Model\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "import json as simplejson\n",
    "from keras import regularizers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier, LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, Ridge, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "seed = 42\n",
    "\n",
    "mtr = MyTotoResearch(algo_no=1)\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "df_predictions = []\n",
    "\n",
    "\n",
    "all_models = []\n",
    "\n",
    "# all_models.append(('SVCpoly01', SVC(kernel='poly', coef0=0.05, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf010', SVC(kernel='rbf', coef0=0.75, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf011', SVC(kernel='rbf', coef0=0.5, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf012', SVC(kernel='rbf', coef0=0.25, probability=True, degree=2, random_state=seed)))\n",
    "\n",
    "# all_models.append(('SVCrbf0103', SVC(kernel='rbf', coef0=0.75, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0113', SVC(kernel='rbf', coef0=0.5, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0123', SVC(kernel='rbf', coef0=0.25, probability=True, degree=3, random_state=seed)))\n",
    "\n",
    "\n",
    "# all_models.append(('SVCrbf020', SVC(kernel='sigmoid', coef0=0.75, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf021', SVC(kernel='sigmoid', coef0=0.5, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf022', SVC(kernel='sigmoid', coef0=0.25, probability=True, degree=2, random_state=seed)))\n",
    "\n",
    "# all_models.append(('SVCrbf0203', SVC(kernel='sigmoid', coef0=0.75, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0213', SVC(kernel='sigmoid', coef0=0.5, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0223', SVC(kernel='sigmoid', coef0=0.25, probability=True, degree=3, random_state=seed)))\n",
    "\n",
    "\n",
    "# all_models.append(('SVCrbf030', SVC(kernel='linear', coef0=0.75, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf031', SVC(kernel='linear', coef0=0.5, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf032', SVC(kernel='linear', coef0=0.25, probability=True, degree=2, random_state=seed)))\n",
    "\n",
    "# all_models.append(('SVCrbf0303', SVC(kernel='linear', coef0=0.75, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0313', SVC(kernel='linear', coef0=0.5, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0323', SVC(kernel='linear', coef0=0.25, probability=True, degree=3, random_state=seed)))\n",
    "\n",
    "\n",
    "\n",
    "# all_models.append(('LR', (LogisticRegression(random_state=seed))))\n",
    "\n",
    "all_models.append(('KNNC', KNeighborsClassifier()))\n",
    "all_models.append(('KNNR', KNeighborsRegressor()))\n",
    "# all_models.append(('RC', RidgeClassifier(random_state=seed)))\n",
    "# all_models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "# all_models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# all_models.append(('DTR', DecisionTreeRegressor()))\n",
    "# all_models.append(('ETR', ExtraTreesRegressor(n_estimators=5)))\n",
    "# all_models.append(('ETC', ExtraTreesClassifier(n_estimators=5)))\n",
    "# all_models.append(('EN', ElasticNet()))\n",
    "# all_models.append(('CART', DecisionTreeClassifier()))\n",
    "# all_models.append(('NB', GaussianNB()))\n",
    "# all_models.append(('Lasso', Lasso()))\n",
    "# all_models.append(('GBR', GradientBoostingRegressor()))\n",
    "# all_models.append(('RFR5', RandomForestClassifier(n_estimators=5, n_jobs=5, random_state=seed)))\n",
    "# all_models.append(('RFR5', RandomForestClassifier(n_estimators=5, n_jobs=5, random_state=seed)))\n",
    "# all_models.append(('RFR3', RandomForestRegressor(n_estimators=3, n_jobs=5, random_state=seed)))\n",
    "# all_models.append(('SGDR', SGDRegressor(random_state=seed)))\n",
    "# all_models.append(('AdaB', AdaBoostClassifier(RandomForestClassifier(n_estimators=3))))\n",
    "# #all_models.append(('MLPC', MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "           n_jobs=7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  Time taken:  1.0000000000065512e-05  \n",
      "MultiOutputClassifier(estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "          weights='uniform'),\n",
      "           n_jobs=7)\n",
      "1.0  Time taken:  7.999999999785956e-06  \n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "from sklearn import model_selection\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "g_all_pred = {}\n",
    "\n",
    "for name, model in all_models:\n",
    "    \n",
    "    X = mtr.modified_dataset(getAllData(df)) #\n",
    "    f = 1.0 #365/27.58\n",
    "#    X = getAdjustedDataF(df,f)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    Z = scaler.transform(X)\n",
    "    \n",
    "#    scaler = None\n",
    "#    Z = X\n",
    "\n",
    "#     kfold = model_selection.KFold(n_splits=3, random_state=seed)\n",
    "#     cv_results = model_selection.cross_val_score(model, Z, mtr.getTarget(3), cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)\n",
    "    \n",
    "    oClassifier = MultiOutputClassifier(model, n_jobs=7)\n",
    "    oClassifier.fit(Z, mtr.getTargets()) \n",
    "    print(oClassifier)\n",
    "    s = oClassifier.score(Z, mtr.getTargets())\n",
    "    if(oClassifier.score(Z, mtr.getTargets()) == 1.0):\n",
    "        print( name, ' ', str(f), ' ', str(s))\n",
    "    store_prediction(mtr, oClassifier, f, scaler=scaler, name=name)\n",
    "    start = time.clock()\n",
    "    print(str(f), \" Time taken: \", (time.clock() - start),  \" \")\n",
    "\n",
    "# for n in range(len(df_predictions)):\n",
    "#     print( mtr.getAccuracyCount(np.array(df_predictions[n])))\n",
    "#     mtr.print_predictions(df_predictions[n])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "# fig = plt.figure()\n",
    "# fig.suptitle('Algorithm Comparison')\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.boxplot(results)\n",
    "# ax.set_xticklabels(names)\n",
    "# plt.show()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import operator\n",
    "from itertools import islice\n",
    "\n",
    "top_n = 12\n",
    "\n",
    "all_pred = [] ;\n",
    "for i in range(len(df_predictions)):\n",
    "    if ( i == 0 ):\n",
    "        all_pred = df_predictions[i]\n",
    "    else:\n",
    "        all_pred = np.column_stack((all_pred, df_predictions[i]) )\n",
    "\n",
    "top_seven = []\n",
    "for i in range(len(all_pred)):\n",
    "    unique, counts = np.unique(all_pred[i], return_counts=True)\n",
    "    x = dict(zip(unique, counts))\n",
    "    sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True) # sorted by value\n",
    "    top_seven.append(list(islice([int(x) for x,y in sorted_x],top_n)))\n",
    "\n",
    "#print(top_seven)\n",
    "columns = ['N'+str(i+1) for i in range(top_n)]\n",
    "df_top_seven = pd.DataFrame(top_seven, columns=columns)\n",
    "r = mtr.getAccuracyCount(np.array(df_top_seven)) ;\n",
    "print ( \"Accuracy: \",  r)\n",
    "#print(df_top_seven)\n",
    "# matched = []\n",
    "# for (p,a) in zip(df_top_seven.values, mtr.get_test_result()):\n",
    "#     matched.append(len(set(p.astype(int)) & set(a)))\n",
    "# bins = np.arange(8) - 0.5\n",
    "# plt.hist(matched, bins, rwidth=0.8)\n",
    "# plt.xticks(range(8))\n",
    "# plt.xlim([-1, 8])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "mtr.plot_matched_counts(df_top_seven.values)\n",
    "\n",
    "\n",
    "#mtr.print_predictions(df_top_seven)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prediction(arr, initial_pred=[]):\n",
    "    global s\n",
    "    if ( isinstance(arr, list) ):\n",
    "        for a in arr:\n",
    "            combine_prediction(a, initial_pred)\n",
    "        return \n",
    "    if ( len(s) > 1 ):\n",
    "        s += '_'\n",
    "    s += arr\n",
    "    initial_pred.append(g_all_pred[arr])\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from itertools import combinations\n",
    "import operator \n",
    "from itertools import islice\n",
    "\n",
    "name_ = []\n",
    "\n",
    "lst = [name for name, model in all_models]\n",
    "iBestIndex = -1\n",
    "iBestN = []\n",
    "#print(\"List \", lst)\n",
    "top_n = 12\n",
    "\n",
    "\n",
    "dict_accuracy = {}\n",
    "for z in range(4, 0,-1):\n",
    "    a = [list(x) for x in itertools.combinations(lst, z) if len(x) > 1 ] \n",
    "#    print(a)\n",
    "\n",
    "    for xx in a:\n",
    "        test_pred = []\n",
    "        s = ''\n",
    "        combine_prediction(xx, test_pred)\n",
    "#        print(s)\n",
    "\n",
    "        #print(len(test_pred))\n",
    "\n",
    "        all_pred = [] ;\n",
    "        for i in range(len(test_pred)):\n",
    "            if ( i == 0 ):\n",
    "                all_pred = test_pred[i]\n",
    "            else:\n",
    "                all_pred = np.column_stack((all_pred, test_pred[i]) )\n",
    "\n",
    "        top_seven = []\n",
    "        for i in range(len(all_pred)):\n",
    "            unique, counts = np.unique(all_pred[i], return_counts=True)\n",
    "            x = dict(zip(unique, counts))\n",
    "            sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True) # sorted by value\n",
    "            l = list(islice([int(x) for x,y in sorted_x],top_n))\n",
    "            while ( len(l) < top_n ):\n",
    "                l.append(-1)\n",
    "\n",
    "            top_seven.append(l)\n",
    "            \n",
    "\n",
    "#        print(len(top_seven))\n",
    "#         if(len(top_seven[0]) < top_n ):\n",
    "#             print(\"*** Caught \", )\n",
    "        columns = ['N'+str(i+1) for i in range(len(top_seven[0]))]\n",
    "#        print(columns)\n",
    "        df_top_seven = pd.DataFrame(top_seven, columns=columns)\n",
    "        r = mtr.getAccuracyCount(np.array(df_top_seven)) ;\n",
    "        matched, weighted_match = mtr.print_weighted_numbers(df_top_seven.values)\n",
    "        r = sum(weighted_match)\n",
    "\n",
    "#TODO Provide weights for predictions         \n",
    "#        weights = [(1+1*(w/10)) for N in df_top_seven]\n",
    "#        print ( \"Accuracy: \",  r)\n",
    "        dict_accuracy.update({s: r})\n",
    "\n",
    "t_accuracy = sorted(dict_accuracy.items(),key=operator.itemgetter(1), reverse=True)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1, 0, 1, 3, 3, 3, 1, 1, 2, 1, 0, 1, 2, 3, 1, 1, 2, 2, 0, 1, 4, 1, 1, 2, 2, 2, 2, 0, 1, 0, 1, 2, 1, 5, 3, 2, 0, 2, 2, 2, 2, 1, 2]\n",
      "[1.2, 1.2, 1.2, 1.4, 1.4, 1.0, 1.2, 1.4, 1.4, 1.2, 1.2, 1.0, 1.2, 1.6, 1.6, 1.6, 1.2, 1.2, 1.4, 1.2, 1.0, 1.2, 1.4, 1.6, 1.2, 1.2, 1.4, 1.4, 1.0, 1.2, 1.8, 1.2, 1.2, 1.4, 1.4, 1.4, 1.4, 1.0, 1.2, 1.0, 1.2, 1.4, 1.2, 2.0, 1.6, 1.4, 1.0, 1.4, 1.4, 1.4, 1.4, 1.2, 1.4]\n"
     ]
    }
   ],
   "source": [
    "# matched = []\n",
    "# for (p,a) in zip(df_top_seven.values, mtr.get_test_result()):\n",
    "#     matched.append(len(set(p.astype(int)) & set(a)))\n",
    "# weighted_match = [(1+2*(N/10)) for N in matched]\n",
    "matched, weighted_match = mtr.print_weighted_numbers(df_top_seven.values)\n",
    "print(matched)\n",
    "print(weighted_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('KNNC_KNNR', 69.40000000000002)]\n",
      "[['KNNC', 'KNNR']]\n",
      "Accuracy:  86.79245283018868\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 7\n",
    "print(t_accuracy[:n])\n",
    "\n",
    "a = [x[0].split('_') for x in t_accuracy[:n] ] \n",
    "print(a)\n",
    "for xx in a:\n",
    "    test_pred = []\n",
    "    s = ''\n",
    "    combine_prediction(xx, test_pred)\n",
    "    all_pred = [] ;\n",
    "    for i in range(len(test_pred)):\n",
    "        if ( i == 0 ):\n",
    "            all_pred = test_pred[i]\n",
    "        else:\n",
    "            all_pred = np.column_stack((all_pred, test_pred[i]) )\n",
    "\n",
    "    top_seven = []\n",
    "    for i in range(len(all_pred)):\n",
    "        unique, counts = np.unique(all_pred[i], return_counts=True)\n",
    "        x = dict(zip(unique, counts))\n",
    "        sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True) # sorted by value\n",
    "        l = list(islice([int(x) for x,y in sorted_x],top_n))\n",
    "        while ( len(l) < top_n ):\n",
    "          l.append(-1)\n",
    "        top_seven.append(l)\n",
    "\n",
    "\n",
    "    columns = ['N'+str(i+1) for i in range(len(top_seven[0]))]\n",
    "    df_top_seven = pd.DataFrame(top_seven, columns=columns)\n",
    "    r = mtr.getAccuracyCount(np.array(df_top_seven)) ;\n",
    "    print ( \"Accuracy: \",  r)\n",
    "    dict_accuracy.update({s: r})\n",
    "    mtr.plot_matched_counts(df_top_seven.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}\n",
    "\n",
    "\n",
    "prev_r = 0\n",
    "\n",
    "mtr = MyTotoResearch(algo_no=1)\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "#Deep Neuro Network\n",
    "for n in range(1,2):\n",
    "    X = mtr.modified_dataset(getAllData(df)) #\n",
    "    f = 1.0 #365/27.58\n",
    "#    X = getAdjustedDataF(df,f)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    Z = scaler.transform(X)\n",
    "\n",
    "    clf = SGDClassifier(random_state=42)\n",
    "\n",
    "    model = MultiOutputClassifier(clf, n_jobs=7)\n",
    "    model.fit(Z, mtr.getTargets()) \n",
    "    print(model)\n",
    "    s = model.score(Z, mtr.getTargets())\n",
    "    if(model.score(Z, mtr.getTargets()) == 1.0):\n",
    "        print( str(f), ' ', str(s))\n",
    "    store_prediction(mtr, model, f)\n",
    "    start = time.clock()\n",
    "    print(str(f), \" Time taken: \", (time.clock() - start),  \" \")\n",
    "\n",
    "print(\"Done.\")\n",
    "# mtr = MyTotoResearch(algo_no=1)\n",
    "# lresult, df = mtr.load_totodata()\n",
    "\n",
    "# test_data = mtr.get_test_data()\n",
    "\n",
    "for n in range(len(df_predictions)):\n",
    "    print( mtr.getAccuracyCount(np.array(df_predictions[n])))\n",
    "    mtr.print_predictions(df_predictions[n])\n",
    "\n",
    "\n",
    "#69.81 => MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='relu', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#75.47 =>  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#64.15 =>  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='adam', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#62  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='lbfgs', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#71.69 => MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='logistic', learning_rate='adaptive', solver='lbfgs', verbose=0,  random_state=42,tol=0.000000001)\n",
    "\n",
    "#75.47 => SVC(kernel='poly', coef0=0.05, probability=True, degree=2, random_state=42, tol=1e-03)\n",
    "\n",
    "\n",
    "\n",
    "#69.81 => SVC(random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nov 26\n",
    "# 16 22 28 31 38 46 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('SVMLREN', 83.01886792452831), \n",
    " ('SVMLRLasso', 83.01886792452831), \n",
    " ('RidgeETC', 81.13207547169812), \n",
    " ('RCETC', 81.13207547169812), \n",
    " ('ETCRidge', 81.13207547169812), \n",
    " ('SVMDTRRFR', 79.24528301886792), \n",
    " ('KNNCLDADTR', 79.24528301886792), \n",
    " ('KNNCLDASGDR', 79.24528301886792), ('LDADTRETC', 79.24528301886792), ('DTRENLasso', 79.24528301886792), ('SVMLR', 79.24528301886792), ('SVMLDA', 79.24528301886792), ('SVMEN', 79.24528301886792), ('SVMLasso', 79.24528301886792), ('RidgeDTR', 79.24528301886792), ('RCDTR', 79.24528301886792), ('DTRRidge', 79.24528301886792), ('SVMLRKNNR', 77.35849056603774), ('SVMLRSGDR', 77.35849056603774), ('SVMKNNRLR', 77.35849056603774), ('SVMLDAEN', 77.35849056603774), ('SVMLDANB', 77.35849056603774), ('SVMLDALasso', 77.35849056603774), ('SVMDTRETC', 77.35849056603774), ('SVMDTREN', 77.35849056603774), ('SVMDTRLasso', 77.35849056603774), ('SVMDTRSGDR', 77.35849056603774), ('SVMENLasso', 77.35849056603774), ('LRKNNCDTR', 77.35849056603774), ('LRKNNCEN', 77.35849056603774), ('LRKNNCLasso', 77.35849056603774), ('LRKNNCRFR', 77.35849056603774), ('LRKNNCSGDR', 77.35849056603774), ('LRETCEN', 77.35849056603774), ('LRETCLasso', 77.35849056603774), ('RidgeDTRETC', 77.35849056603774), ('RidgeDTREN', 77.35849056603774), ('RidgeDTRLasso', 77.35849056603774), ('RidgeDTRSGDR', 77.35849056603774), ('KNNCLRDTR', 77.35849056603774), ('KNNCLREN', 77.35849056603774), ('KNNCLRLasso', 77.35849056603774), ('KNNCLRRFR', 77.35849056603774), ('KNNCLRSGDR', 77.35849056603774), ('KNNCLDAEN', 77.35849056603774), ('KNNCLDALasso', 77.35849056603774), ('RCDTRETC', 77.35849056603774), ('RCDTREN', 77.35849056603774), ('RCDTRLasso', 77.35849056603774), ('RCDTRSGDR', 77.35849056603774), ('DTRETCNB', 77.35849056603774), ('DTRETCRidge', 77.35849056603774), ('DTRENRidge', 77.35849056603774), ('DTRRidgeLasso', 77.35849056603774), ('DTRRidgeSGDR', 77.35849056603774), ('ENLassoAdaB', 77.35849056603774), ('LRETC', 77.35849056603774), ('RidgeEN', 77.35849056603774), ('RidgeLasso', 77.35849056603774), ('RCEN', 77.35849056603774), ('RCLasso', 77.35849056603774), ('LDAETC', 77.35849056603774), ('DTRETC', 77.35849056603774), ('ENRidge', 77.35849056603774), ('SVMLRNB', 75.47169811320755), ('SVMLRGBR', 75.47169811320755), ('SVMLRRFR', 75.47169811320755), ('SVMDTRCART', 75.47169811320755), ('SVMETCSGDR', 75.47169811320755), ('LRDTRETC', 75.47169811320755), ('LRENLasso', 75.47169811320755), ('RidgeKNNCSGDR', 75.47169811320755), ('RidgeDTRRFR', 75.47169811320755), ('RidgeENLasso', 75.47169811320755), ('KNNCRCSGDR', 75.47169811320755), ('KNNCDTRETC', 75.47169811320755), ('KNNCENNB', 75.47169811320755), ('KNNCENLasso', 75.47169811320755), ('KNNCENSGDR', 75.47169811320755), ('KNNCNBLasso', 75.47169811320755), ('KNNCRidgeSGDR', 75.47169811320755), ('KNNCLassoSGDR', 75.47169811320755), ('KNNCRFRSGDR', 75.47169811320755), ('RCDTRRFR', 75.47169811320755), ('RCENLasso', 75.47169811320755), ('LDADTREN', 75.47169811320755), ('LDADTRLasso', 75.47169811320755), ('LDADTRRFR', 75.47169811320755), ('LDADTRSGDR', 75.47169811320755), ('LDAENLasso', 75.47169811320755), ('DTRRidgeRFR', 75.47169811320755), ('ENRidgeLasso', 75.47169811320755), ('ENLassoRFR', 75.47169811320755), ('SVMETC', 75.47169811320755), ('LRDTR', 75.47169811320755), ('KNNRETC', 75.47169811320755), ('LDADTR', 75.47169811320755), ('SVMLRKNNC', 73.58490566037736), ('SVMKNNCLR', 73.58490566037736), ('SVMKNNCSGDR', 73.58490566037736), ('SVMKNNRDTR', 73.58490566037736), ('SVMKNNRETC', 73.58490566037736), ('SVMLDADTR', 73.58490566037736), ('SVMLDASGDR', 73.58490566037736), ('SVMDTRNB', 73.58490566037736), ('LRKNNCNB', 73.58490566037736), ('LRKNNCGBR', 73.58490566037736), ('LRKNNCAdaB', 73.58490566037736), ('LRETCNB', 73.58490566037736), ('LRETCRFR', 73.58490566037736), ('LRETCSGDR', 73.58490566037736), ('LRENRFR', 73.58490566037736), ('LRLassoRFR', 73.58490566037736), ('RidgeDTRNB', 73.58490566037736), ('KNNCKNNRDTR', 73.58490566037736), ('KNNCLRNB', 73.58490566037736), ('KNNCLRGBR', 73.58490566037736), ('KNNCLRAdaB', 73.58490566037736), ('KNNCLDARFR', 73.58490566037736), ('KNNCDTRSGDR', 73.58490566037736), ('KNNCNBSGDR', 73.58490566037736), ('RCDTRNB', 73.58490566037736), ('LDADTRCART', 73.58490566037736), ('LDADTRGBR', 73.58490566037736), ('LDAETCNB', 73.58490566037736), ('DTRETCRFR', 73.58490566037736), ('DTRCARTRFR', 73.58490566037736), ('DTRNBRidge', 73.58490566037736), ('ETRENLasso', 73.58490566037736), ('ETCENLasso', 73.58490566037736), ('ENNBLasso', 73.58490566037736), ('SVMDTR', 73.58490566037736), ('LREN', 73.58490566037736), ('LRLasso', 73.58490566037736), ('RidgeLDA', 73.58490566037736), ('KNNCDTR', 73.58490566037736), ('RCLDA', 73.58490566037736), ('LDAEN', 73.58490566037736), ('LDARidge', 73.58490566037736), ('LDALasso', 73.58490566037736), ('DTRRFR', 73.58490566037736), ('ETCCART', 73.58490566037736), ('ETCRFR', 73.58490566037736), ('ETCSGDR', 73.58490566037736), ('ENLasso', 73.58490566037736), ('SVMLRLDA', 71.69811320754717), ('SVMRidgeEN', 71.69811320754717), ('SVMRidgeLasso', 71.69811320754717), ('SVMKNNRLDA', 71.69811320754717), ('SVMKNNREN', 71.69811320754717), ('SVMKNNRLasso', 71.69811320754717), ('SVMRCEN', 71.69811320754717), ('SVMRCLasso', 71.69811320754717), ('SVMLDAETC', 71.69811320754717), ('SVMLDAGBR', 71.69811320754717), ('SVMDTRGBR', 71.69811320754717), ('SVMETCEN', 71.69811320754717), ('SVMETCLasso', 71.69811320754717), ('SVMETCGBR', 71.69811320754717), ('SVMENRidge', 71.69811320754717), ('SVMENGBR', 71.69811320754717), ('SVMENRFR', 71.69811320754717), ('SVMENSGDR', 71.69811320754717), ('SVMLassoGBR', 71.69811320754717), ('SVMLassoRFR', 71.69811320754717), ('SVMLassoSGDR', 71.69811320754717), ('SVMRFRSGDR', 71.69811320754717), ('LRKNNCCART', 71.69811320754717), ('LRDTREN', 71.69811320754717), ('LRDTRLasso', 71.69811320754717), ('LRDTRRFR', 71.69811320754717), ('LRENNB', 71.69811320754717), ('LRENGBR', 71.69811320754717), ('LRENSGDR', 71.69811320754717), ('LRNBLasso', 71.69811320754717), ('LRNBSGDR', 71.69811320754717), ('LRLassoGBR', 71.69811320754717), ('LRLassoSGDR', 71.69811320754717), ('LRRFRSGDR', 71.69811320754717), ('RidgeKNNCEN', 71.69811320754717), ('RidgeKNNCNB', 71.69811320754717), ('RidgeKNNCLasso', 71.69811320754717), ('RidgeKNNRDTR', 71.69811320754717), ('RidgeDTRCART', 71.69811320754717), ('RidgeDTRGBR', 71.69811320754717), ('RidgeETCNB', 71.69811320754717), ('RidgeETCSGDR', 71.69811320754717), ('RidgeENNB', 71.69811320754717), ('RidgeENAdaB', 71.69811320754717), ('RidgeNBLasso', 71.69811320754717), ('RidgeLassoAdaB', 71.69811320754717), ('RidgeRFRSGDR', 71.69811320754717), ('KNNCRCEN', 71.69811320754717), ('KNNCRCNB', 71.69811320754717), ('KNNCRCLasso', 71.69811320754717), ('KNNCLRCART', 71.69811320754717), ('KNNCLDAGBR', 71.69811320754717), ('KNNCDTREN', 71.69811320754717), ('KNNCDTRNB', 71.69811320754717), ('KNNCDTRLasso', 71.69811320754717), ('KNNCDTRGBR', 71.69811320754717), ('KNNCDTRRFR', 71.69811320754717), ('KNNCENRidge', 71.69811320754717), ('KNNCCARTNB', 71.69811320754717), ('KNNCCARTSGDR', 71.69811320754717), ('KNNCNBRidge', 71.69811320754717), ('KNNCRidgeLasso', 71.69811320754717), ('KNNRRCDTR', 71.69811320754717), ('KNNRDTRRidge', 71.69811320754717), ('RCDTRCART', 71.69811320754717), ('RCDTRGBR', 71.69811320754717), ('RCETCNB', 71.69811320754717), ('RCETCSGDR', 71.69811320754717), ('RCENNB', 71.69811320754717), ('RCENAdaB', 71.69811320754717), ('RCNBLasso', 71.69811320754717), ('RCLassoAdaB', 71.69811320754717), ('RCRFRSGDR', 71.69811320754717), ('LDAETCRFR', 71.69811320754717), ('LDAENNB', 71.69811320754717), ('LDANBLasso', 71.69811320754717), ('DTRETCCART', 71.69811320754717), ('DTRETCSGDR', 71.69811320754717), ('DTRCARTRidge', 71.69811320754717), ('DTRCARTSGDR', 71.69811320754717), ('DTRNBRFR', 71.69811320754717), ('DTRRidgeGBR', 71.69811320754717), ('ETRETCRFR', 71.69811320754717), ('ETCNBRidge', 71.69811320754717), ('ETCRidgeSGDR', 71.69811320754717), ('ENNBRidge', 71.69811320754717), ('ENRidgeAdaB', 71.69811320754717), ('ENLassoGBR', 71.69811320754717), ('CARTRFRSGDR', 71.69811320754717), ('NBRidgeLasso', 71.69811320754717), ('SVMNB', 71.69811320754717), ('SVMGBR', 71.69811320754717), ('SVMSGDR', 71.69811320754717), ('LRRFR', 71.69811320754717), ('LRAdaB', 71.69811320754717), ('RidgeKNNR', 71.69811320754717), ('RidgeNB', 71.69811320754717), ('KNNCSGDR', 71.69811320754717), ('KNNRRC', 71.69811320754717), ('KNNREN', 71.69811320754717), ('KNNRRidge', 71.69811320754717), ('KNNRLasso', 71.69811320754717), ('RCNB', 71.69811320754717), ('LDACART', 71.69811320754717), ('LDAAdaB', 71.69811320754717), ('DTRCART', 71.69811320754717), ('DTRNB', 71.69811320754717), ('ETCNB', 71.69811320754717), ('ENSGDR', 71.69811320754717), ('NBRidge', 71.69811320754717), ('LassoSGDR', 71.69811320754717), ('GBRRFR', 71.69811320754717), ('SVMLRDTR', 69.81132075471697), ('SVMLRETR', 69.81132075471697), ('SVMLRETC', 69.81132075471697), ('SVMLRAdaB', 69.81132075471697), ('SVMRidgeNB', 69.81132075471697), ('SVMRidgeSGDR', 69.81132075471697), ('SVMKNNCLDA', 69.81132075471697), ('SVMKNNRNB', 69.81132075471697), ('SVMKNNRSGDR', 69.81132075471697), ('SVMRCNB', 69.81132075471697), ('SVMRCSGDR', 69.81132075471697), ('SVMDTRETR', 69.81132075471697), ('SVMETCNB', 69.81132075471697), ('SVMETCRFR', 69.81132075471697), ('SVMENCART', 69.81132075471697), ('SVMENNB', 69.81132075471697), ('SVMENAdaB', 69.81132075471697), ('SVMCARTLasso', 69.81132075471697), ('SVMCARTSGDR', 69.81132075471697), ('SVMNBRidge', 69.81132075471697), ('SVMNBLasso', 69.81132075471697), ('SVMNBSGDR', 69.81132075471697), ('SVMLassoAdaB', 69.81132075471697), ('LRKNNCETC', 69.81132075471697), ('LRKNNREN', 69.81132075471697), ('LRKNNRNB', 69.81132075471697), ('LRKNNRLasso', 69.81132075471697), ('LRLDADTR', 69.81132075471697), ('LRLDAEN', 69.81132075471697), ('LRLDACART', 69.81132075471697), ('LRLDALasso', 69.81132075471697), ('LRDTRNB', 69.81132075471697), ('LRDTRGBR', 69.81132075471697), ('LRDTRSGDR', 69.81132075471697), ('LRETRETC', 69.81132075471697), ('LRETCGBR', 69.81132075471697), ('LRENAdaB', 69.81132075471697), ('LRNBGBR', 69.81132075471697), ('LRLassoAdaB', 69.81132075471697), ('LRGBRRFR', 69.81132075471697), ('RidgeKNNCDTR', 69.81132075471697), ('RidgeKNNCCART', 69.81132075471697), ('RidgeKNNCGBR', 69.81132075471697), ('RidgeKNNREN', 69.81132075471697), ('RidgeKNNRLasso', 69.81132075471697), ('RidgeLDAEN', 69.81132075471697), ('RidgeLDALasso', 69.81132075471697), ('RidgeETCEN', 69.81132075471697), ('RidgeETCLasso', 69.81132075471697), ('RidgeENGBR', 69.81132075471697), ('RidgeNBSGDR', 69.81132075471697), ('RidgeLassoGBR', 69.81132075471697), ('RidgeSGDRAdaB', 69.81132075471697), ('KNNCRCDTR', 69.81132075471697), ('KNNCRCCART', 69.81132075471697), ('KNNCRCGBR', 69.81132075471697), ('KNNCLRETC', 69.81132075471697), ('KNNCLDACART', 69.81132075471697), ('KNNCLDAAdaB', 69.81132075471697), ('KNNCDTRRidge', 69.81132075471697), ('KNNCETRSGDR', 69.81132075471697), ('KNNCENGBR', 69.81132075471697), ('KNNCCARTRidge', 69.81132075471697), ('KNNCNBGBR', 69.81132075471697), ('KNNCNBRFR', 69.81132075471697), ('KNNCRidgeGBR', 69.81132075471697), ('KNNCLassoGBR', 69.81132075471697), ('KNNCGBRSGDR', 69.81132075471697), ('KNNRRCEN', 69.81132075471697), ('KNNRRCLasso', 69.81132075471697), ('KNNRLREN', 69.81132075471697), ('KNNRLRNB', 69.81132075471697), ('KNNRLRLasso', 69.81132075471697), ('KNNRLDADTR', 69.81132075471697), ('KNNRLDAEN', 69.81132075471697), ('KNNRLDANB', 69.81132075471697), ('KNNRLDALasso', 69.81132075471697), ('KNNRDTRETC', 69.81132075471697), ('KNNRDTRCART', 69.81132075471697), ('KNNRENRidge', 69.81132075471697), ('KNNRENLasso', 69.81132075471697), ('KNNRRidgeLasso', 69.81132075471697), ('RCLDAEN', 69.81132075471697), ('RCLDALasso', 69.81132075471697), ('RCETCEN', 69.81132075471697), ('RCETCLasso', 69.81132075471697), ('RCENGBR', 69.81132075471697), ('RCNBSGDR', 69.81132075471697), ('RCLassoGBR', 69.81132075471697), ('RCSGDRAdaB', 69.81132075471697), ('LDADTRNB', 69.81132075471697), ('LDAETCEN', 69.81132075471697), ('LDAETCLasso', 69.81132075471697), ('LDAETCSGDR', 69.81132075471697), ('LDAENCART', 69.81132075471697), ('LDAENRidge', 69.81132075471697), ('LDAENSGDR', 69.81132075471697), ('LDACARTLasso', 69.81132075471697), ('LDACARTSGDR', 69.81132075471697), ('LDANBGBR', 69.81132075471697), ('LDANBSGDR', 69.81132075471697), ('LDARidgeLasso', 69.81132075471697), ('LDALassoSGDR', 69.81132075471697), ('LDARFRSGDR', 69.81132075471697), ('DTRENAdaB', 69.81132075471697), ('DTRNBSGDR', 69.81132075471697), ('DTRLassoAdaB', 69.81132075471697), ('DTRRFRSGDR', 69.81132075471697), ('ETCENRidge', 69.81132075471697), ('ETCNBGBR', 69.81132075471697), ('ETCNBSGDR', 69.81132075471697), ('ETCRidgeLasso', 69.81132075471697), ('ENCARTLasso', 69.81132075471697), ('ENRidgeGBR', 69.81132075471697), ('ENLassoSGDR', 69.81132075471697), ('ENRFRSGDR', 69.81132075471697), ('NBRidgeSGDR', 69.81132075471697), ('LassoRFRSGDR', 69.81132075471697), ('GBRRFRRFR', 69.81132075471697), ('GBRRFRSGDR', 69.81132075471697), ('RFRRFRSGDR', 69.81132075471697), ('SVMRidge', 69.81132075471697), ('SVMKNNR', 69.81132075471697), ('SVMRC', 69.81132075471697), ('LRRidge', 69.81132075471697), ('LRRC', 69.81132075471697), ('RidgeLR', 69.81132075471697), ('RidgeRFR', 69.81132075471697), ('RidgeSGDR', 69.81132075471697), ('KNNCETC', 69.81132075471697), ('KNNCNB', 69.81132075471697), ('RCLR', 69.81132075471697), ('RCRFR', 69.81132075471697), ('RCSGDR', 69.81132075471697), ('LDANB', 69.81132075471697), ('LDARFR', 69.81132075471697), ('DTRGBR', 69.81132075471697), ('ETCEN', 69.81132075471697), ('ETCLasso', 69.81132075471697), ('ETCGBR', 69.81132075471697), ('ENRFR', 69.81132075471697), ('NBRFR', 69.81132075471697), ('LassoRFR', 69.81132075471697), ('RFRSGDR', 69.81132075471697), ('SVMLRRidge', 67.9245283018868), ('SVMLRRC', 67.9245283018868), ('SVMLRLR', 67.9245283018868), ('SVMLRCART', 67.9245283018868), ('SVMRidgeKNNC', 67.9245283018868), ('SVMRidgeLR', 67.9245283018868), ('SVMRidgeETC', 67.9245283018868), ('SVMRidgeCART', 67.9245283018868), ('SVMRidgeGBR', 67.9245283018868), ('SVMKNNCRC', 67.9245283018868), ('SVMKNNCDTR', 67.9245283018868), ('SVMKNNCEN', 67.9245283018868), ('SVMKNNCRidge', 67.9245283018868), ('SVMKNNCLasso', 67.9245283018868), ('SVMKNNRCART', 67.9245283018868), ('SVMKNNRGBR', 67.9245283018868), ('SVMRCLR', 67.9245283018868), ('SVMRCETC', 67.9245283018868), ('SVMRCCART', 67.9245283018868), ('SVMRCGBR', 67.9245283018868), ('SVMLDACART', 67.9245283018868), ('SVMLDARFR', 67.9245283018868), ('SVMLDAAdaB', 67.9245283018868), ('SVMETRETC', 67.9245283018868), ('SVMETCCART', 67.9245283018868), ('SVMETCRidge', 67.9245283018868), ('SVMCARTRidge', 67.9245283018868), ('SVMGBRRFR', 67.9245283018868), ('SVMGBRSGDR', 67.9245283018868), ('SVMGBRAdaB', 67.9245283018868), ('SVMSGDRAdaB', 67.9245283018868), ('LRRidgeETC', 67.9245283018868), ('LRRidgeEN', 67.9245283018868), ('LRRidgeLasso', 67.9245283018868), ('LRKNNCKNNR', 67.9245283018868), ('LRKNNCLDA', 67.9245283018868), ('LRKNNRLDA', 67.9245283018868), ('LRRCETC', 67.9245283018868), ('LRRCEN', 67.9245283018868), ('LRRCLasso', 67.9245283018868), ('LRLDAETC', 67.9245283018868), ('LRLDAGBR', 67.9245283018868), ('LRLDASGDR', 67.9245283018868), ('LRETCRidge', 67.9245283018868), ('LRETCAdaB', 67.9245283018868), ('LRENRidge', 67.9245283018868), ('LRGBRSGDR', 67.9245283018868), ('LRRFRRFR', 67.9245283018868), ('RidgeKNNCAdaB', 67.9245283018868), ('RidgeKNNRNB', 67.9245283018868), ('RidgeKNNRSGDR', 67.9245283018868), ('RidgeRCEN', 67.9245283018868), ('RidgeRCCART', 67.9245283018868), ('RidgeRCLasso', 67.9245283018868), ('RidgeLRETC', 67.9245283018868), ('RidgeLREN', 67.9245283018868), ('RidgeLRLasso', 67.9245283018868), ('RidgeDTRETR', 67.9245283018868), ('RidgeETCGBR', 67.9245283018868), ('RidgeENRidge', 67.9245283018868), ('RidgeENRFR', 67.9245283018868), ('RidgeENSGDR', 67.9245283018868), ('RidgeCARTRidge', 67.9245283018868), ('RidgeNBGBR', 67.9245283018868), ('RidgeNBAdaB', 67.9245283018868), ('RidgeRidgeLasso', 67.9245283018868), ('RidgeLassoRFR', 67.9245283018868), ('RidgeLassoSGDR', 67.9245283018868), ('RidgeGBRRFR', 67.9245283018868), ('RidgeGBRAdaB', 67.9245283018868), ('KNNCKNNRLR', 67.9245283018868), ('KNNCKNNREN', 67.9245283018868), ('KNNCKNNRNB', 67.9245283018868), ('KNNCKNNRLasso', 67.9245283018868), ('KNNCKNNRSGDR', 67.9245283018868), ('KNNCRCAdaB', 67.9245283018868), ('KNNCLRLDA', 67.9245283018868), ('KNNCLDAETC', 67.9245283018868), ('KNNCLDANB', 67.9245283018868), ('KNNCDTRCART', 67.9245283018868), ('KNNCETREN', 67.9245283018868), ('KNNCETRLasso', 67.9245283018868), ('KNNCETCSGDR', 67.9245283018868), ('KNNCENRFR', 67.9245283018868), ('KNNCRidgeAdaB', 67.9245283018868), ('KNNCLassoRFR', 67.9245283018868), ('KNNRRCNB', 67.9245283018868), ('KNNRRCSGDR', 67.9245283018868), ('KNNRLRLDA', 67.9245283018868), ('KNNRETCNB', 67.9245283018868), ('KNNRNBRidge', 67.9245283018868), ('KNNRRidgeSGDR', 67.9245283018868), ('KNNRRFRRFR', 67.9245283018868), ('\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20180514   [17 24 29 45 46 49  5]   [ 8. 22. 16. 19. 39. 43.]   []\n",
    "20180517   [ 7 21 25 29 35 37 13]   [16.  6. 34. 40. 35. 43.]   [35]\n",
    "20180521   [ 8 10 16 30 37 44 17]   [ 5.  9. 16. 26. 24. 43.]   [16]\n",
    "20180524   [11 25 26 34 36 42 16]   [ 5.  9. 16. 26. 45. 36.]   [16 26 36]\n",
    "20180528   [ 5  9 27 28 30 44  2]   [ 5.  9. 16. 38. 39. 43.]   [5 9]\n",
    "20180531   [11 13 24 26 47 49 33]   [20.  9. 23. 26. 34. 43.]   [26]\n",
    "20180604   [20 22 31 37 43 45 27]   [ 5.  9. 16. 26. 22. 43.]   [22 43]\n",
    "20180607   [12 20 29 31 37 39 42]   [ 8.  9. 16. 27. 22. 41.]   []\n",
    "20180611   [16 25 30 37 44 49 34]   [ 5. 20. 25. 38. 44. 42.]   [25 44]\n",
    "20180614   [ 4 29 31 35 42 48  1]   [18.  6. 18. 26. 32. 36.]   []\n",
    "20180618   [11 15 22 23 26 43 25]   [18.  6. 16. 26. 22. 36.]   [22 26]\n",
    "201806\n",
    "\n",
    "75.47169811320755\n",
    "20180514   [17 24 29 45 46 49  5]   [ 2. 35. 30. 17. 25. 27.]   [17]\n",
    "20180517   [ 7 21 25 29 35 37 13]   [ 5. 33. 36. 16. 25. 31.]   [25]\n",
    "20180521   [ 8 10 16 30 37 44 17]   [ 5. 27. 30. 18. 33. 38.]   [30]\n",
    "20180524   [11 25 26 34 36 42 16]   [ 5. 26. 30. 18. 29. 45.]   [26]\n",
    "20180528   [ 5  9 27 28 30 44  2]   [ 5.  7. 12. 18. 22. 38.]   [5]\n",
    "20180531   [11 13 24 26 47 49 33]   [ 5. 35. 12. 38. 33. 41.]   [33]\n",
    "20180604   [20 22 31 37 43 45 27]   [ 5.  7. 12. 18. 24. 38.]   []\n",
    "20180607   [12 20 29 31 37 39 42]   [ 5. 35. 12. 38. 22. 40.]   [12]\n",
    "20180611   [16 25 30 37 44 49 34]   [22. 27. 28. 38. 33. 38.]   []\n",
    "20180614   [ 4 29 31 35 42 48  1]   [ 5. 36. 30. 23. 24. 31.]   [31]\n",
    "20180618   [11 15 22 23 26 43 25]   [13. 36. 30. 17. 22. 36.]   [22]\n",
    "20180621   [ 4  6 15 24 30 35 46]   [10. 20. 23. 28. 32. 42.]   []\n",
    "20180625   [ 2  5 25 38 44 48  9]   [15. 18. 20. 27. 41. 40.]   []\n",
    "20180628   [ 2  7 22 27 40 47 48]   [12. 15. 27. 35. 41. 43.]   [27]\n",
    "20180702   [12 13 26 33 35 38 23]   [ 8.  7. 19. 35. 41. 43.]   [35]\n",
    "20180705   [ 8 11 28 30 32 34 39]   [ 9. 18. 17. 28. 37. 42.]   [28]\n",
    "20180709   [ 6 23 31 38 39 43 33]   [12. 23. 26. 28. 36. 40.]   [23]\n",
    "20180712   [ 4 15 25 32 40 41 10]   [ 5. 23. 35. 29. 32. 45.]   [32]\n",
    "20180716   [ 4  8 19 24 32 47 22]   [ 8. 19. 27. 24. 31. 38.]   [ 8 19 24]\n",
    "20180719   [13 14 23 35 37 46 45]   [10. 17. 27. 32. 40. 41.]   []\n",
    "20180723   [ 2 23 26 28 39 40 12]   [23. 23. 33. 28. 31. 43.]   [23 28]\n",
    "20180726   [ 1  9 13 17 28 40 37]   [11. 28. 30. 32. 34. 39.]   [28]\n",
    "20180730   [ 8 10 19 20 41 43  7]   [ 8. 23. 26. 24. 35. 38.]   [8]\n",
    "20180802   [ 1 10 15 27 41 46 35]   [ 3.  9. 25. 29. 40. 48.]   []\n",
    "20180806   [ 7 18 20 27 36 40 15]   [ 6. 15. 24. 30. 35. 45.]   [15]\n",
    "20180809   [13 16 20 23 39 42 28]   [11. 22. 23. 27. 35. 43.]   [23]\n",
    "20180813   [ 1  3  6 16 22 36 17]   [ 4. 18. 31. 35. 42. 44.]   []\n",
    "20180816   [22 23 25 32 33 36 20]   [ 7. 18. 34. 31. 34. 44.]   []\n",
    "20180820   [ 9 10 25 38 40 42  2]   [ 9. 18. 26. 27. 39. 44.]   [9]\n",
    "20180823   [ 2  3 23 30 39 41 19]   [ 8. 18. 23. 37. 43. 44.]   [23]\n",
    "20180827   [ 5  6 16 24 26 29 38]   [ 8. 17. 23. 27. 41. 44.]   []\n",
    "20180830   [ 3  9 27 29 31 40 46]   [ 8. 18. 27. 32. 41. 44.]   [27]\n",
    "20180903   [ 4  5 13 18 39 40  3]   [10. 18. 22. 27. 36. 42.]   [18]\n",
    "20180906   [ 2 15 17 20 23 30 45]   [ 7. 18. 23. 27. 41. 44.]   [23]\n",
    "20180910   [ 2  6  9 15 40 43 18]   [ 7. 18. 19. 27. 41. 44.]   [18]\n",
    "20180913   [ 6 16 17 40 44 48 34]   [11. 18. 17. 27. 41. 44.]   [17 44]\n",
    "20180917   [16 21 22 24 25 27  1]   [ 7. 18. 17. 27. 41. 44.]   [27]\n",
    "20180920   [ 5 12 18 30 32 38 22]   [11. 18. 22. 27. 41. 44.]   [18 22]\n",
    "20180924   [ 6  8 17 24 29 47 34]   [ 7. 18. 19. 31. 38. 45.]   []\n",
    "20180927   [ 2 25 29 33 42 45 20]   [11. 18. 23. 31. 41. 44.]   []\n",
    "20181001   [11 15 23 24 32 40 43]   [11. 18. 17. 31. 41. 44.]   [11]\n",
    "20181004   [ 5 12 23 32 37 42 43]   [ 7. 18. 22. 27. 41. 44.]   []\n",
    "20181008   [17 18 23 39 43 49  2]   [ 4. 11. 22. 30. 30. 45.]   []\n",
    "20181011   [ 1 16 18 24 29 46 35]   [ 9. 18. 23. 32. 41. 43.]   [18]\n",
    "20181015   [ 1  4 24 32 35 48 20]   [ 7. 18. 17. 31. 35. 45.]   [35]\n",
    "20181018   [ 5 14 17 31 46 48 47]   [ 5. 13. 17. 31. 40. 45.]   [ 5 17 31]\n",
    "20181022   [ 5 22 24 40 43 48  2]   [ 5. 15. 25. 31. 38. 42.]   [5]\n",
    "20181025   [ 7  8 13 15 35 48 30]   [14. 17. 22. 34. 38. 42.]   []\n",
    "20181029   [ 2  6 10 20 28 31 30]   [ 6. 15. 19. 31. 40. 44.]   [ 6 31]\n",
    "20181101   [ 6 27 28 41 44 48 15]   [ 6. 15. 23. 27. 41. 44.]   [ 6 15 27 41 44]\n",
    "20181101   [ 6 27 28 41 44 48 15]   [ 8. 15. 29. 27. 34. 41.]   [15 27 41]\n",
    "\n",
    "20181105   [ 3  8 14 28 43 49 26]   [11. 18. 23. 31. 41. 44.]   []\n",
    "20181108   [ 8 13 16 26 28 38 46]   [ 7. 17. 23. 31. 38. 45.]   [38]\n",
    "20181112   [ 4 12 21 34 41 47 33]   [ 8. 12. 22. 31. 41. 44.]   [12 41]\n",
    "20181115  Predicted:  [10. 18. 22. 27. 40. 44.]  \n",
    "20181119  Predicted:  [ 9. 18. 19. 27. 35. 45.]  \n",
    "20181122  Predicted:  [ 9. 18. 22. 27. 35. 41.]  \n",
    "20181126  Predicted:  [ 6. 18. 23. 27. 38. 44.]  \n",
    "20181129  Predicted:  [ 7. 18. 23. 30. 35. 44.]  \n",
    "20181203  Predicted:  [ 7. 18. 17. 31. 41. 45.]  \n",
    "20181206  Predicted:  [ 7. 18. 17. 27. 35. 44.]  \n",
    "20181210  Predicted:  [ 6. 18. 17. 31. 41. 45.]  \n",
    "20181213  Predicted:  [ 7. 18. 17. 31. 41. 44.]  \n",
    "20181217  Predicted:  [ 7. 18. 19. 27. 35. 44.]  \n",
    "20181220  Predicted:  [ 7. 18. 23. 31. 41. 44.]  \n",
    "20181224  Predicted:  [ 7. 18. 22. 27. 41. 44.]  \n",
    "20181227  Predicted:  [ 8. 18. 23. 27. 41. 44.]  \n",
    "20181231  Predicted:  [ 9. 18. 23. 27. 41. 44.]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep track of all results\n",
    "#df_predictions = []\n",
    "\n",
    "#print(df_predictions)\n",
    "#mtr = MyTotoResearch(algo_no=1)\n",
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'L','M','S','R','E','A','V' ,'J','U','K']\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "    return X\n",
    "\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "test_data = mtr.get_test_data()\n",
    "X = mtr.modified_dataset(getAllData(test_data)) #\n",
    "\n",
    "print(len(df_predictions))\n",
    "for n in range(len(df_predictions)):\n",
    "    print( mtr.getAccuracyCount(np.array(df_predictions[n])))\n",
    "    mtr.print_predictions(df_predictions[n])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dOld = dfResult\n",
    "#2 9 14 36 46 48 5\n",
    "\n",
    "\n",
    "\n",
    "20180514   [17 24 29 45 46 49  5]   [ 4. 18. 22. 24. 25. 36.]   [24]\n",
    "20180514   [17 24 29 45 46 49  5]   [ 7. 17. 22. 24. 39. 45.]   [17 24 45]\n",
    "20180514   [17 24 29 45 46 49  5]   [ 6. 14. 34. 24. 25. 27.]   [24]\n",
    "20180514   [17 24 29 45 46 49  5]   [ 7.  9. 22. 24. 42. 45.]   [24 45]\n",
    "20180514   [17 24 29 45 46 49  5]   [ 7.  9. 22. 24. 42. 45.]   [24 45]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
