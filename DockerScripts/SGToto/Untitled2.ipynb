{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SGH.csv', 'PPv3.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import utils, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier, Ridge\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "#from skmultilearn.adapt import MLkNN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "#from sklearn.linear_model import RidgeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Compare Algorithms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "#warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings\n",
    "#warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "seed = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(prediction, actual):\n",
    "    matched = []\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "        matched.append(len(set(p.astype(int)) & set(a)))\n",
    "    return matched\n",
    "\n",
    "def getPercent(prediction, actual, n):\n",
    "    matched = []\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "        matched.append(set(p.astype(int)) & set(a))\n",
    "    return sum(len(num) > n for num in matched)/len(matched)*100.00\n",
    "\n",
    "def getCounts(prediction, actual):\n",
    "    matched = []\n",
    "    N = [0,0,0,0,0,0,0,0]\n",
    "    if len(prediction) == 0: return N\n",
    "    for (a,p) in zip(actual, prediction):\n",
    "        matched.append(set(p.astype(int)) & set(a))\n",
    "    if len(matched) == 0:\n",
    "        return N\n",
    "    N[0] = sum(len(num) > 0 for num in matched)/len(matched)*100.00\n",
    "    N[1] = sum(len(num) > 1 for num in matched)/len(matched)*100.00\n",
    "    N[2] = sum(len(num) > 2 for num in matched)/len(matched)*100.00\n",
    "    N[3] = sum(len(num) > 3 for num in matched)/len(matched)*100.00\n",
    "    N[4] = sum(len(num) > 4 for num in matched)/len(matched)*100.00\n",
    "    N[5] = sum(len(num) > 5 for num in matched)/len(matched)*100.00\n",
    "    N[6] = sum(len(num) > 6 for num in matched)/len(matched)*100.00\n",
    "    N[7] = sum(len(num) > 7 for num in matched)/len(matched)*100.00\n",
    "#    matched.extend(N)\n",
    "    return N\n",
    "\n",
    "\n",
    "def getAccuracy1dCount(prediction, actual):\n",
    "    iMatched = 0\n",
    "    print(len(prediction))\n",
    "    for i in range(0,len(prediction)):\n",
    "        if prediction[i] == actual[i]:\n",
    "            iMatched = iMatched +1\n",
    "    return iMatched\n",
    "\n",
    "def getAccuracy1dPercentCorrect(prediction, actual):\n",
    "    iMatched = 0\n",
    "    print(len(prediction))\n",
    "    for i in range(0,len(prediction)):\n",
    "        if prediction[i] == actual[i]:\n",
    "            iMatched = iMatched +1\n",
    "    return iMatched/len(prediction) * 100.0\n",
    "\n",
    "\n",
    "def getAccuracyCount(prediction, actual):\n",
    "    matched = []\n",
    "    if len(prediction) == 0: return 0\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "#        print ( \"p: \", p, \" a: \", a, (set(p.astype(int)) & set(a)) )\n",
    "        matched.append((set(p.astype(int)) & set(a)))\n",
    "    return sum(len(num) > 0 for num in matched)/len(matched)*100.00\n",
    "\n",
    "def getIntersection(p1, p2):\n",
    "    return [reduce(np.intersect1d, (p.astype(int), a.astype(int))) for (p,a) in zip(p1, p2)]\n",
    "\n",
    "def getUnion(p1, p2):\n",
    "    if len(p1) == 0: return p2\n",
    "    return [reduce(np.union1d, (p.astype(int), a.astype(int))) for (p,a) in zip(p1, p2)]\n",
    "\n",
    "def getUnion1dArray(p1,p2):\n",
    "    return reduce(np.union1d, (p1,p2))\n",
    "\n",
    "def getIntersection1dArray(prediction, actual):\n",
    "    iMatched = 0\n",
    "#     return reduce(np.intersect1d,([prediction,actual]))\n",
    "#     for idx, i in enumerate(prediction):\n",
    "#       if prediction[idx] == actual[idx]:\n",
    "#         iMatched = iMatched + 1\n",
    "#     return iMatched\n",
    "\n",
    "# def getAccuracy1dCount(prediction, actual):\n",
    "#     iMatched = 0\n",
    "#     for idx in enumerate(prediction):\n",
    "#       if prediction[idx] == actual[idx]:\n",
    "#         iMatched = iMatched + 1\n",
    "#     return iMatched\n",
    "\n",
    "\n",
    "\n",
    "def unionPrediction(ff):\n",
    "    predicted = []\n",
    "    for i, f in enumerate(ff):\n",
    "#        i_index = name_.index(sInputDir + f + '.csv')        \n",
    "        i_index = name_.index(f)        \n",
    "        if i == 0: predicted = list_[i_index][cols].values\n",
    "        if i > 0:\n",
    "            predicted = getUnion(predicted,list_[i_index][cols].values)\n",
    "    return predicted\n",
    "\n",
    "def getMatches(prediction, actual):\n",
    "    matched = []\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "        print ( len(p), \"** p: \", p, \" a: \", a, (set(p.astype(int)) & set(a)) )\n",
    "        matched.append((set(p.astype(int)) & set(a)))\n",
    "    return matched\n",
    "\n",
    "def getMatchedCount(prediction, actual):\n",
    "    return getAccuracyCount(prediction, actual)\n",
    "\n",
    "def printPredictions ( prediction, actual ):\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "        print ( '[',len(set(p.astype(int) )&set(a.astype(int))),'/',len(p),'',set(p.astype(int) ), ' ', set(a.astype(int)), ' ', set(p.astype(int) )&set(a.astype(int)))\n",
    "\n",
    "def bins_labels(bins, **kwargs):\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "def getColums (idx):\n",
    "    return list(os.path.splitext(basename(name_[idx]))[0][2:])\n",
    "\n",
    "\n",
    "def showResult(str_alg, prediction, actual ):\n",
    "    print( str_alg, \" Accuracy predict 1 in 7: \", getAccuracy(prediction, actual))\n",
    "\n",
    "def printResult(predictions, actual):\n",
    "    df_result=pd.DataFrame({ 'Predicted':list(predictions), 'Actual':list(actual)})\n",
    "    print(df_result)  \n",
    "    \n",
    "def getStdDeviationOfPrediction(ytestPredicted, y_test):\n",
    "    print(\"Removing invalid predictions ( < 0 )\")\n",
    "    ind2remove = np.where(ytestPredicted <= 0)[0]\n",
    "    ytestPredictedFinal = np.delete(ytestPredicted, ind2remove)\n",
    "    y_testFinal = np.delete(y_test, ind2remove)\n",
    "    iM = getAccuracy1dCount(y_testFinal, ytestPredictedFinal)\n",
    "    print(iM)   \n",
    "    print(np.std(ytestPredictedFinal-y_testFinal))\n",
    "\n",
    "\n",
    "print('Done')\n",
    "\n",
    "def loadResult(col_n = 1):\n",
    "    col_n = 1  #Column Number interested\n",
    "    print(lresult)\n",
    "    aa = np.delete(lresult, np.s_[col_n:], axis=1)  \n",
    "    aa = np.delete(aa, np.s_[0:col_n-1], axis=1)  \n",
    "\n",
    "    # 1. INSTANTIATE\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "    # 2. FIT\n",
    "    enc.fit(aa)\n",
    "\n",
    "    # 3. Transform\n",
    "    onehotlabels = enc.transform(aa).toarray()\n",
    "    onehotlabels.shape\n",
    "    #print(onehotlabels)\n",
    "\n",
    "    #Convert 2d array to Dataframe\n",
    "    y = pd.DataFrame(aa, columns=list('N'))\n",
    "    y.head()\n",
    "    y = aa.astype(int).ravel()\n",
    "    print ( y )\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             T           L  Lg  Lt  Ls  Lb           S  Sg  St  Ss ...  \\\n",
      "1547  20181217  300.014568   7   5   3   3  359.526457   6   3   7 ...   \n",
      "1548  20181220  302.236280   7   5  12  11   40.189495   4   2   2 ...   \n",
      "1549  20181224  305.200567   7   5   1   6   98.931481   2   7   4 ...   \n",
      "1550  20181227  307.425821   7  11  11   7  142.704093   1   4   7 ...   \n",
      "1551  20181231  310.396111   7  11   6  11  197.112557   4  11   4 ...   \n",
      "\n",
      "               U  Ug  Ut  Us  Ub           K  Kg  Kt  Ks  Kb  \n",
      "1547  255.692043   6   4   1  11  274.279218   7   1   7   2  \n",
      "1548  256.040966   6   4   1   3  274.120357   7   1   7   1  \n",
      "1549  256.509451   6   4   2  11  273.908541   7   1   7   4  \n",
      "1550  256.862581   6   4   2   7  273.749679   7   1   7  12  \n",
      "1551  257.334785   6   4   5   5  273.537864   7   1   7   3  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "1521\n",
      "[[ 3. 10. 18. ... 29. 36. 42.]\n",
      " [ 6.  8. 22. ... 40. 41. 45.]\n",
      " [ 5.  8. 15. ... 21. 35. 36.]\n",
      " ...\n",
      " [ 8. 10. 16. ... 30. 37. 44.]\n",
      " [ 7. 13. 21. ... 29. 35. 37.]\n",
      " [ 5. 17. 24. ... 45. 46. 49.]]\n",
      "[[ 3. 10. 18. ... 29. 36. 42.]\n",
      " [ 6.  8. 22. ... 40. 41. 45.]\n",
      " [ 5.  8. 15. ... 21. 35. 36.]\n",
      " ...\n",
      " [ 8. 10. 16. ... 30. 37. 44.]\n",
      " [ 7. 13. 21. ... 29. 35. 37.]\n",
      " [ 5. 17. 24. ... 45. 46. 49.]]\n",
      "[3 6 5 ... 8 7 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pp = pd.read_csv('../input/PPv3.csv')\n",
    "print(pp.tail())\n",
    "\n",
    "lr = pd.read_csv('../input/SGH.csv')\n",
    "#print(lr.describe())\n",
    "\n",
    "#print(lr)\n",
    "\n",
    "#print(len(lr))\n",
    "#lr = lr.sort_values(by=['D'])\n",
    "#lr = lr.drop_duplicates () ;\n",
    "print(len(lr))\n",
    "cols = ['D', 'N1','N2','N3','N4','N5','N6','N7']\n",
    "lr = lr[cols]\n",
    "#print(lr.head(30))\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "df = pd.concat([pp, lr], axis=1, sort=False)\n",
    "df = df.dropna()\n",
    "#print(len(df))\n",
    "#df.head()\n",
    "df.reset_index().drop(['D'], axis=1)\n",
    "\n",
    "cols = ['N1','N2','N3','N4','N5','N6','N7']\n",
    "lr = df[cols]\n",
    "\n",
    "\n",
    "# cols = ['L','M','S','R','E','A','V' ,'J','U']\n",
    "# cols = ['L', 'M', 'R', 'J', 'U']\n",
    "# X = df[cols]\n",
    "\n",
    "X = df\n",
    "#Remove T, D and Results\n",
    "drop_cols = ['T','D','N1','N2','N3','N4','N5','N6','N7','L','M','S','R','E','A','V' ,'J','U','K']\n",
    "X = X.drop(drop_cols, axis=1)\n",
    "related_X = X\n",
    "dataset = related_X\n",
    "\n",
    "lresult = np.sort(lr.values[:, ::-1])\n",
    "print(lresult)\n",
    "\n",
    "loadResult(1) # interested in column 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3. 10. 18. ... 29. 36. 42.]\n",
      " [ 6.  8. 22. ... 40. 41. 45.]\n",
      " [ 5.  8. 15. ... 21. 35. 36.]\n",
      " ...\n",
      " [ 8. 10. 16. ... 30. 37. 44.]\n",
      " [ 7. 13. 21. ... 29. 35. 37.]\n",
      " [ 5. 17. 24. ... 45. 46. 49.]]\n",
      "[3 6 5 ... 8 7 5]\n",
      "(1368, 40) (1368,)\n",
      "(153, 40) (153,)\n",
      "1368\n",
      "0.0\n",
      "Removing invalid predictions ( < 0 )\n",
      "1368\n",
      "1368\n",
      "0.0\n",
      "[ 6  5  1 10  2  7  6  4  5  1  5  4  1  1  4  1 17 12  7  2  1  5  1  1\n",
      "  1 16  1  9  7  2  2  5  7  4  4  4  6  4  1  5  3  1  1  2 27 11  2 27\n",
      "  8 15  2  9  2 14  6 15 11  2  7  8  8  6  9  6  2  7  2  1  8  2  5  2\n",
      "  2  6  2  8  6  6 10 10  7  6  6  8  8  6  8 11  6  2  6  8  5  6  6  6\n",
      "  2  4  7  8  7  1  7  6  5  2  1  1  1  1  6  1  4  1  4  2 12  8  8  6\n",
      "  6  2 13  2  4 13  4  4  1  2  2  7  1  2  2  7  5 13  7  1  8  5  6  8\n",
      "  1  4 15  3  3  4  5  3  3]\n",
      "[24  1 10 13  7  3  2  2  4  8  4  1  8  5  4 21  3 13  2 15  1  9 20  1\n",
      "  4 14  2  5  2 11 12  9  8  2 14 11 14  5  1  2 11  4 11  1  3 10 13  2\n",
      " 12  3  2  7 10  1  9  6  6  3  2  2  3  8  7  2 22  3 11  9 11  7 17  4\n",
      "  9  5  1  2  1  6  1  3  3  6  3  1  2  1  1  7  4 25  8  3  1 10  4  4\n",
      " 24  6  2  2  9  3  5  6 10  3  3 18  1  1 18  1  5  7  8  2  4  1  6  2\n",
      "  2  3  3  5  2  2 20  1 13  7  1  7  1  2 13  4  4  6  8 12  2  4 11  1\n",
      " 16 12 20 11  2 11  8  7  5]\n",
      "153\n",
      "7.57177624228842\n",
      "Removing invalid predictions ( < 0 )\n",
      "153\n",
      "15\n",
      "7.57177624228842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y = loadResult(1)\n",
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y.astype(int), test_size=0.1, shuffle=False)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "classifier = DecisionTreeClassifier()  \n",
    "m = classifier.fit(X_train, y_train)  \n",
    "\n",
    "ytrainPredicted = m.predict(X_train)\n",
    "\n",
    "iM = getAccuracy1dCount(y_train, ytrainPredicted) \n",
    "print(np.std(ytrainPredicted-y_train))\n",
    "getStdDeviationOfPrediction(ytrainPredicted,y_train)\n",
    "\n",
    "ytestPredicted = m.predict(X_test)\n",
    "#ytestPredicted = m.predict(X_test).astype(int) #, [list(item) for item in y_train])\n",
    "\n",
    "print(ytestPredicted)\n",
    "print(y_test)\n",
    "\n",
    "iM = getAccuracy1dCount(y_test, ytestPredicted)\n",
    "print(np.std(ytestPredicted-y_test))\n",
    "getStdDeviationOfPrediction(ytestPredicted,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
