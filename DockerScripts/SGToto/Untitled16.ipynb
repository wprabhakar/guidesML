{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import utils, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from matplotlib.pyplot import figure\n",
    "from functools import reduce\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "\n",
    "\n",
    "\n",
    "class UnionIntersection:\n",
    "    \n",
    "    @classmethod\n",
    "    def __init__(self):\n",
    "        print('Loaded UnionIntersection ')\n",
    "\n",
    "    @classmethod\n",
    "    def getIntersection(df1, df2):\n",
    "        \n",
    "    def load_totodata(self, inputPPFile='../input/PPv4.csv', inputTotoResult='../input/SGH.csv'):\n",
    "        pp = pd.read_csv(inputPPFile)\n",
    "        lr = pd.read_csv(inputTotoResult)\n",
    "        print(len(lr))\n",
    "        cols = ['D', 'N1','N2','N3','N4','N5','N6','N7']\n",
    "        #lr = lr[cols]\n",
    "\n",
    "        result_sorted = -np.sort(-lr[cols].values, axis=1).astype(int)\n",
    "        result_df = pd.DataFrame(result_sorted, columns=['D','N1','N2','N3','N4','N5','N6','N7'])\n",
    "\n",
    "        lr = result_df\n",
    "        print(lr)\n",
    "\n",
    "        #https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "        df = pd.concat([pp, lr], axis=1, sort=False)\n",
    "        df = df.dropna()\n",
    "        df.reset_index().drop(['D'], axis=1)\n",
    "\n",
    "#         print(df.shape)\n",
    "#         counts = [df['N'+str(i)].value_counts() for i in range(1,8)]\n",
    "#         for i in range(len(counts)):\n",
    "#             df = df[~df['N'+str(i+1)].isin(counts[i][counts[i] <= 3].index)]\n",
    "#         print('After removing numbers that have shown 3 or less times')\n",
    "#         print(df.shape)\n",
    "\n",
    "        cols = ['N1','N2','N3','N4','N5','N6','N7']\n",
    "        lr = df[cols]\n",
    "\n",
    "        self.df = df\n",
    "        self.lresult = np.sort(lr.values[:, ::-1])\n",
    "        return self.lresult, self.df \n",
    "    \n",
    "    @classmethod\n",
    "    def modified_dataset ( self, dataset ):\n",
    "        self.dataset = dataset\n",
    "        return self.dataset\n",
    "    \n",
    "    @classmethod\n",
    "    def get_result_n(self, col_n):\n",
    "        aa = np.delete(self.lresult, np.s_[col_n:], axis=1)  \n",
    "        aa = np.delete(aa, np.s_[0:col_n-1], axis=1)  \n",
    "        return pd.DataFrame(aa, columns=list('N'))\n",
    "\n",
    "    @classmethod\n",
    "    def get_result_n_encoded(self, col_n):\n",
    "        aa = np.delete(self.lresult, np.s_[col_n:], axis=1)  \n",
    "        aa = np.delete(aa, np.s_[0:col_n-1], axis=1)  \n",
    "        # 1. INSTANTIATE\n",
    "        enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "        # 2. FIT\n",
    "        enc.fit(aa)\n",
    "\n",
    "        # 3. Transform\n",
    "        onehotlabels = enc.transform(aa).toarray()\n",
    "        onehotlabels.shape\n",
    "        #print(onehotlabels)\n",
    "\n",
    "        #Convert 2d array to Dataframe\n",
    "        y = pd.DataFrame(aa, columns=list('N'))\n",
    "        y.head()\n",
    "        y = aa.astype(int).ravel()\n",
    "    #    print ( y )\n",
    "        return y\n",
    "        \n",
    "    @classmethod\n",
    "    def get_test_data(self, file_name = '../input/PPv4-Predict.csv' ):\n",
    "        self.data2Predict = pd.read_csv(file_name)\n",
    "        self.data2Predict.reset_index()\n",
    "        return self.data2Predict\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def plot_history(self, history):\n",
    "        loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "        val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "        acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "        val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "\n",
    "        if len(loss_list) == 0:\n",
    "            print('Loss is missing in history')\n",
    "            return \n",
    "\n",
    "        ## As loss always exists\n",
    "        epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "\n",
    "        ## Loss\n",
    "        figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "        plt.figure(1)\n",
    "        for l in loss_list:\n",
    "            plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "        for l in val_loss_list:\n",
    "            plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        ## Accuracy\n",
    "        plt.figure(1)\n",
    "        for l in acc_list:\n",
    "            plt.plot(epochs, history.history[l], 'r', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "        for l in val_acc_list:    \n",
    "            plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    @classmethod\n",
    "    def save_model(self, model, predict_number):\n",
    "        # serialize model to JSON\n",
    "        model_json = model.to_json()\n",
    "        with open(str(self.algo_number) + '_' + str(predict_number) + \"_model.json\", \"w\") as json_file:\n",
    "            json_file.write(simplejson.dumps(simplejson.loads(model_json), indent=4))\n",
    "\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(str(self.algo_number) + '_' + str(predict_number) + \"_model.h5\")\n",
    "        print(\"Saved model to disk \", self.algo_number, \" Predict #N \", predict_number)\n",
    "\n",
    "    @classmethod\n",
    "    def print_result(self, predicted_values ):\n",
    "        test_df = pd.read_csv('../input/TestResult.csv', sep='\\s+', header=None, names=['D','N1','N2','N3','N4','N5','N6','N7'])\n",
    "        test_df['D'].replace(regex=True,inplace=True,to_replace=r'-',value=r'')\n",
    "        test_df['D'] = pd.to_numeric(test_df['D'])\n",
    "\n",
    "        cols = ['D', 'N1','N2','N3','N4','N5','N6','N7']\n",
    "        test_df = self.data2Predict.merge(test_df, left_on='T', right_on='D', how='inner')\n",
    "        test_df = test_df[cols]\n",
    "\n",
    "        tdfResult = predicted_values.drop(predicted_values.columns[0], axis=1) ;\n",
    "\n",
    "        \n",
    "        actual_result = test_df[cols[1:]].values\n",
    "        predicted_result = np.unique(tdfResult.values)\n",
    "        predicted_result = [np.unique(a) for a in tdfResult.values]\n",
    "\n",
    "        matched = self.getIntersection(actual_result, predicted_result)\n",
    "\n",
    "        c = 0\n",
    "        for i in range(len(matched)):\n",
    "            print(int(self.data2Predict.loc[i]['T']), '<', len(predicted_result[i]), '> ', actual_result[i], ' **', matched[c], '** ', predicted_result[i])\n",
    "            c += 1\n",
    "        for i in range(c, len(predicted_result)):\n",
    "            print(int(self.data2Predict.loc[i]['T']), ' Predicted: ', predicted_result[i], ' ')\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(self, predict_number):\n",
    "        json_file = open(str(self.algo_number) + \"_\" + str(predict_number)+'_model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(str(self.algo_number) + \"_\" + str(predict_number)+\"_model.h5\")\n",
    "        print(\"Loaded model from disk \" + str(self.algo_number) + \"_\" + str(predict_number) + \"_model\" )\n",
    "        return loaded_model\n",
    "\n",
    "    @classmethod\n",
    "    def getTargets(self):\n",
    "        return np.array([self.get_result_n(i)['N'] for i in range(1,8)]).T\n",
    "\n",
    "    @classmethod\n",
    "    def getTarget(self, N):\n",
    "        return ([self.get_result_n(i)['N'] for i in range(1,8)])[N-1]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def getIntersection(p1, p2):\n",
    "        return [reduce(np.intersect1d, (p.astype(int), a.astype(int))) for (p,a) in zip(p1, p2)]\n",
    "\n",
    "    @classmethod\n",
    "    def get_test_result(self, result='../input/TestResult.csv'):\n",
    "        #load the test Toto Results files\n",
    "        test_df = pd.read_csv(result, sep='\\s+', header=None, names=['D','N1','N2','N3','N4','N5','N6','N7'])\n",
    "        test_df['D'].replace(regex=True,inplace=True,to_replace=r'-',value=r'')\n",
    "        test_df['D'] = pd.to_numeric(test_df['D'])\n",
    "\n",
    "        #Merge the Planet Position File with the Toto Results file\n",
    "        test_df = self.data2Predict.merge(test_df, left_on='T', right_on='D', how='inner')\n",
    "\n",
    "        #Extract only the Results for all dates\n",
    "        cols = ['D', 'N1','N2','N3','N4','N5','N6','N7']\n",
    "        test_df = test_df[cols]\n",
    "\n",
    "        actual_result = test_df[cols[1:]].values\n",
    "        return actual_result\n",
    "        \n",
    "    @classmethod\n",
    "    def get_matched_intersection(self, df_prediction1, df_prediction2):\n",
    "        intersected_values = (self.getIntersection(np.array(df_prediction1), np.array(df_prediction2)))\n",
    "        return list(self.getIntersection(self.get_test_result(), intersected_values))\n",
    "        \n",
    "    @classmethod\n",
    "    def getAccuracyCount(self, prediction):\n",
    "        actual = self.get_test_result()\n",
    "        matched = []\n",
    "        if len(prediction) == 0: return 0\n",
    "        for (p,a) in zip(prediction, actual):\n",
    "    #        print ( \"p: \", p, \" a: \", a, (set(p.astype(int)) & set(a)) )\n",
    "            matched.append((set(p.astype(int)) & set(a)))\n",
    "        return sum(len(num) > 0 for num in matched)/len(matched)*100.00\n",
    "\n",
    "    @classmethod\n",
    "    def print_weighted_numbers(self, dfPredictions):\n",
    "        matched = []\n",
    "        for (p,a) in zip(dfPredictions, self.get_test_result()):\n",
    "    \t      matched.append(len(set(p.astype(int)) & set(a)))\n",
    "        weighted_match = [(1+2*(N/10)) for N in matched]\n",
    "        return matched, weighted_match\n",
    "\n",
    "    @staticmethod\n",
    "    def bins_labels(bins, **kwargs):\n",
    "        bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "        plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "        plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "    @classmethod\n",
    "    def plot_matched_counts(self, predicted):\n",
    "        matched = []\n",
    "        for (p,a) in zip(predicted, self.get_test_result()):\n",
    "            matched.append(len(set(p.astype(int)) & set(a)))\n",
    "        bins = np.arange(8) - 0.5\n",
    "        plt.hist(matched, bins, rwidth=0.8)\n",
    "        plt.xticks(range(8))\n",
    "        plt.xlim([-1, 8])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def print_predictions(self, dfPredictions):\n",
    "        actual_result = self.get_test_result()\n",
    "#         #load the test Toto Results files\n",
    "#         test_df = pd.read_csv(result, sep='\\s+', header=None, names=['D','N1','N2','N3','N4','N5','N6','N7'])\n",
    "#         test_df['D'].replace(regex=True,inplace=True,to_replace=r'-',value=r'')\n",
    "#         test_df['D'] = pd.to_numeric(test_df['D'])\n",
    "\n",
    "#         #Merge the Planet Position File with the Toto Results file\n",
    "#         test_df = self.data2Predict.merge(test_df, left_on='T', right_on='D', how='inner')\n",
    "\n",
    "#         #Extract only the Results for all dates\n",
    "#         cols = ['D', 'N1','N2','N3','N4','N5','N6','N7']\n",
    "#         test_df = test_df[cols]\n",
    "\n",
    "        tdfResult = dfPredictions.drop(dfPredictions.columns[0], axis=1) ;\n",
    "\n",
    "#         actual_result = test_df[cols[1:]].values\n",
    "        predicted_result = tdfResult.values\n",
    "\n",
    "        matched = MyTotoResearch.getIntersection(actual_result, predicted_result)\n",
    "\n",
    "        c = 0\n",
    "        for i in range(len(matched)):\n",
    "            print(int(self.data2Predict.loc[i]['T']), ' ', actual_result[i], ' ', predicted_result[i], ' ', matched[c])\n",
    "            c += 1\n",
    "        for i in range(c, len(predicted_result)):\n",
    "            print(int(self.data2Predict.loc[i]['T']), ' Predicted: ', predicted_result[i], ' ')\n",
    "\n",
    "            \n",
    "def getAdjustedDataF(df,f):\n",
    "    #Use only Planet Positions Testing\n",
    "    cols = ['L','M','S', 'R','E','A','V' ,'J','U','K']\n",
    "    X = df[cols]\n",
    "    deg = f\n",
    "    \n",
    "#     X['S_3'] = X['S'] // (deg*3)\n",
    "#     X['L_3'] = X['L'] // (deg*3)\n",
    "#     X['M_3'] = X['M'] // (deg*3)\n",
    "#     X['R_3'] = X['R'] // (deg*3)\n",
    "#     X['E_3'] = X['E'] // (deg*3)\n",
    "#     X['A_3'] = X['A'] // (deg*3)\n",
    "#     X['V_3'] = X['V'] // (deg*3)\n",
    "#     X['J_3'] = X['J'] // (deg*3)\n",
    "#     X['U_3'] = X['U'] // (deg*3)\n",
    "\n",
    "\n",
    "#     X['S_2'] = X['S'] // (deg*2)\n",
    "#     X['L_2'] = X['L'] // (deg*2)\n",
    "#     X['M_2'] = X['M'] // (deg*2)\n",
    "#     X['R_2'] = X['R'] // (deg*2)\n",
    "#     X['E_2'] = X['E'] // (deg*2)\n",
    "#     X['A_2'] = X['A'] // (deg*2)\n",
    "#     X['V_2'] = X['V'] // (deg*2)\n",
    "#     X['J_2'] = X['J'] // (deg*2)\n",
    "#     X['U_2'] = X['U'] // (deg*2)\n",
    "\n",
    "    X['S_1'] = X['S'] // (deg)\n",
    "    X['L_1'] = X['L'] // (deg)\n",
    "    X['M_1'] = X['M'] // (deg)\n",
    "    X['R_1'] = X['R'] // (deg)\n",
    "    X['E_1'] = X['E'] // (deg)\n",
    "    X['A_1'] = X['A'] // (deg)\n",
    "    X['V_1'] = X['V'] // (deg)\n",
    "    X['J_1'] = X['J'] // (deg)\n",
    "    X['U_1'] = X['U'] // (deg)\n",
    "   \n",
    "    X = X.drop(cols, axis=1)\n",
    "    return X\n",
    "\n",
    "print(\"Done.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
