{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# Load and split the data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_lr_pca = Pipeline([('scl', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_rf_pca = Pipeline([('scl', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', svm.SVC(random_state=42))])\n",
    "\n",
    "pipe_svm_pca = Pipeline([('scl', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)),\n",
    "            ('clf', svm.SVC(random_state=42))])\n",
    "\n",
    "# Set grid search params\n",
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "\n",
    "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__C': param_range_fl,\n",
    "        'clf__solver': ['liblinear']}] \n",
    "\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
    "        'clf__min_samples_leaf': param_range,\n",
    "        'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range[1:]}]\n",
    "\n",
    "grid_params_svm = [{'clf__kernel': ['linear', 'rbf'], \n",
    "        'clf__C': param_range}]\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=pipe_lr,\n",
    "            param_grid=grid_params_lr,\n",
    "            scoring='accuracy',\n",
    "            cv=10) \n",
    "\n",
    "gs_lr_pca = GridSearchCV(estimator=pipe_lr_pca,\n",
    "            param_grid=grid_params_lr,\n",
    "            scoring='accuracy',\n",
    "            cv=10)\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "            param_grid=grid_params_rf,\n",
    "            scoring='accuracy',\n",
    "            cv=10, \n",
    "            n_jobs=jobs)\n",
    "\n",
    "gs_rf_pca = GridSearchCV(estimator=pipe_rf_pca,\n",
    "            param_grid=grid_params_rf,\n",
    "            scoring='accuracy',\n",
    "            cv=10, \n",
    "            n_jobs=jobs)\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "            param_grid=grid_params_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=10,\n",
    "            n_jobs=jobs)\n",
    "\n",
    "gs_svm_pca = GridSearchCV(estimator=pipe_svm_pca,\n",
    "            param_grid=grid_params_svm,\n",
    "            scoring='accuracy',\n",
    "            cv=10,\n",
    "            n_jobs=jobs)\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_lr_pca, gs_rf, gs_rf_pca, gs_svm, gs_svm_pca]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Logistic Regression', 1: 'Logistic Regression w/PCA', \n",
    "        2: 'Random Forest', 3: 'Random Forest w/PCA', \n",
    "        4: 'Support Vector Machine', 5: 'Support Vector Machine w/PCA'}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    gs.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])\n",
    "\n",
    "# Save best grid search pipeline to file\n",
    "dump_file = 'best_gs_pipeline.pkl'\n",
    "joblib.dump(best_gs, dump_file, compress=1)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], dump_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "1. Load Data\n",
    "2. Clean Data\n",
    "3. Run PCA with different n_components to select the best\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline with PCA & GridSearch\n",
    "#https://www.kaggle.com/gaborvecsei/pipeline-pca-gridsearch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add PCA Visualization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "pca_2d = PCA(n_components=2)\n",
    "Z_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.scatter(Z_2d[y_train==0, 0], Z_2d[y_train==0, 1], label='isFraud: 0')\n",
    "ax.scatter(Z_2d[y_train==1, 0], Z_2d[y_train==1, 1], label='isFraud: 1')\n",
    "ax.set(title='PCA 2-d projection', xlabel='Z[0]', ylabel='Z[1]')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. split into training and test sets\n",
    "# 2. do PCA\n",
    "# 3. fit on train set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pca = PCA(n_components=150)\n",
    "Z_train = pca.fit_transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model_pca = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model_pca.fit(Z_train, y_train)\n",
    "\n",
    "# 4. Compare scores on test set\n",
    "Z_test = pca.transform(X_test) # not re-fitting PCA\n",
    "\n",
    "print('Accuracy (PCA)', model_pca.score(Z_test, y_test))\n",
    "\n",
    "print('Accuracy (no PCA)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(model):\n",
    "    # 3-fold cross validation to get learning curve R2 scores\n",
    "    # using default train_sizes\n",
    "    train_sizes, train_scores, val_scores = learning_curve(model,\n",
    "                                                           Z_train, \n",
    "                                                           y_train, cv=3)\n",
    "\n",
    "    # plot learning curve:\n",
    "    #   plot train_scores vs. train_sizes\n",
    "    #   plot val_scores vs. train_sizes\n",
    "    # train_sizes is the number of training samples used for training\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(train_sizes, train_scores.mean(axis=1),\n",
    "            label='train') # average for 5-folds\n",
    "    ax.plot(train_sizes, val_scores.mean(axis=1),\n",
    "            label='val')\n",
    "    ax.legend()\n",
    "    ax.set(title='Learning curve', xlabel='Train size', ylabel='R2')\n",
    "    return train_sizes, train_scores, val_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8f6e62aef012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# - cross validate (trains models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m scores = cross_validate(model, Z_train, y_train, cv=5,\n\u001b[0m\u001b[1;32m     10\u001b[0m                         return_train_score=True, return_estimator=True)\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_validate' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "\n",
    "# Cross Validate\n",
    "# SGDRegressor.learning_rate\n",
    "model = SVC(max_iter=1000, tol=1e-3,\n",
    "                     random_state=8)\n",
    "\n",
    "# - cross validate (trains models)\n",
    "scores = cross_validate(model, Z_train, y_train, cv=5,\n",
    "                        return_train_score=True, return_estimator=True)\n",
    "# scores\n",
    "\n",
    "# - learning curve (plot for overfit / underfit)\n",
    "train_sizes, train_scores, val_scores = plot_learning_curve(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "# Use GridSearchCV to automate finding the best combination\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameters to try:\n",
    "# learning_rate='invscaling'\n",
    "#  'constant' with eta0=1e-1\n",
    "#  'constant' with eta0=1e-4,\n",
    "#  'optimal' with default eta0\n",
    "params = {\n",
    "    'learning_rate' : ['invscaling', 'constant', 'optimal'],\n",
    "    'eta0' : [0.01, 1e-1, 1e-4]\n",
    "}\n",
    "\n",
    "# consider setting n_jobs to run more in parallel if too slow\n",
    "gs = GridSearchCV(model, params, cv=3, return_train_score=True)\n",
    "gs.fit(Z_train, y_train)\n",
    "\n",
    "print(gs.best_score_) # best score of 9 models\n",
    "print(gs.best_params_) # best parameters\n",
    "gs.best_estimator_ # best of 9 models (9 combinations of params)```\n",
    "\n",
    "results_df = pd.DataFrame(gs.cv_results_)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "y_pred = model.predict(Z_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')\n",
    "ax.set(xlabel='Prediction', ylabel='Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Learning Curve\n",
    "fig, axes = plt.subplots(nrows=6, ncols=2, figsize=(10, 30))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    params = results_df.params.values[i]\n",
    "    model = SGDRegressor(max_iter=1000, tol=1e-3,\n",
    "                         random_state=8,\n",
    "                         learning_rate=params['learning_rate'],\n",
    "                         eta0=params['eta0'])\n",
    "    train_sizes, train_scores, val_scores = learning_curve(model,\n",
    "                                                       Z_train, \n",
    "                                                       y_train, cv=3)\n",
    "\n",
    "    ax = axes[i]\n",
    "    ax.plot(train_sizes, train_scores.mean(axis=1), label='train')\n",
    "    ax.plot(train_sizes, val_scores.mean(axis=1), label='val')\n",
    "    ax.legend()\n",
    "    ax.set(title=str(params), xlabel='Train size', ylabel='R2')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot ROC / AUC \n",
    "prob_sgd = sgd.decision_function(Z_test)\n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(y_test, prob_sgd)\n",
    "auc_sgd = auc(fpr_sgd, tpr_sgd)\n",
    "\n",
    "prob_svc = svc.decision_function(Z_test)\n",
    "fpr_svc, tpr_svc, _ = roc_curve(y_test, prob_svc)\n",
    "auc_svc = auc(fpr_svc, tpr_svc)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(fpr_sgd, tpr_sgd, label='Logistic Regression (auc %.3f)' % auc_sgd)\n",
    "ax.plot(fpr_svc, tpr_svc, label='SVC (auc %.3f)' % auc_svc)\n",
    "ax.set(xlabel='False positive rate', ylabel='True positive rate', title='ROC curve')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = []\n",
    "\n",
    "# all_models.append(('LR', (LogisticRegression(random_state=seed))))\n",
    "\n",
    "all_models.append(('KNNC', KNeighborsClassifier()))\n",
    "all_models.append(('KNNR', KNeighborsRegressor()))\n",
    "\n",
    "for name, model in all_models:\n",
    "    \n",
    "    X = x_train\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    \n",
    "    Z = scaler.transform(X)\n",
    "    \n",
    "#    scaler = None\n",
    "#    Z = X\n",
    "\n",
    "#     kfold = model_selection.KFold(n_splits=3, random_state=seed)\n",
    "#     cv_results = model_selection.cross_val_score(model, Z, mtr.getTarget(3), cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)\n",
    "    \n",
    "    oClassifier = MultiOutputClassifier(model, n_jobs=7)\n",
    "    oClassifier.fit(Z, mtr.getTargets()) \n",
    "    print(oClassifier)\n",
    "    s = oClassifier.score(Z, mtr.getTargets())\n",
    "    if(oClassifier.score(Z, mtr.getTargets()) == 1.0):\n",
    "        print( name, ' ', str(f), ' ', str(s))\n",
    "    store_prediction(mtr, oClassifier, f, scaler=scaler, name=name)\n",
    "    start = time.clock()\n",
    "    print(str(f), \" Time taken: \", (time.clock() - start),  \" \")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
