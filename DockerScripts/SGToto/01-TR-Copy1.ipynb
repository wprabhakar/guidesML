{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py:923: DeprecationWarning: builtin type EagerTensor has no __module__ attribute\n",
      "  EagerTensor = c_api.TFE_Py_InitEagerTensor(_EagerTensorBase)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4785: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/walter/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
      "  _config = json.load(open(_config_path))\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!conda install -n mldds -c anaconda joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Cores: \", num_cores)\n",
    "\n",
    "import time\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': num_cores} )\n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from MyTotoResearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'D', 'N1','N2','N3','N4','N5','N6','N7','L','M','S','R','E','A','V' ,'J','U','K']\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_prediction(mrt, model, f, scaler=None, name='unnamed'):\n",
    "    def getAllData(df):\n",
    "        drop_cols = ['T', 'L','M','S','R','E','A','V' ,'J','U','K']\n",
    "        X = df.drop(drop_cols, axis=1)\n",
    "        return X\n",
    "\n",
    "    test_data = mtr.get_test_data()\n",
    "    X = mtr.modified_dataset(getAllData(test_data)) #\n",
    "#    X = getAdjustedDataF(test_data,f)\n",
    "\n",
    "\n",
    "    if ( scaler == None ):\n",
    "        Z = X\n",
    "    else:\n",
    "        scaler.fit(X)\n",
    "        Z = scaler.transform(X)\n",
    "\n",
    "    predictions = model.predict(Z)\n",
    "\n",
    "    dfResult= pd.DataFrame(predictions, columns=['N1', 'N2', 'N3', 'N4', 'N5','N6', 'N7'])\n",
    "#    mtr.print_predictions(dfResult)\n",
    "\n",
    "    global df_predictions\n",
    "    global prev_r\n",
    "    r = mtr.getAccuracyCount(np.array(dfResult)) ;\n",
    "#    if ( r > prev_r ):\n",
    "#        df_predictions = []\n",
    "    df_predictions.append(dfResult)\n",
    "    g_all_pred.update({name : dfResult})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MyTotoResearch algo_no:  1\n",
      "1521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from keras.models import Input, Model\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "import json as simplejson\n",
    "from keras import regularizers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier, LogisticRegression, PassiveAggressiveClassifier, Perceptron, RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, Ridge, RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "seed = 42\n",
    "\n",
    "mtr = MyTotoResearch(algo_no=1)\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "df_predictions = []\n",
    "\n",
    "\n",
    "all_models = []\n",
    "\n",
    "all_models.append(('SVCpoly01', SVC(kernel='poly', coef0=0.05, probability=True, degree=2, random_state=seed)))\n",
    "all_models.append(('SVCrbf010', SVC(kernel='rbf', coef0=0.75, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf011', SVC(kernel='rbf', coef0=0.5, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf012', SVC(kernel='rbf', coef0=0.25, probability=True, degree=2, random_state=seed)))\n",
    "\n",
    "# all_models.append(('SVCrbf0103', SVC(kernel='rbf', coef0=0.75, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0113', SVC(kernel='rbf', coef0=0.5, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0123', SVC(kernel='rbf', coef0=0.25, probability=True, degree=3, random_state=seed)))\n",
    "\n",
    "\n",
    "all_models.append(('SVCrbf020', SVC(kernel='sigmoid', coef0=0.75, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf021', SVC(kernel='sigmoid', coef0=0.5, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf022', SVC(kernel='sigmoid', coef0=0.25, probability=True, degree=2, random_state=seed)))\n",
    "\n",
    "# all_models.append(('SVCrbf0203', SVC(kernel='sigmoid', coef0=0.75, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0213', SVC(kernel='sigmoid', coef0=0.5, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0223', SVC(kernel='sigmoid', coef0=0.25, probability=True, degree=3, random_state=seed)))\n",
    "\n",
    "\n",
    "# all_models.append(('SVCrbf030', SVC(kernel='linear', coef0=0.75, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf031', SVC(kernel='linear', coef0=0.5, probability=True, degree=2, random_state=seed)))\n",
    "# all_models.append(('SVCrbf032', SVC(kernel='linear', coef0=0.25, probability=True, degree=2, random_state=seed)))\n",
    "\n",
    "# all_models.append(('SVCrbf0303', SVC(kernel='linear', coef0=0.75, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0313', SVC(kernel='linear', coef0=0.5, probability=True, degree=3, random_state=seed)))\n",
    "# all_models.append(('SVCrbf0323', SVC(kernel='linear', coef0=0.25, probability=True, degree=3, random_state=seed)))\n",
    "\n",
    "\n",
    "\n",
    "# all_models.append(('LR', (LogisticRegression(random_state=seed))))\n",
    "\n",
    "all_models.append(('KNNC', KNeighborsClassifier()))\n",
    "#all_models.append(('KNNR', KNeighborsRegressor()))\n",
    "all_models.append(('RC', RidgeClassifier(random_state=seed)))\n",
    "# all_models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "# all_models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# all_models.append(('DTR', DecisionTreeRegressor()))\n",
    "# all_models.append(('ETR', ExtraTreesRegressor(n_estimators=5)))\n",
    "all_models.append(('ETC', ExtraTreesClassifier(n_estimators=5)))\n",
    "# all_models.append(('EN', ElasticNet()))\n",
    "all_models.append(('CART', DecisionTreeClassifier()))\n",
    "# all_models.append(('NB', GaussianNB()))\n",
    "# all_models.append(('Lasso', Lasso()))\n",
    "# all_models.append(('GBR', GradientBoostingRegressor()))\n",
    "all_models.append(('RFR5', RandomForestClassifier(n_estimators=5, n_jobs=5, random_state=seed)))\n",
    "# all_models.append(('RFR5', RandomForestClassifier(n_estimators=5, n_jobs=5, random_state=seed)))\n",
    "# all_models.append(('RFR3', RandomForestRegressor(n_estimators=3, n_jobs=5, random_state=seed)))\n",
    "# all_models.append(('SGDR', SGDRegressor(random_state=seed)))\n",
    "all_models.append(('AdaB', AdaBoostClassifier(RandomForestClassifier(n_estimators=3))))\n",
    "# #all_models.append(('MLPC', MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.05,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
      "  kernel='poly', max_iter=-1, probability=True, random_state=42,\n",
      "  shrinking=True, tol=0.001, verbose=False),\n",
      "           n_jobs=7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  Time taken:  1.100000000064938e-05  \n",
      "MultiOutputClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.75,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=True, random_state=42,\n",
      "  shrinking=True, tol=0.001, verbose=False),\n",
      "           n_jobs=7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  Time taken:  8.000000001118224e-06  \n",
      "MultiOutputClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.75,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
      "  kernel='sigmoid', max_iter=-1, probability=True, random_state=42,\n",
      "  shrinking=True, tol=0.001, verbose=False),\n",
      "           n_jobs=7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  Time taken:  9.999999999621423e-06  \n",
      "MultiOutputClassifier(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "           n_jobs=7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  Time taken:  9.999999999621423e-06  \n",
      "MultiOutputClassifier(estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=42, solver='auto',\n",
      "        tol=0.001),\n",
      "           n_jobs=7)\n",
      "1.0  Time taken:  8.999999998593466e-06  \n",
      "MultiOutputClassifier(estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
      "           n_jobs=7)\n",
      "ETC   1.0   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  Time taken:  8.999999998593466e-06  \n",
      "MultiOutputClassifier(estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "           n_jobs=7)\n",
      "CART   1.0   1.0\n",
      "1.0  Time taken:  9.999999999621423e-06  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=5,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
      "           n_jobs=7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  Time taken:  9.00000000214618e-06  \n",
      "MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min...e=0,\n",
      "            warm_start=False),\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
      "           n_jobs=7)\n",
      "AdaB   1.0   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/walter/Software/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  Time taken:  7.000000000090267e-06  \n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "from sklearn import model_selection\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "g_all_pred = {}\n",
    "\n",
    "for name, model in all_models:\n",
    "    \n",
    "    X = mtr.modified_dataset(getAllData(df)) #\n",
    "    f = 1.0 #365/27.58\n",
    "#    X = getAdjustedDataF(df,f)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    Z = scaler.transform(X)\n",
    "    \n",
    "#    scaler = None\n",
    "#    Z = X\n",
    "\n",
    "#     kfold = model_selection.KFold(n_splits=3, random_state=seed)\n",
    "#     cv_results = model_selection.cross_val_score(model, Z, mtr.getTarget(3), cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)\n",
    "    \n",
    "    oClassifier = MultiOutputClassifier(model, n_jobs=7)\n",
    "    oClassifier.fit(Z, mtr.getTargets()) \n",
    "    print(oClassifier)\n",
    "    s = oClassifier.score(Z, mtr.getTargets())\n",
    "    if(oClassifier.score(Z, mtr.getTargets()) == 1.0):\n",
    "        print( name, ' ', str(f), ' ', str(s))\n",
    "    store_prediction(mtr, oClassifier, f, scaler=scaler, name=name)\n",
    "    start = time.clock()\n",
    "    print(str(f), \" Time taken: \", (time.clock() - start),  \" \")\n",
    "\n",
    "# for n in range(len(df_predictions)):\n",
    "#     print( mtr.getAccuracyCount(np.array(df_predictions[n])))\n",
    "#     mtr.print_predictions(df_predictions[n])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "# fig = plt.figure()\n",
    "# fig.suptitle('Algorithm Comparison')\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.boxplot(results)\n",
    "# ax.set_xticklabels(names)\n",
    "# plt.show()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import operator\n",
    "from itertools import islice\n",
    "\n",
    "top_n = 12\n",
    "\n",
    "all_pred = [] ;\n",
    "for i in range(len(df_predictions)):\n",
    "    if ( i == 0 ):\n",
    "        all_pred = df_predictions[i]\n",
    "    else:\n",
    "        all_pred = np.column_stack((all_pred, df_predictions[i]) )\n",
    "\n",
    "top_seven = []\n",
    "for i in range(len(all_pred)):\n",
    "    unique, counts = np.unique(all_pred[i], return_counts=True)\n",
    "    x = dict(zip(unique, counts))\n",
    "    sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True) # sorted by value\n",
    "    top_seven.append(list(islice([int(x) for x,y in sorted_x],top_n)))\n",
    "\n",
    "#print(top_seven)\n",
    "columns = ['N'+str(i+1) for i in range(top_n)]\n",
    "df_top_seven = pd.DataFrame(top_seven, columns=columns)\n",
    "r = mtr.getAccuracyCount(np.array(df_top_seven)) ;\n",
    "print ( \"Accuracy: \",  r)\n",
    "#print(df_top_seven)\n",
    "# matched = []\n",
    "# for (p,a) in zip(df_top_seven.values, mtr.get_test_result()):\n",
    "#     matched.append(len(set(p.astype(int)) & set(a)))\n",
    "# bins = np.arange(8) - 0.5\n",
    "# plt.hist(matched, bins, rwidth=0.8)\n",
    "# plt.xticks(range(8))\n",
    "# plt.xlim([-1, 8])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "mtr.plot_matched_counts(df_top_seven.values)\n",
    "\n",
    "\n",
    "#mtr.print_predictions(df_top_seven)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prediction(arr, initial_pred=[]):\n",
    "    global s\n",
    "    if ( isinstance(arr, list) ):\n",
    "        for a in arr:\n",
    "            combine_prediction(a, initial_pred)\n",
    "        return \n",
    "    if ( len(s) > 1 ):\n",
    "        s += '_'\n",
    "    s += arr\n",
    "    initial_pred.append(g_all_pred[arr])\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from itertools import combinations\n",
    "import operator \n",
    "from itertools import islice\n",
    "\n",
    "name_ = []\n",
    "\n",
    "lst = [name for name, model in all_models]\n",
    "iBestIndex = -1\n",
    "iBestN = []\n",
    "#print(\"List \", lst)\n",
    "top_n = 12\n",
    "\n",
    "\n",
    "dict_accuracy = {}\n",
    "for z in range(5, 0,-1):\n",
    "    a = [list(x) for x in itertools.combinations(lst, z) if len(x) > 1 ] \n",
    "#    print(a)\n",
    "\n",
    "    for xx in a:\n",
    "        test_pred = []\n",
    "        s = ''\n",
    "        combine_prediction(xx, test_pred)\n",
    "#        print(s)\n",
    "\n",
    "        #print(len(test_pred))\n",
    "\n",
    "        all_pred = [] ;\n",
    "        for i in range(len(test_pred)):\n",
    "            if ( i == 0 ):\n",
    "                all_pred = test_pred[i]\n",
    "            else:\n",
    "                all_pred = np.column_stack((all_pred, test_pred[i]) )\n",
    "\n",
    "        top_seven = []\n",
    "        for i in range(len(all_pred)):\n",
    "            unique, counts = np.unique(all_pred[i], return_counts=True)\n",
    "            x = dict(zip(unique, counts))\n",
    "            sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True) # sorted by value\n",
    "            l = list(islice([int(x) for x,y in sorted_x],top_n))\n",
    "            while ( len(l) < top_n ):\n",
    "                l.append(-1)\n",
    "\n",
    "            top_seven.append(l)\n",
    "            \n",
    "\n",
    "#        print(len(top_seven))\n",
    "#         if(len(top_seven[0]) < top_n ):\n",
    "#             print(\"*** Caught \", )\n",
    "        columns = ['N'+str(i+1) for i in range(len(top_seven[0]))]\n",
    "#        print(columns)\n",
    "        df_top_seven = pd.DataFrame(top_seven, columns=columns)\n",
    "        r = mtr.getAccuracyCount(np.array(df_top_seven)) ;\n",
    "        matched, weighted_match = mtr.print_weighted_numbers(df_top_seven.values)\n",
    "        r = sum(weighted_match)\n",
    "\n",
    "        dict_accuracy.update({s: r})\n",
    "\n",
    "t_accuracy = sorted(dict_accuracy.items(),key=operator.itemgetter(1), reverse=True)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 1, 1, 1, 0, 2, 2, 1, 2, 0, 0, 2, 0, 1, 2, 1, 7, 0, 1, 1, 1, 0, 1, 2, 1, 2, 1, 3, 3, 3, 3, 3, 2, 1, 2, 2, 3, 2, 2, 3, 1, 1, 3, 1, 3, 4, 2, 1, 2, 1, 1]\n",
      "[1.2, 1.4, 1.4, 1.2, 1.2, 1.2, 1.0, 1.4, 1.4, 1.2, 1.4, 1.0, 1.0, 1.4, 1.0, 1.2, 1.4, 1.2, 2.4, 1.0, 1.2, 1.2, 1.2, 1.0, 1.2, 1.4, 1.2, 1.4, 1.2, 1.6, 1.6, 1.6, 1.6, 1.6, 1.4, 1.2, 1.4, 1.4, 1.6, 1.4, 1.4, 1.6, 1.2, 1.2, 1.6, 1.2, 1.6, 1.8, 1.4, 1.2, 1.4, 1.2, 1.2]\n"
     ]
    }
   ],
   "source": [
    "matched, weighted_match = mtr.print_weighted_numbers(df_top_seven.values)\n",
    "print(matched)\n",
    "print(weighted_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CART_RFR5_AdaB', 73.80000000000003), ('SVCpoly01_ETC_CART', 73.8), ('RC_RFR5_AdaB', 73.60000000000002), ('SVCrbf020_CART_RFR5', 73.40000000000003), ('SVCrbf010_CART_RFR5', 73.40000000000002), ('RC_ETC_CART', 73.4), ('SVCpoly01_CART_RFR5', 73.2)]\n",
      "[['CART', 'RFR5', 'AdaB'], ['SVCpoly01', 'ETC', 'CART'], ['RC', 'RFR5', 'AdaB'], ['SVCrbf020', 'CART', 'RFR5'], ['SVCrbf010', 'CART', 'RFR5'], ['RC', 'ETC', 'CART'], ['SVCpoly01', 'CART', 'RFR5']]\n",
      "Accuracy:  94.33962264150944\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  92.45283018867924\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  86.79245283018868\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  96.22641509433963\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  92.45283018867924\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAC4xJREFUeJzt3FGIpfdZx/Hvr9mINm1pyk7C0iSOSggNgkkZViVQojE1NaWJF4UuNASpbC/akqAga2+qd3tj9UYKazZ2xTSlNg0NJtSGWIkFrZ2N0Wzc1NSwtdus2QlBknhTkj5ezLtlWHY7Z845s+/ZZ74fGM4577yz78OyfPed/znvm6pCknTxe8vYA0iS5sOgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqYteFPNju3btreXn5Qh5Ski56R48efbmqljbb74IGfXl5mdXV1Qt5SEm66CX53iT7ueQiSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTVzQK0U1vuUDj17wY544ePsFP6a0E3mGLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmNg16kquTfCPJ8STPJrln2P6uJI8neX54vHz7x5Uknc8kZ+hvAL9fVe8BfgX4RJLrgQPAE1V1LfDE8FqSNJJNg15Vp6rqqeH5a8Bx4N3AHcCRYbcjwJ3bNaQkaXNbWkNPsgzcCHwLuLKqTsF69IEr5j2cJGlyEwc9yduAh4B7q+rVLfzc/iSrSVbX1tammVGSNIGJgp7kUtZj/kBVfWXY/FKSPcP39wCnz/WzVXWoqlaqamVpaWkeM0uSzmGST7kEOAwcr6rPbvjWI8Ddw/O7ga/OfzxJ0qR2TbDPTcBdwDNJnh62fRo4CHwpyceA/wY+vD0jSpImsWnQq+qbQM7z7VvmO44kaVpeKSpJTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJjYNepL7k5xOcmzDtj9K8oMkTw9fv7W9Y0qSNjPJGfrngdvOsf1Pq+qG4eux+Y4lSdqqTYNeVU8Cr1yAWSRJM5hlDf2TSf59WJK5fG4TSZKmMm3QPwf8AnADcAr4k/PtmGR/ktUkq2tra1MeTpK0mamCXlUvVdWbVfUj4C+AvT9h30NVtVJVK0tLS9POKUnaxFRBT7Jnw8vfBo6db19J0oWxa7MdkjwI3AzsTnIS+Axwc5IbgAJOAB/fxhklSRPYNOhVte8cmw9vwyySpBl4pagkNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITm95tUdNZPvDoKMc9cfD2UY4raXyeoUtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITXimq0XlVrTQfnqFLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqYlNg57k/iSnkxzbsO1dSR5P8vzwePn2jilJ2swkZ+ifB247a9sB4ImquhZ4YngtSRrRpkGvqieBV87afAdwZHh+BLhzznNJkrZo2jX0K6vqFMDweMX8RpIkTWPb3xRNsj/JapLVtbW17T6cJO1Y0wb9pSR7AIbH0+fbsaoOVdVKVa0sLS1NeThJ0mamDfojwN3D87uBr85nHEnStCb52OKDwD8B1yU5meRjwEHg1iTPA7cOryVJI9q12Q5Vte8837plzrNIkmbglaKS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJamLXLD+c5ATwGvAm8EZVrcxjKEnS1s0U9MGvVdXLc/hzJEkzcMlFkpqYNegFfD3J0ST75zGQJGk6sy653FRVLya5Ang8yXNV9eTGHYbQ7we45pprZjycJOl8ZjpDr6oXh8fTwMPA3nPsc6iqVqpqZWlpaZbDSZJ+gqmDnuSyJG8/8xx4P3BsXoNJkrZmliWXK4GHk5z5c75QVV+by1SSpC2bOuhV9QLwS3OcRZI0Az+2KElNGHRJasKgS1ITBl2SmpjHvVxGt3zg0VGOe+Lg7aMcV5LOxTN0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkprYNfYA0iJaPvDoKMc9cfD2835vEWfSYvEMXZKaMOiS1IRBl6QmDLokNWHQJamJmYKe5LYk30ny3SQH5jWUJGnrpg56kkuAPwc+AFwP7Ety/bwGkyRtzSxn6HuB71bVC1X1Q+CLwB3zGUuStFWzBP3dwPc3vD45bJMkjSBVNd0PJh8GfrOqfnd4fRewt6o+ddZ++4H9w8vrgO9MP+622A28PPYQZ1nEmWAx53KmyTjT5BZxrp+tqqXNdprl0v+TwNUbXl8FvHj2TlV1CDg0w3G2VZLVqloZe46NFnEmWMy5nGkyzjS5RZ1rErMsuXwbuDbJzyX5KeAjwCPzGUuStFVTn6FX1RtJPgn8HXAJcH9VPTu3ySRJWzLT3Rar6jHgsTnNMpZFXA5axJlgMedypsk40+QWda5NTf2mqCRpsXjpvyQ1saODvmi3Lkhyf5LTSY6NPcsZSa5O8o0kx5M8m+SeBZjpp5P8S5J/G2b647FnOiPJJUn+Ncnfjj3LGUlOJHkmydNJVseeByDJO5N8Oclzw7+tXx15nuuGv58zX68muXfMmaaxY5dchlsX/CdwK+sfwfw2sK+q/mPEmd4HvA78VVX94lhzbJRkD7Cnqp5K8nbgKHDnyH9PAS6rqteTXAp8E7inqv55rJnOSPJ7wArwjqr64NjzwHrQgZWqWpjPVic5AvxjVd03fErurVX1v2PPBT9uww+AX66q7409z1bs5DP0hbt1QVU9Cbwy5gxnq6pTVfXU8Pw14DgjXxFc614fXl46fI1+ZpLkKuB24L6xZ1lkSd4BvA84DFBVP1yUmA9uAf7rYos57Oyge+uCLUqyDNwIfGvcSX68tPE0cBp4vKpGnwn4M+APgB+NPchZCvh6kqPDldtj+3lgDfjLYXnqviSXjT3UBh8BHhx7iGns5KDnHNtGP8tbVEneBjwE3FtVr449T1W9WVU3sH6F8t4koy5RJfkgcLqqjo45x3ncVFXvZf3OqJ8YlvbGtAt4L/C5qroR+D9g9PewAIblnw8BfzP2LNPYyUGf6NYFgmGd+iHggar6ytjzbDT8qv4PwG0jj3IT8KFhvfqLwK8n+etxR1pXVS8Oj6eBh1lfbhzTSeDkht+qvsx64BfBB4CnquqlsQeZxk4OurcumMDwBuRh4HhVfXbseQCSLCV55/D8Z4DfAJ4bc6aq+sOquqqqlln/t/T3VfXRMWcCSHLZ8GY2w7LG+4FRP0VVVf8DfD/JdcOmW4DR3mQ/yz4u0uUWmPFK0YvZIt66IMmDwM3A7iQngc9U1eExZ2L9zPMu4JlhzRrg08NVwmPZAxwZPo3wFuBLVbUwHxNcMFcCD6//v8wu4AtV9bVxRwLgU8ADw8nUC8DvjDwPSd7K+qfePj72LNPasR9blKRudvKSiyS1YtAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJv4fDyujFWvkGZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  88.67924528301887\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.56603773584906\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 7\n",
    "print(t_accuracy[:n])\n",
    "\n",
    "a = [x[0].split('_') for x in t_accuracy[:n] ] \n",
    "print(a)\n",
    "for xx in a:\n",
    "    test_pred = []\n",
    "    s = ''\n",
    "    combine_prediction(xx, test_pred)\n",
    "    all_pred = [] ;\n",
    "    for i in range(len(test_pred)):\n",
    "        if ( i == 0 ):\n",
    "            all_pred = test_pred[i]\n",
    "        else:\n",
    "            all_pred = np.column_stack((all_pred, test_pred[i]) )\n",
    "\n",
    "    top_seven = []\n",
    "    for i in range(len(all_pred)):\n",
    "        unique, counts = np.unique(all_pred[i], return_counts=True)\n",
    "        x = dict(zip(unique, counts))\n",
    "        sorted_x = sorted(x.items(), key=operator.itemgetter(1), reverse=True) # sorted by value\n",
    "        l = list(islice([int(x) for x,y in sorted_x],top_n))\n",
    "        while ( len(l) < top_n ):\n",
    "          l.append(-1)\n",
    "        top_seven.append(l)\n",
    "\n",
    "\n",
    "    columns = ['N'+str(i+1) for i in range(len(top_seven[0]))]\n",
    "    df_top_seven = pd.DataFrame(top_seven, columns=columns)\n",
    "    r = mtr.getAccuracyCount(np.array(df_top_seven)) ;\n",
    "    print ( \"Accuracy: \",  r)\n",
    "    dict_accuracy.update({s: r})\n",
    "    mtr.plot_matched_counts(df_top_seven.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}\n",
    "\n",
    "\n",
    "prev_r = 0\n",
    "\n",
    "mtr = MyTotoResearch(algo_no=1)\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "#Deep Neuro Network\n",
    "for n in range(1,2):\n",
    "    X = mtr.modified_dataset(getAllData(df)) #\n",
    "    f = 1.0 #365/27.58\n",
    "#    X = getAdjustedDataF(df,f)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    Z = scaler.transform(X)\n",
    "\n",
    "    clf = SGDClassifier(random_state=42)\n",
    "\n",
    "    model = MultiOutputClassifier(clf, n_jobs=7)\n",
    "    model.fit(Z, mtr.getTargets()) \n",
    "    print(model)\n",
    "    s = model.score(Z, mtr.getTargets())\n",
    "    if(model.score(Z, mtr.getTargets()) == 1.0):\n",
    "        print( str(f), ' ', str(s))\n",
    "    store_prediction(mtr, model, f)\n",
    "    start = time.clock()\n",
    "    print(str(f), \" Time taken: \", (time.clock() - start),  \" \")\n",
    "\n",
    "print(\"Done.\")\n",
    "# mtr = MyTotoResearch(algo_no=1)\n",
    "# lresult, df = mtr.load_totodata()\n",
    "\n",
    "# test_data = mtr.get_test_data()\n",
    "\n",
    "for n in range(len(df_predictions)):\n",
    "    print( mtr.getAccuracyCount(np.array(df_predictions[n])))\n",
    "    mtr.print_predictions(df_predictions[n])\n",
    "\n",
    "\n",
    "#69.81 => MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='relu', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#75.47 =>  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#64.15 =>  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='adam', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#62  MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='tanh', learning_rate='adaptive', solver='lbfgs', verbose=0,  random_state=42,tol=0.000000001)\n",
    "#71.69 => MLPClassifier(hidden_layer_sizes=(500,500,500), max_iter=2000, alpha=0.001, activation='logistic', learning_rate='adaptive', solver='lbfgs', verbose=0,  random_state=42,tol=0.000000001)\n",
    "\n",
    "#75.47 => SVC(kernel='poly', coef0=0.05, probability=True, degree=2, random_state=42, tol=1e-03)\n",
    "\n",
    "\n",
    "\n",
    "#69.81 => SVC(random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nov 26\n",
    "# 16 22 28 31 38 46 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521\n",
      "9\n",
      "60.37735849056604\n",
      "20180514   [17 24 29 45 46 49  5]   [16. 21. 22. 24. 25. 27.]   [24]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [16. 17. 34. 40. 44. 45.]   []\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 6.  9. 15. 18. 40. 43.]   []\n",
      "20180524   [11 25 26 34 36 42 16]   [15. 17. 20. 23. 30. 45.]   []\n",
      "20180528   [ 5  9 27 28 30 44  2]   [ 4.  5. 13. 18. 39. 40.]   [5]\n",
      "20180531   [11 13 24 26 47 49 33]   [ 9. 27. 29. 31. 40. 44.]   []\n",
      "20180604   [20 22 31 37 43 45 27]   [ 6. 16. 22. 26. 29. 38.]   [22]\n",
      "20180607   [12 20 29 31 37 39 42]   [ 3. 19. 23. 30. 39. 41.]   [39]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 9. 10. 25. 38. 40. 42.]   [25]\n",
      "20180614   [ 4 29 31 35 42 48  1]   [22. 23. 25. 32. 33. 36.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [ 3.  6. 16. 17. 22. 36.]   [22]\n",
      "20180621   [ 4  6 15 24 30 35 46]   [16. 20. 23. 28. 39. 42.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [15. 18. 20. 27. 36. 40.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [10. 15. 27. 28. 41. 43.]   [27]\n",
      "20180702   [12 13 26 33 35 38 23]   [ 8. 10. 19. 20. 41. 43.]   []\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 9. 13. 17. 28. 37. 40.]   [28]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [12. 23. 26. 28. 39. 40.]   [23 39]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [14. 23. 35. 37. 45. 46.]   []\n",
      "20180716   [ 4  8 19 24 32 47 22]   [ 8. 19. 22. 24. 32. 45.]   [ 8 19 22 24 32]\n",
      "20180719   [13 14 23 35 37 46 45]   [10. 15. 25. 32. 40. 41.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [23. 31. 33. 38. 39. 43.]   [23 39]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11. 28. 30. 32. 34. 39.]   [28]\n",
      "20180730   [ 8 10 19 20 41 43  7]   [13. 23. 26. 33. 35. 38.]   []\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 3.  9. 25. 38. 44. 48.]   []\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 6. 15. 24. 30. 35. 45.]   [15]\n",
      "20180809   [13 16 20 23 39 42 28]   [11. 22. 23. 25. 41. 43.]   [23]\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 4. 18. 19. 35. 42. 44.]   []\n",
      "20180816   [22 23 25 32 33 36 20]   [25. 30. 34. 31. 44. 42.]   [25]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [ 5. 29. 26. 37. 39. 42.]   [42]\n",
      "20180823   [ 2  3 23 30 39 41 19]   [10. 18. 31. 37. 43. 45.]   []\n",
      "20180827   [ 5  6 16 24 26 29 38]   [13. 17. 26. 33. 47. 44.]   [26]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 5.  9. 27. 28. 41. 44.]   [ 9 27]\n",
      "20180903   [ 4  5 13 18 39 40  3]   [16. 17. 22. 34. 36. 42.]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [ 9. 18. 17. 27. 41. 44.]   [17]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [ 9. 18. 17. 27. 41. 44.]   [ 9 18]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [ 9. 18. 17. 31. 41. 44.]   [17 44]\n",
      "20180917   [16 21 22 24 25 27  1]   [ 8. 18. 30. 31. 41. 44.]   []\n",
      "20180920   [ 5 12 18 30 32 38 22]   [ 9. 18. 19. 31. 36. 44.]   [18]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [ 9. 18. 17. 31. 38. 45.]   [17]\n",
      "20180927   [ 2 25 29 33 42 45 20]   [11. 18. 17. 31. 41. 44.]   []\n",
      "20181001   [11 15 23 24 32 40 43]   [ 8. 18. 17. 31. 41. 45.]   []\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 9. 18. 17. 27. 37. 44.]   [37]\n",
      "20181008   [17 18 23 39 43 49  2]   [ 4.  8. 22. 30. 30. 45.]   []\n",
      "20181011   [ 1 16 18 24 29 46 35]   [ 9. 13. 23. 32. 40. 43.]   []\n",
      "20181015   [ 1  4 24 32 35 48 20]   [ 9. 17. 17. 31. 41. 45.]   []\n",
      "20181018   [ 5 14 17 31 46 48 47]   [ 9. 13. 19. 32. 40. 45.]   []\n",
      "20181022   [ 5 22 24 40 43 48  2]   [ 9. 13. 25. 31. 41. 45.]   []\n",
      "20181025   [ 7  8 13 15 35 48 30]   [10. 16. 22. 34. 41. 45.]   []\n",
      "20181029   [ 2  6 10 20 28 31 30]   [ 6. 15. 19. 31. 40. 44.]   [ 6 31]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [ 6. 15. 19. 32. 38. 44.]   [ 6 15 44]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 6. 12. 19. 31. 41. 44.]   []\n",
      "20181108   [ 8 13 16 26 28 38 46]   [ 6. 17. 25. 31. 38. 44.]   [38]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 8. 12. 22. 27. 41. 44.]   [12 41]\n",
      "20181115  Predicted:  [10. 17. 22. 32. 40. 44.]  \n",
      "20181119  Predicted:  [ 9. 12. 19. 27. 34. 44.]  \n",
      "20181122  Predicted:  [ 9. 14. 19. 31. 35. 41.]  \n",
      "20181126  Predicted:  [ 6. 14. 17. 27. 40. 44.]  \n",
      "20181129  Predicted:  [12. 18. 23. 33. 39. 43.]  \n",
      "20181203  Predicted:  [ 8. 18. 17. 31. 37. 45.]  \n",
      "20181206  Predicted:  [ 8. 18. 17. 31. 35. 44.]  \n",
      "20181210  Predicted:  [ 9. 18. 17. 31. 41. 45.]  \n",
      "20181213  Predicted:  [ 9. 18. 17. 31. 41. 45.]  \n",
      "20181217  Predicted:  [ 9. 18. 19. 31. 35. 44.]  \n",
      "20181220  Predicted:  [ 9. 18. 23. 31. 41. 44.]  \n",
      "20181224  Predicted:  [ 8. 18. 22. 27. 35. 44.]  \n",
      "20181227  Predicted:  [ 9. 18. 17. 27. 41. 44.]  \n",
      "20181231  Predicted:  [ 9. 18. 17. 27. 41. 44.]  \n",
      "64.15094339622641\n",
      "20180514   [17 24 29 45 46 49  5]   [ 7. 17. 22. 24. 39. 45.]   [17 24 45]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [16. 17. 22. 30. 39. 45.]   []\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 6.  9. 22. 30. 40. 43.]   [30]\n",
      "20180524   [11 25 26 34 36 42 16]   [15. 17. 22. 30. 40. 43.]   []\n",
      "20180528   [ 5  9 27 28 30 44  2]   [ 7. 12. 22. 30. 39. 43.]   [30]\n",
      "20180531   [11 13 24 26 47 49 33]   [ 9. 22. 24. 27. 40. 45.]   [24]\n",
      "20180604   [20 22 31 37 43 45 27]   [ 6. 16. 24. 26. 39. 43.]   [43]\n",
      "20180607   [12 20 29 31 37 39 42]   [ 3. 19. 23. 30. 39. 41.]   [39]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 9. 10. 25. 38. 40. 42.]   [25]\n",
      "20180614   [ 4 29 31 35 42 48  1]   [ 7. 23. 25. 32. 33. 36.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [12. 13. 16. 32. 41. 45.]   []\n",
      "20180621   [ 4  6 15 24 30 35 46]   [10. 20. 23. 32. 39. 42.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [10. 18. 23. 27. 41. 42.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [12. 15. 27. 32. 41. 43.]   [27]\n",
      "20180702   [12 13 26 33 35 38 23]   [ 8. 15. 25. 32. 41. 43.]   []\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 9. 13. 17. 28. 37. 40.]   [28]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [12. 23. 26. 28. 39. 40.]   [23 39]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [14. 23. 27. 37. 39. 44.]   []\n",
      "20180716   [ 4  8 19 24 32 47 22]   [ 8. 19. 22. 24. 39. 44.]   [ 8 19 22 24]\n",
      "20180719   [13 14 23 35 37 46 45]   [10. 15. 25. 32. 39. 41.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [10. 16. 33. 32. 39. 43.]   [39]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11. 15. 30. 32. 41. 45.]   []\n",
      "20180730   [ 8 10 19 20 41 43  7]   [13. 23. 19. 32. 35. 43.]   [19 43]\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 7.  9. 25. 38. 41. 43.]   [41]\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 6. 15. 24. 30. 35. 44.]   [15]\n",
      "20180809   [13 16 20 23 39 42 28]   [ 6. 22. 19. 27. 35. 43.]   []\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 4. 18. 31. 27. 35. 43.]   []\n",
      "20180816   [22 23 25 32 33 36 20]   [ 8. 15. 23. 31. 34. 44.]   [23]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [10. 15. 22. 37. 39. 42.]   [10 42]\n",
      "20180823   [ 2  3 23 30 39 41 19]   [10. 12. 31. 37. 43. 44.]   []\n",
      "20180827   [ 5  6 16 24 26 29 38]   [13. 17. 26. 32. 35. 44.]   [26]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 8.  9. 27. 37. 39. 44.]   [ 9 27]\n",
      "20180903   [ 4  5 13 18 39 40  3]   [10. 17. 22. 37. 36. 42.]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [ 9. 16. 17. 27. 37. 45.]   [17 45]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [ 9. 18. 17. 27. 37. 44.]   [ 9 18]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [ 9. 18. 17. 31. 41. 45.]   [17]\n",
      "20180917   [16 21 22 24 25 27  1]   [ 9. 18. 30. 31. 36. 44.]   []\n",
      "20180920   [ 5 12 18 30 32 38 22]   [ 9. 18. 19. 31. 36. 44.]   [18]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [ 9. 18. 19. 31. 36. 49.]   []\n",
      "20180927   [ 2 25 29 33 42 45 20]   [11. 18. 17. 31. 41. 44.]   []\n",
      "20181001   [11 15 23 24 32 40 43]   [ 9. 18. 17. 31. 41. 44.]   []\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 7. 18. 17. 31. 36. 44.]   []\n",
      "20181008   [17 18 23 39 43 49  2]   [ 9. 16. 25. 31. 41. 45.]   []\n",
      "20181011   [ 1 16 18 24 29 46 35]   [ 9. 13. 17. 32. 41. 44.]   []\n",
      "20181015   [ 1  4 24 32 35 48 20]   [ 9. 17. 17. 34. 35. 45.]   [35]\n",
      "20181018   [ 5 14 17 31 46 48 47]   [ 9. 13. 30. 32. 41. 45.]   []\n",
      "20181022   [ 5 22 24 40 43 48  2]   [10. 17. 25. 32. 41. 45.]   []\n",
      "20181025   [ 7  8 13 15 35 48 30]   [10. 13. 25. 34. 41. 45.]   [13]\n",
      "20181029   [ 2  6 10 20 28 31 30]   [ 6. 12. 30. 28. 41. 44.]   [ 6 28 30]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [ 8. 15. 25. 32. 39. 45.]   [15]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 8. 12. 17. 32. 41. 44.]   [8]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [ 9. 14. 25. 28. 41. 42.]   [28]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 8. 12. 22. 31. 36. 45.]   [12]\n",
      "20181115  Predicted:  [ 9. 13. 25. 32. 41. 45.]  \n",
      "20181119  Predicted:  [ 6. 18. 27. 31. 39. 44.]  \n",
      "20181122  Predicted:  [ 9. 14. 19. 31. 35. 45.]  \n",
      "20181126  Predicted:  [ 8. 17. 22. 27. 35. 45.]  \n",
      "20181129  Predicted:  [ 7. 18. 17. 31. 34. 44.]  \n",
      "20181203  Predicted:  [ 8. 18. 17. 31. 37. 45.]  \n",
      "20181206  Predicted:  [ 6. 18. 17. 27. 35. 44.]  \n",
      "20181210  Predicted:  [ 6. 18. 17. 31. 35. 45.]  \n",
      "20181213  Predicted:  [ 9. 18. 17. 31. 36. 45.]  \n",
      "20181217  Predicted:  [ 9. 13. 19. 31. 35. 44.]  \n",
      "20181220  Predicted:  [ 9. 18. 23. 31. 37. 44.]  \n",
      "20181224  Predicted:  [ 8. 13. 22. 27. 35. 44.]  \n",
      "20181227  Predicted:  [ 9. 18. 17. 27. 41. 44.]  \n",
      "20181231  Predicted:  [11. 18. 17. 27. 41. 44.]  \n",
      "60.37735849056604\n",
      "20180514   [17 24 29 45 46 49  5]   [ 7.  9. 22. 30. 39. 45.]   [45]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [10. 16. 22. 30. 39. 43.]   []\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 7. 22. 22. 30. 33. 43.]   [30]\n",
      "20180524   [11 25 26 34 36 42 16]   [ 7. 12. 22. 30. 33. 41.]   []\n",
      "20180528   [ 5  9 27 28 30 44  2]   [ 7.  9. 22. 29. 32. 43.]   [9]\n",
      "20180531   [11 13 24 26 47 49 33]   [ 8. 12. 22. 32. 39. 45.]   []\n",
      "20180604   [20 22 31 37 43 45 27]   [14. 12. 22. 27. 39. 45.]   [22 27 45]\n",
      "20180607   [12 20 29 31 37 39 42]   [ 7. 18. 17. 32. 39. 45.]   [39]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 8. 18. 28. 32. 39. 43.]   []\n",
      "20180614   [ 4 29 31 35 42 48  1]   [ 7. 22. 25. 32. 39. 45.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [12. 13. 23. 32. 37. 43.]   [23 43]\n",
      "20180621   [ 4  6 15 24 30 35 46]   [12. 22. 22. 32. 41. 43.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [ 8. 17. 23. 31. 41. 44.]   [44]\n",
      "20180628   [ 2  7 22 27 40 47 48]   [12. 12. 23. 32. 37. 44.]   []\n",
      "20180702   [12 13 26 33 35 38 23]   [12. 15. 17. 32. 33. 44.]   [12 33]\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 8. 18. 27. 32. 41. 44.]   [ 8 32]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [10. 16. 27. 27. 40. 43.]   [43]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [ 6. 15. 27. 31. 39. 44.]   [15]\n",
      "20180716   [ 4  8 19 24 32 47 22]   [10. 23. 27. 28. 39. 44.]   []\n",
      "20180719   [13 14 23 35 37 46 45]   [ 7. 18. 19. 32. 39. 44.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [ 8. 16. 24. 32. 36. 45.]   []\n",
      "20180726   [ 1  9 13 17 28 40 37]   [ 7. 18. 24. 31. 36. 45.]   []\n",
      "20180730   [ 8 10 19 20 41 43  7]   [12. 15. 22. 27. 39. 43.]   [43]\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 9. 18. 19. 29. 39. 43.]   []\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 7. 12. 23. 32. 39. 42.]   [7]\n",
      "20180809   [13 16 20 23 39 42 28]   [ 8. 12. 19. 32. 35. 43.]   []\n",
      "20180813   [ 1  3  6 16 22 36 17]   [10. 18. 24. 32. 35. 43.]   []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180816   [22 23 25 32 33 36 20]   [ 8. 15. 23. 31. 34. 43.]   [23]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [ 8. 15. 22. 27. 41. 43.]   []\n",
      "20180823   [ 2  3 23 30 39 41 19]   [ 8. 15. 25. 32. 33. 43.]   []\n",
      "20180827   [ 5  6 16 24 26 29 38]   [ 8. 17. 25. 32. 36. 45.]   []\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 8. 16. 22. 31. 39. 43.]   [31]\n",
      "20180903   [ 4  5 13 18 39 40  3]   [10. 17. 30. 31. 36. 45.]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [10. 16. 25. 31. 38. 45.]   [45]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [10. 18. 25. 31. 37. 44.]   [18]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [10. 18. 25. 31. 41. 45.]   []\n",
      "20180917   [16 21 22 24 25 27  1]   [11. 15. 19. 31. 36. 45.]   []\n",
      "20180920   [ 5 12 18 30 32 38 22]   [11. 18. 24. 31. 37. 45.]   [18]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [ 6. 18. 17. 31. 41. 44.]   [ 6 17]\n",
      "20180927   [ 2 25 29 33 42 45 20]   [10. 18. 17. 31. 36. 44.]   []\n",
      "20181001   [11 15 23 24 32 40 43]   [ 9. 18. 17. 31. 41. 44.]   []\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 7. 18. 17. 31. 36. 45.]   []\n",
      "20181008   [17 18 23 39 43 49  2]   [ 9. 11. 22. 31. 41. 44.]   []\n",
      "20181011   [ 1 16 18 24 29 46 35]   [ 8. 18. 17. 27. 41. 44.]   [18]\n",
      "20181015   [ 1  4 24 32 35 48 20]   [10. 18. 25. 27. 37. 44.]   []\n",
      "20181018   [ 5 14 17 31 46 48 47]   [ 9. 20. 30. 31. 36. 45.]   [31]\n",
      "20181022   [ 5 22 24 40 43 48  2]   [10. 18. 30. 27. 41. 45.]   []\n",
      "20181025   [ 7  8 13 15 35 48 30]   [ 8. 18. 25. 27. 41. 44.]   [8]\n",
      "20181029   [ 2  6 10 20 28 31 30]   [ 8. 14. 22. 27. 41. 45.]   []\n",
      "20181101   [ 6 27 28 41 44 48 15]   [ 8. 15. 22. 27. 34. 45.]   [15 27]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 8. 18. 16. 27. 41. 45.]   [8]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [ 8. 14. 19. 27. 36. 45.]   [8]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 8. 15. 22. 27. 36. 45.]   []\n",
      "20181115  Predicted:  [ 9. 13. 25. 27. 41. 45.]  \n",
      "20181119  Predicted:  [ 6. 18. 24. 31. 35. 41.]  \n",
      "20181122  Predicted:  [ 9. 18. 24. 31. 38. 45.]  \n",
      "20181126  Predicted:  [ 8. 12. 22. 27. 35. 44.]  \n",
      "20181129  Predicted:  [ 7. 12. 16. 27. 34. 44.]  \n",
      "20181203  Predicted:  [ 6. 18. 23. 31. 34. 45.]  \n",
      "20181206  Predicted:  [ 6. 18. 16. 27. 38. 45.]  \n",
      "20181210  Predicted:  [ 6. 18. 16. 27. 37. 44.]  \n",
      "20181213  Predicted:  [ 6. 18. 30. 31. 36. 45.]  \n",
      "20181217  Predicted:  [ 9. 13. 23. 31. 37. 45.]  \n",
      "20181220  Predicted:  [ 6. 18. 16. 31. 37. 44.]  \n",
      "20181224  Predicted:  [ 6. 13. 22. 27. 37. 44.]  \n",
      "20181227  Predicted:  [ 6. 18. 17. 30. 37. 44.]  \n",
      "20181231  Predicted:  [11. 18. 17. 31. 37. 45.]  \n",
      "56.60377358490566\n",
      "20180514   [17 24 29 45 46 49  5]   [ 6. 14. 34. 24. 25. 27.]   [24]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [11. 17. 24. 30. 32. 36.]   []\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 3.  8. 14. 18. 21. 36.]   [8]\n",
      "20180524   [11 25 26 34 36 42 16]   [ 4. 17. 13. 18. 21. 43.]   []\n",
      "20180528   [ 5  9 27 28 30 44  2]   [ 3.  5.  8. 18. 22. 33.]   [5]\n",
      "20180531   [11 13 24 26 47 49 33]   [ 9.  6. 12. 16. 31. 27.]   []\n",
      "20180604   [20 22 31 37 43 45 27]   [12. 13. 22. 23. 24. 41.]   [22]\n",
      "20180607   [12 20 29 31 37 39 42]   [ 3. 19. 29. 30. 39. 41.]   [29 39]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 4. 10. 23. 30. 41. 43.]   [30]\n",
      "20180614   [ 4 29 31 35 42 48  1]   [ 3.  6. 16. 26. 33. 36.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [ 5.  6. 16. 17. 38. 45.]   []\n",
      "20180621   [ 4  6 15 24 30 35 46]   [16. 18. 13. 17. 23. 27.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [ 6.  8. 14. 28. 29. 30.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [ 3.  7. 27. 17. 25. 46.]   [ 7 27]\n",
      "20180702   [12 13 26 33 35 38 23]   [ 8.  7. 25. 15. 41. 31.]   []\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 8. 18. 20. 24. 29. 40.]   [8]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [ 6. 24. 13. 28. 21. 45.]   [6]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [11. 12. 23. 27. 45. 34.]   []\n",
      "20180716   [ 4  8 19 24 32 47 22]   [11. 12. 16. 36. 39. 33.]   []\n",
      "20180719   [13 14 23 35 37 46 45]   [ 4.  5.  9. 10. 19. 30.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [ 6. 11. 13. 17. 37. 35.]   []\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11. 18. 30. 36. 37. 38.]   [37]\n",
      "20180730   [ 8 10 19 20 41 43  7]   [17. 23. 24. 26. 35. 36.]   []\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 3. 20. 23. 30. 39. 48.]   []\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 6.  9. 16. 25. 31. 47.]   []\n",
      "20180809   [13 16 20 23 39 42 28]   [ 6.  8. 19. 25. 22. 31.]   []\n",
      "20180813   [ 1  3  6 16 22 36 17]   [11. 20. 31. 27. 30. 34.]   []\n",
      "20180816   [22 23 25 32 33 36 20]   [ 6. 17. 12. 18. 24. 37.]   []\n",
      "20180820   [ 9 10 25 38 40 42  2]   [ 4.  6. 22. 37. 30. 32.]   []\n",
      "20180823   [ 2  3 23 30 39 41 19]   [ 6.  9. 20. 24. 43. 38.]   []\n",
      "20180827   [ 5  6 16 24 26 29 38]   [ 9.  6. 26. 29. 35. 38.]   [ 6 26 29 38]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 5.  9. 11. 36. 30. 44.]   [9]\n",
      "20180903   [ 4  5 13 18 39 40  3]   [16.  9. 12. 23. 36. 38.]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [ 8. 10. 17. 18. 31. 32.]   [17]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [ 3. 10. 10. 29. 23. 28.]   []\n",
      "20180913   [ 6 16 17 40 44 48 34]   [ 7. 15. 16. 21. 31. 32.]   [16]\n",
      "20180917   [16 21 22 24 25 27  1]   [ 4. 22.  9. 17. 31. 44.]   [22]\n",
      "20180920   [ 5 12 18 30 32 38 22]   [ 3. 10. 10. 15. 23. 44.]   []\n",
      "20180924   [ 6  8 17 24 29 47 34]   [ 6. 10. 11. 18. 23. 37.]   [6]\n",
      "20180927   [ 2 25 29 33 42 45 20]   [ 7. 15. 16. 21. 36. 32.]   []\n",
      "20181001   [11 15 23 24 32 40 43]   [ 9. 12. 16. 22. 46. 27.]   []\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 6. 10. 17. 21. 23. 37.]   [23 37]\n",
      "20181008   [17 18 23 39 43 49  2]   [ 4.  7. 10. 25. 29. 43.]   [43]\n",
      "20181011   [ 1 16 18 24 29 46 35]   [16. 19. 16. 22. 24. 43.]   [16 24]\n",
      "20181015   [ 1  4 24 32 35 48 20]   [ 4. 21. 12. 16. 25. 41.]   [4]\n",
      "20181018   [ 5 14 17 31 46 48 47]   [ 9. 31. 19. 23. 25. 44.]   [31]\n",
      "20181022   [ 5 22 24 40 43 48  2]   [ 9. 10. 32. 23. 41. 44.]   []\n",
      "20181025   [ 7  8 13 15 35 48 30]   [ 5. 19. 21. 25. 41. 42.]   []\n",
      "20181029   [ 2  6 10 20 28 31 30]   [16. 19. 21. 24. 37. 38.]   []\n",
      "20181101   [ 6 27 28 41 44 48 15]   [10. 11. 14. 20. 31. 42.]   []\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 4. 11. 14. 18. 19. 42.]   [14]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [ 9. 10. 17. 36. 23. 42.]   []\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 4. 10. 15. 20. 22. 32.]   [4]\n",
      "20181115  Predicted:  [16. 17.  9. 17. 31. 33.]  \n",
      "20181119  Predicted:  [ 2.  3.  7. 18. 27. 38.]  \n",
      "20181122  Predicted:  [ 5. 14. 18. 21. 35. 41.]  \n",
      "20181126  Predicted:  [ 6. 14. 24. 21. 23. 40.]  \n",
      "20181129  Predicted:  [ 7. 17. 18. 20. 34. 37.]  \n",
      "20181203  Predicted:  [ 2.  6.  9. 17. 19. 33.]  \n",
      "20181206  Predicted:  [ 6. 10. 17. 21. 41. 42.]  \n",
      "20181210  Predicted:  [ 4.  6. 16. 21. 24. 26.]  \n",
      "20181213  Predicted:  [ 2.  6. 11. 20. 24. 26.]  \n",
      "20181217  Predicted:  [ 3.  6. 16. 18. 19. 42.]  \n",
      "20181220  Predicted:  [ 9. 22. 23. 24. 28. 39.]  \n",
      "20181224  Predicted:  [ 4.  6.  7. 18. 19. 39.]  \n",
      "20181227  Predicted:  [ 3.  6.  7. 18. 26. 39.]  \n",
      "20181231  Predicted:  [ 2.  3. 14. 21. 33. 34.]  \n",
      "64.15094339622641\n",
      "20180514   [17 24 29 45 46 49  5]   [ 7.  9. 22. 24. 42. 45.]   [24 45]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [16. 23. 29. 30. 32. 45.]   [29]\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 7.  9. 22. 30. 33. 43.]   [30]\n",
      "20180524   [11 25 26 34 36 42 16]   [ 7.  9. 22. 30. 32. 43.]   []\n",
      "20180528   [ 5  9 27 28 30 44  2]   [ 7. 23. 18. 23. 32. 43.]   []\n",
      "20180531   [11 13 24 26 47 49 33]   [14. 17. 23. 31. 29. 45.]   []\n",
      "20180604   [20 22 31 37 43 45 27]   [14. 12. 22. 32. 39. 43.]   [22 43]\n",
      "20180607   [12 20 29 31 37 39 42]   [ 3. 18. 17. 32. 32. 45.]   []\n",
      "20180611   [16 25 30 37 44 49 34]   [ 9. 17. 28. 38. 39. 42.]   []\n",
      "20180614   [ 4 29 31 35 42 48  1]   [13. 17. 25. 32. 33. 43.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [12. 13. 23. 32. 41. 45.]   [23]\n",
      "20180621   [ 4  6 15 24 30 35 46]   [12. 10. 21. 32. 41. 43.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [10. 13. 27. 31. 41. 42.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [12. 15. 23. 27. 37. 43.]   [27]\n",
      "20180702   [12 13 26 33 35 38 23]   [12. 15. 17. 32. 37. 43.]   [12]\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 8. 18. 17. 28. 37. 44.]   [ 8 28]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [12. 23. 27. 31. 39. 40.]   [23 31 39]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [12. 15. 27. 37. 39. 40.]   [15 40]\n",
      "20180716   [ 4  8 19 24 32 47 22]   [10. 23. 27. 28. 39. 44.]   []\n",
      "20180719   [13 14 23 35 37 46 45]   [ 7. 15. 21. 32. 39. 38.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [10. 16. 24. 32. 39. 45.]   [39]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11.  9. 21. 32. 39. 45.]   [9]\n",
      "20180730   [ 8 10 19 20 41 43  7]   [ 7. 12. 19. 32. 39. 43.]   [ 7 19 43]\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 7. 10. 21. 38. 35. 43.]   [10 35]\n",
      "20180806   [ 7 18 20 27 36 40 15]   [13. 15. 24. 30. 41. 42.]   [15]\n",
      "20180809   [13 16 20 23 39 42 28]   [13. 11. 24. 27. 35. 42.]   [13 42]\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 4. 18. 20. 27. 35. 43.]   []\n",
      "20180816   [22 23 25 32 33 36 20]   [ 8. 15. 23. 31. 39. 42.]   [23]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [ 5. 15. 22. 37. 39. 43.]   []\n",
      "20180823   [ 2  3 23 30 39 41 19]   [10. 11. 25. 32. 33. 44.]   []\n",
      "20180827   [ 5  6 16 24 26 29 38]   [13. 11. 31. 32. 33. 42.]   []\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 5. 16. 22. 31. 39. 42.]   [31]\n",
      "20180903   [ 4  5 13 18 39 40  3]   [10. 17. 22. 33. 36. 42.]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [10. 16. 25. 31. 38. 45.]   [45]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [ 9. 21. 25. 34. 36. 44.]   [9]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [ 9. 18. 25. 31. 38. 45.]   []\n",
      "20180917   [16 21 22 24 25 27  1]   [11. 23. 25. 31. 31. 44.]   [25]\n",
      "20180920   [ 5 12 18 30 32 38 22]   [ 9. 18. 29. 31. 37. 45.]   [18]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [ 9. 14. 25. 33. 36. 44.]   []\n",
      "20180927   [ 2 25 29 33 42 45 20]   [11. 18. 25. 31. 42. 44.]   [25 42]\n",
      "20181001   [11 15 23 24 32 40 43]   [ 9. 18. 17. 31. 31. 44.]   []\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 9. 16. 25. 31. 31. 44.]   []\n",
      "20181008   [17 18 23 39 43 49  2]   [ 9. 11. 15. 31. 41. 44.]   []\n",
      "20181011   [ 1 16 18 24 29 46 35]   [ 9. 13. 25. 24. 41. 44.]   [24]\n",
      "20181015   [ 1  4 24 32 35 48 20]   [10. 21. 26. 34. 37. 44.]   []\n",
      "20181018   [ 5 14 17 31 46 48 47]   [ 9. 20. 30. 31. 36. 45.]   [31]\n",
      "20181022   [ 5 22 24 40 43 48  2]   [10. 10. 30. 34. 41. 45.]   []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181025   [ 7  8 13 15 35 48 30]   [11. 13. 25. 37. 41. 44.]   [13]\n",
      "20181029   [ 2  6 10 20 28 31 30]   [ 8. 20. 22. 28. 41. 41.]   [20 28]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [ 8. 15. 22. 27. 34. 45.]   [15 27]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 8. 20. 29. 32. 41. 45.]   [8]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [ 8. 20. 25. 28. 36. 45.]   [ 8 28]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 8. 20. 22. 28. 36. 45.]   []\n",
      "20181115  Predicted:  [ 8. 20. 25. 29. 41. 45.]  \n",
      "20181119  Predicted:  [ 6. 15. 27. 31. 39. 41.]  \n",
      "20181122  Predicted:  [ 9. 14. 23. 31. 36. 45.]  \n",
      "20181126  Predicted:  [ 8. 12. 20. 21. 35. 44.]  \n",
      "20181129  Predicted:  [ 7. 12. 16. 21. 34. 41.]  \n",
      "20181203  Predicted:  [ 8. 12. 24. 31. 34. 45.]  \n",
      "20181206  Predicted:  [ 6. 18. 26. 31. 34. 44.]  \n",
      "20181210  Predicted:  [ 6. 13. 30. 31. 35. 44.]  \n",
      "20181213  Predicted:  [ 9. 20. 30. 31. 36. 45.]  \n",
      "20181217  Predicted:  [ 9. 13. 22. 31. 36. 44.]  \n",
      "20181220  Predicted:  [ 9. 18. 28. 33. 37. 44.]  \n",
      "20181224  Predicted:  [ 6. 13. 22. 21. 38. 44.]  \n",
      "20181227  Predicted:  [ 9. 17. 22. 21. 33. 44.]  \n",
      "20181231  Predicted:  [11. 18. 22. 33. 40. 45.]  \n",
      "56.60377358490566\n",
      "20180514   [17 24 29 45 46 49  5]   [20. 21. 16. 29. 39. 27.]   [29]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [16. 12. 14. 40. 21. 48.]   [21]\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 4.  8. 19. 12. 28. 43.]   [8]\n",
      "20180524   [11 25 26 34 36 42 16]   [ 4. 17. 20. 23. 30. 31.]   []\n",
      "20180528   [ 5  9 27 28 30 44  2]   [13. 17. 13. 18. 28. 39.]   [28]\n",
      "20180531   [11 13 24 26 47 49 33]   [ 6. 27.  8. 23. 25. 36.]   []\n",
      "20180604   [20 22 31 37 43 45 27]   [ 6.  6. 23. 26. 29. 38.]   []\n",
      "20180607   [12 20 29 31 37 39 42]   [ 3. 19. 16. 30. 30. 41.]   []\n",
      "20180611   [16 25 30 37 44 49 34]   [ 7. 15. 15. 38. 28. 45.]   []\n",
      "20180614   [ 4 29 31 35 42 48  1]   [22. 17.  9. 32. 31. 35.]   [31 35]\n",
      "20180618   [11 15 22 23 26 43 25]   [ 3.  6. 12. 17. 27. 45.]   []\n",
      "20180621   [ 4  6 15 24 30 35 46]   [10.  6. 15. 19. 37. 26.]   [ 6 15]\n",
      "20180625   [ 2  5 25 38 44 48  9]   [10.  8. 15. 17. 26. 42.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [10. 15. 12. 25. 42. 34.]   []\n",
      "20180702   [12 13 26 33 35 38 23]   [ 8.  7.  9. 22. 41. 32.]   []\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 3.  7. 11. 28. 29. 40.]   [11 28]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [12. 23. 26. 28. 39. 37.]   [23 39]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [ 4. 23. 35. 37. 22. 46.]   [4]\n",
      "20180716   [ 4  8 19 24 32 47 22]   [ 3.  8. 14. 24. 39. 47.]   [ 8 24 47]\n",
      "20180719   [13 14 23 35 37 46 45]   [ 3.  9. 17. 29. 41. 37.]   [37]\n",
      "20180723   [ 2 23 26 28 39 40 12]   [23.  6. 11. 20. 24. 44.]   [23]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [ 4. 12. 22. 39. 33. 39.]   []\n",
      "20180730   [ 8 10 19 20 41 43  7]   [13. 10. 20. 39. 29. 31.]   [10 20]\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 3. 19. 19. 36. 34. 48.]   []\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 3. 10. 11. 19. 34. 31.]   []\n",
      "20180809   [13 16 20 23 39 42 28]   [ 5.  7. 11. 28. 29. 43.]   [28]\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 6. 15. 19. 34. 27. 43.]   [6]\n",
      "20180816   [22 23 25 32 33 36 20]   [ 5.  6. 19. 22. 30. 49.]   [22]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [ 4. 11. 19. 21. 28. 31.]   []\n",
      "20180823   [ 2  3 23 30 39 41 19]   [ 6.  7. 31. 19. 28. 37.]   [19]\n",
      "20180827   [ 5  6 16 24 26 29 38]   [13. 11.  8. 33. 29. 37.]   [29]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 4. 15. 19. 28. 28. 33.]   []\n",
      "20180903   [ 4  5 13 18 39 40  3]   [ 4. 12. 22. 15. 28. 45.]   [4]\n",
      "20180906   [ 2 15 17 20 23 30 45]   [10. 13. 21. 30. 23. 42.]   [23 30]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [ 6. 21. 15. 29. 29. 37.]   [ 6 15]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [ 4.  9. 10. 45. 23. 42.]   []\n",
      "20180917   [16 21 22 24 25 27  1]   [ 7.  8. 20. 15. 44. 33.]   []\n",
      "20180920   [ 5 12 18 30 32 38 22]   [ 2.  9. 21. 18. 29. 34.]   [18]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [12. 13. 26. 26. 23. 49.]   []\n",
      "20180927   [ 2 25 29 33 42 45 20]   [11. 10. 11. 16. 35. 39.]   []\n",
      "20181001   [11 15 23 24 32 40 43]   [ 7. 11. 32. 20. 23. 42.]   [11 23 32]\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 2. 11. 17. 21. 27. 37.]   [37]\n",
      "20181008   [17 18 23 39 43 49  2]   [ 5. 11. 19. 21. 35. 37.]   []\n",
      "20181011   [ 1 16 18 24 29 46 35]   [ 7.  7. 15. 22. 28. 40.]   []\n",
      "20181015   [ 1  4 24 32 35 48 20]   [11. 14. 14. 26. 18. 43.]   []\n",
      "20181018   [ 5 14 17 31 46 48 47]   [ 7. 11. 10. 13. 26. 45.]   []\n",
      "20181022   [ 5 22 24 40 43 48  2]   [ 4. 27. 20. 17. 30. 45.]   []\n",
      "20181025   [ 7  8 13 15 35 48 30]   [10.  6. 29. 18. 30. 43.]   [30]\n",
      "20181029   [ 2  6 10 20 28 31 30]   [ 2.  6. 17. 21. 34. 43.]   [2 6]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [ 5. 12. 10. 12. 16. 33.]   []\n",
      "20181105   [ 3  8 14 28 43 49 26]   [15.  6. 19. 21. 16. 33.]   []\n",
      "20181108   [ 8 13 16 26 28 38 46]   [ 2. 13. 20. 25. 25. 43.]   [13]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 6.  7. 31. 13. 31. 45.]   []\n",
      "20181115  Predicted:  [10.  6. 20. 23. 30. 45.]  \n",
      "20181119  Predicted:  [ 2.  6. 15. 19. 30. 28.]  \n",
      "20181122  Predicted:  [ 2.  7. 26. 12. 24. 45.]  \n",
      "20181126  Predicted:  [ 6. 13. 31. 18. 40. 31.]  \n",
      "20181129  Predicted:  [ 7. 13. 17. 30. 31. 36.]  \n",
      "20181203  Predicted:  [13. 11. 13. 37. 26. 37.]  \n",
      "20181206  Predicted:  [ 2. 22. 25. 31. 29. 45.]  \n",
      "20181210  Predicted:  [ 4. 14. 21. 31. 29. 40.]  \n",
      "20181213  Predicted:  [13.  6. 15. 31. 32. 44.]  \n",
      "20181217  Predicted:  [10. 14. 30. 24. 30. 42.]  \n",
      "20181220  Predicted:  [13. 16.  9. 24. 22. 37.]  \n",
      "20181224  Predicted:  [ 8. 11. 21. 24. 23. 30.]  \n",
      "20181227  Predicted:  [ 3. 23. 15. 26. 29. 45.]  \n",
      "20181231  Predicted:  [ 5. 21. 23. 26. 32. 43.]  \n",
      "77.35849056603774\n",
      "20180514   [17 24 29 45 46 49  5]   [26. 15. 20. 24. 22. 36.]   [24]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [15. 21. 32. 40. 40. 40.]   [21]\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 4. 19. 13. 26. 22. 41.]   []\n",
      "20180524   [11 25 26 34 36 42 16]   [ 4. 21. 31. 26. 32. 43.]   [26]\n",
      "20180528   [ 5  9 27 28 30 44  2]   [11.  8. 18. 28. 22. 41.]   [28]\n",
      "20180531   [11 13 24 26 47 49 33]   [12. 27. 31. 26. 28. 35.]   [26]\n",
      "20180604   [20 22 31 37 43 45 27]   [29. 19. 23. 26. 28. 45.]   [45]\n",
      "20180607   [12 20 29 31 37 39 42]   [29. 19. 20. 26. 17. 41.]   [20 29]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 9. 10. 16. 27. 32. 42.]   [16]\n",
      "20180614   [ 4 29 31 35 42 48  1]   [29. 23. 18. 32. 26. 38.]   [29]\n",
      "20180618   [11 15 22 23 26 43 25]   [ 3.  6. 14. 32. 27. 38.]   []\n",
      "20180621   [ 4  6 15 24 30 35 46]   [16. 14. 24. 21. 25. 42.]   [24]\n",
      "20180625   [ 2  5 25 38 44 48  9]   [16. 18. 24. 32. 30. 36.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [12. 15. 22. 19. 29. 32.]   [22]\n",
      "20180702   [12 13 26 33 35 38 23]   [ 8. 10. 14. 41. 28. 33.]   [33]\n",
      "20180705   [ 8 11 28 30 32 34 39]   [14. 13. 28. 28. 37. 38.]   [28]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [22. 23. 20. 28. 38. 43.]   [23 38 43]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [14. 15. 35. 37. 32. 36.]   [15 32]\n",
      "20180716   [ 4  8 19 24 32 47 22]   [ 9. 15. 35. 24. 39. 44.]   [24]\n",
      "20180719   [13 14 23 35 37 46 45]   [10. 15. 13. 32. 35. 43.]   [13 35]\n",
      "20180723   [ 2 23 26 28 39 40 12]   [ 6. 28. 24. 38. 39. 38.]   [28 39]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11. 28. 17. 32. 39. 44.]   [17 28]\n",
      "20180730   [ 8 10 19 20 41 43  7]   [13. 29. 20. 33. 33. 38.]   [20]\n",
      "20180802   [ 1 10 15 27 41 46 35]   [31.  8. 19. 35. 27. 43.]   [27 35]\n",
      "20180806   [ 7 18 20 27 36 40 15]   [14. 21. 14. 34. 39. 40.]   [40]\n",
      "20180809   [13 16 20 23 39 42 28]   [ 5. 13. 20. 23. 43. 39.]   [13 20 23 39]\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 5.  8. 23. 25. 35. 34.]   []\n",
      "20180816   [22 23 25 32 33 36 20]   [ 8. 21. 13. 19. 39. 43.]   []\n",
      "20180820   [ 9 10 25 38 40 42  2]   [ 7. 17. 30. 37. 39. 31.]   []\n",
      "20180823   [ 2  3 23 30 39 41 19]   [24. 15. 23. 41. 39. 38.]   [23 39 41]\n",
      "20180827   [ 5  6 16 24 26 29 38]   [ 7. 22. 17. 41. 34. 39.]   []\n",
      "20180830   [ 3  9 27 29 31 40 46]   [14. 17. 23. 23. 38. 42.]   []\n",
      "20180903   [ 4  5 13 18 39 40  3]   [15.  9. 17. 40. 36. 45.]   [40]\n",
      "20180906   [ 2 15 17 20 23 30 45]   [11. 15. 21. 16. 31. 43.]   [15]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [17. 18. 27. 34. 38. 38.]   [18]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [17. 31. 18. 34. 34. 44.]   [17 34 44]\n",
      "20180917   [16 21 22 24 25 27  1]   [ 4. 30. 25. 34. 30. 37.]   [25]\n",
      "20180920   [ 5 12 18 30 32 38 22]   [20. 18. 19. 34. 31. 42.]   [18]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [16. 23. 22. 34. 31. 34.]   [34]\n",
      "20180927   [ 2 25 29 33 42 45 20]   [ 7. 24. 32. 16. 38. 38.]   []\n",
      "20181001   [11 15 23 24 32 40 43]   [13.  5. 18. 39. 37. 45.]   []\n",
      "20181004   [ 5 12 23 32 37 42 43]   [10. 11. 11. 39. 36. 39.]   []\n",
      "20181008   [17 18 23 39 43 49  2]   [16. 23. 11. 35. 41. 28.]   [23]\n",
      "20181011   [ 1 16 18 24 29 46 35]   [13. 12. 26. 35. 39. 36.]   [35]\n",
      "20181015   [ 1  4 24 32 35 48 20]   [12. 14. 26. 35. 44. 41.]   [35]\n",
      "20181018   [ 5 14 17 31 46 48 47]   [12. 20. 17. 34. 34. 41.]   [17]\n",
      "20181022   [ 5 22 24 40 43 48  2]   [10. 18. 19. 35. 38. 41.]   []\n",
      "20181025   [ 7  8 13 15 35 48 30]   [10. 33. 16. 42. 31. 40.]   []\n",
      "20181029   [ 2  6 10 20 28 31 30]   [14. 19. 31. 25. 31. 44.]   [31]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [10. 11. 27. 35. 27. 30.]   [27]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [10. 15. 26. 33. 20. 43.]   [26 43]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [14. 15. 19. 30. 34. 43.]   []\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 5. 26. 20. 25. 34. 30.]   [34]\n",
      "20181115  Predicted:  [ 6. 21. 17. 26. 44. 33.]  \n",
      "20181119  Predicted:  [28. 23. 27. 45. 41. 41.]  \n",
      "20181122  Predicted:  [12. 29. 38. 38. 36. 36.]  \n",
      "20181126  Predicted:  [ 8. 24. 31. 31. 28. 33.]  \n",
      "20181129  Predicted:  [ 6. 13. 26. 23. 34. 38.]  \n",
      "20181203  Predicted:  [ 8. 22. 16. 38. 26. 41.]  \n",
      "20181206  Predicted:  [14. 19. 26. 26. 30. 41.]  \n",
      "20181210  Predicted:  [ 3. 14. 37. 21. 30. 45.]  \n",
      "20181213  Predicted:  [12. 11. 23. 25. 27. 45.]  \n",
      "20181217  Predicted:  [ 4. 22. 16. 18. 36. 41.]  \n",
      "20181220  Predicted:  [ 4. 22. 26. 33. 30. 42.]  \n",
      "20181224  Predicted:  [27. 27. 21. 35. 36. 44.]  \n",
      "20181227  Predicted:  [15. 14. 16. 33. 39. 43.]  \n",
      "20181231  Predicted:  [ 2. 27. 26. 38. 41. 33.]  \n",
      "73.58490566037736\n",
      "20180514   [17 24 29 45 46 49  5]   [10. 15.  9. 24. 25. 27.]   [24]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [21.  8. 19. 12. 44. 41.]   [21]\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 5.  7. 29. 16. 34. 40.]   [16]\n",
      "20180524   [11 25 26 34 36 42 16]   [ 3. 20. 22. 30. 34. 44.]   [34]\n",
      "20180528   [ 5  9 27 28 30 44  2]   [12.  5. 13. 15. 39. 36.]   [5]\n",
      "20180531   [11 13 24 26 47 49 33]   [ 4.  9. 21. 31. 32. 35.]   []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180604   [20 22 31 37 43 45 27]   [ 6.  7.  9. 26. 24. 38.]   []\n",
      "20180607   [12 20 29 31 37 39 42]   [ 3.  8.  7. 30. 23. 31.]   [31]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 5.  9. 14. 12. 30. 43.]   [30]\n",
      "20180614   [ 4 29 31 35 42 48  1]   [11.  6. 25. 32. 33. 36.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [ 7. 11. 13. 17. 22. 36.]   [11 22]\n",
      "20180621   [ 4  6 15 24 30 35 46]   [ 5. 14. 22. 26. 21. 36.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [ 6. 18.  8. 20. 36. 42.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [10. 13. 27. 38. 22. 29.]   [22 27]\n",
      "20180702   [12 13 26 33 35 38 23]   [ 8.  5. 17. 37. 25. 29.]   []\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 6. 13. 17. 28. 37. 40.]   [28]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [12. 23.  9. 28. 39. 40.]   [23 39]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [ 7. 13. 35. 22. 45. 40.]   [40]\n",
      "20180716   [ 4  8 19 24 32 47 22]   [19. 11. 22. 24. 26. 38.]   [19 22 24]\n",
      "20180719   [13 14 23 35 37 46 45]   [10. 15. 26. 18. 33. 49.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [ 4.  9. 33. 38. 39. 29.]   [39]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11.  9. 30. 32. 25. 38.]   [9]\n",
      "20180730   [ 8 10 19 20 41 43  7]   [ 7.  9. 24. 21. 27. 43.]   [ 7 43]\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 3.  9. 25. 38. 32. 40.]   []\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 6. 10. 19. 23. 28. 27.]   [27]\n",
      "20180809   [13 16 20 23 39 42 28]   [ 4. 18. 11. 25. 39. 27.]   [39]\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 4.  7. 11. 23. 33. 37.]   []\n",
      "20180816   [22 23 25 32 33 36 20]   [ 9. 14. 12. 30. 22. 46.]   [22]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [10.  8. 20. 17. 31. 42.]   [10 42]\n",
      "20180823   [ 2  3 23 30 39 41 19]   [ 5. 16. 23. 37. 33. 40.]   [23]\n",
      "20180827   [ 5  6 16 24 26 29 38]   [ 3.  8. 19. 12. 33. 29.]   [29]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 5.  9.  9. 28. 28. 40.]   [ 9 40]\n",
      "20180903   [ 4  5 13 18 39 40  3]   [ 4. 17.  9. 34. 36. 46.]   [4]\n",
      "20180906   [ 2 15 17 20 23 30 45]   [ 5.  7. 17. 20. 37. 44.]   [17 20]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [13.  9. 25. 29. 30. 36.]   [9]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [ 9. 10. 25. 22. 39. 42.]   []\n",
      "20180917   [16 21 22 24 25 27  1]   [ 3.  7.  9. 15. 38. 29.]   []\n",
      "20180920   [ 5 12 18 30 32 38 22]   [ 9.  6. 19. 20. 38. 36.]   [38]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [ 7.  6.  9. 20. 28. 45.]   [6]\n",
      "20180927   [ 2 25 29 33 42 45 20]   [ 7. 10. 11. 20. 48. 31.]   [20]\n",
      "20181001   [11 15 23 24 32 40 43]   [11. 22. 24. 20. 42. 29.]   [11 24]\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 9.  6. 10. 38. 27. 42.]   [42]\n",
      "20181008   [17 18 23 39 43 49  2]   [ 3. 12. 13. 20. 27. 28.]   []\n",
      "20181011   [ 1 16 18 24 29 46 35]   [ 3. 18. 26. 12. 44. 44.]   [18]\n",
      "20181015   [ 1  4 24 32 35 48 20]   [11. 21. 11. 27. 27. 44.]   []\n",
      "20181018   [ 5 14 17 31 46 48 47]   [10. 16. 15. 20. 32. 26.]   []\n",
      "20181022   [ 5 22 24 40 43 48  2]   [ 8. 21. 11. 15. 24. 44.]   [24]\n",
      "20181025   [ 7  8 13 15 35 48 30]   [ 7.  7. 13. 30. 46. 44.]   [ 7 13 30]\n",
      "20181029   [ 2  6 10 20 28 31 30]   [ 9. 10. 22. 22. 22. 45.]   [10]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [17. 17. 16. 31. 31. 29.]   []\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 5. 15. 16. 29. 26. 44.]   [26]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [13. 10. 22. 22. 22. 49.]   [13]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 3. 15.  9. 10. 35. 45.]   []\n",
      "20181115  Predicted:  [ 5.  6. 24. 29. 26. 33.]  \n",
      "20181119  Predicted:  [12.  7. 30. 20. 26. 36.]  \n",
      "20181122  Predicted:  [ 6. 13. 21. 35. 37. 45.]  \n",
      "20181126  Predicted:  [ 9.  7. 17. 17. 38. 40.]  \n",
      "20181129  Predicted:  [ 6. 12.  7. 20. 26. 36.]  \n",
      "20181203  Predicted:  [ 6. 14. 11. 22. 27. 34.]  \n",
      "20181206  Predicted:  [ 9. 14. 19. 20. 28. 36.]  \n",
      "20181210  Predicted:  [ 6. 15. 20. 38. 34. 42.]  \n",
      "20181213  Predicted:  [ 9. 15. 15. 20. 34. 36.]  \n",
      "20181217  Predicted:  [ 9. 15. 15. 31. 35. 44.]  \n",
      "20181220  Predicted:  [ 7.  7. 36. 30. 38. 49.]  \n",
      "20181224  Predicted:  [11.  7. 17. 19. 26. 36.]  \n",
      "20181227  Predicted:  [21. 23. 12. 22. 34. 29.]  \n",
      "20181231  Predicted:  [ 2. 14. 15. 27. 33. 49.]  \n",
      "62.264150943396224\n",
      "20180514   [17 24 29 45 46 49  5]   [16. 21. 22. 32. 30. 42.]   []\n",
      "20180517   [ 7 21 25 29 35 37 13]   [ 8. 17. 34. 28. 42. 43.]   []\n",
      "20180521   [ 8 10 16 30 37 44 17]   [ 6. 15. 15. 18. 40. 43.]   []\n",
      "20180524   [11 25 26 34 36 42 16]   [ 8. 17. 20. 23. 30. 45.]   []\n",
      "20180528   [ 5  9 27 28 30 44  2]   [ 8. 23. 13. 18. 34. 40.]   []\n",
      "20180531   [11 13 24 26 47 49 33]   [ 9. 15. 29. 31. 34. 41.]   []\n",
      "20180604   [20 22 31 37 43 45 27]   [11. 16. 24. 26. 29. 38.]   []\n",
      "20180607   [12 20 29 31 37 39 42]   [12. 19. 23. 30. 39. 41.]   [12 39]\n",
      "20180611   [16 25 30 37 44 49 34]   [ 9. 10. 25. 32. 40. 42.]   [25]\n",
      "20180614   [ 4 29 31 35 42 48  1]   [ 6. 23. 25. 32. 33. 36.]   []\n",
      "20180618   [11 15 22 23 26 43 25]   [10.  6. 16. 17. 41. 43.]   [43]\n",
      "20180621   [ 4  6 15 24 30 35 46]   [12. 22. 23. 28. 39. 42.]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [15. 18. 24. 27. 36. 40.]   []\n",
      "20180628   [ 2  7 22 27 40 47 48]   [10. 15. 27. 28. 41. 44.]   [27]\n",
      "20180702   [12 13 26 33 35 38 23]   [ 8. 15. 19. 20. 41. 45.]   []\n",
      "20180705   [ 8 11 28 30 32 34 39]   [ 9. 13. 17. 28. 39. 40.]   [28 39]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [12. 23. 26. 28. 39. 40.]   [23 39]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [14. 23. 29. 37. 45. 43.]   []\n",
      "20180716   [ 4  8 19 24 32 47 22]   [ 8. 19. 22. 24. 32. 41.]   [ 8 19 22 24 32]\n",
      "20180719   [13 14 23 35 37 46 45]   [10. 15. 25. 32. 40. 41.]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [23. 14. 33. 38. 39. 44.]   [23 39]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [11. 28. 30. 32. 34. 39.]   [28]\n",
      "20180730   [ 8 10 19 20 41 43  7]   [13. 12. 26. 33. 35. 38.]   []\n",
      "20180802   [ 1 10 15 27 41 46 35]   [ 3.  9. 25. 38. 44. 41.]   [41]\n",
      "20180806   [ 7 18 20 27 36 40 15]   [ 8. 15. 24. 30. 35. 41.]   [15]\n",
      "20180809   [13 16 20 23 39 42 28]   [15. 15. 23. 25. 40. 43.]   [23]\n",
      "20180813   [ 1  3  6 16 22 36 17]   [ 7. 22. 16. 27. 35. 43.]   [16 22]\n",
      "20180816   [22 23 25 32 33 36 20]   [25. 22. 28. 37. 32. 40.]   [22 25 32]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [20. 22. 26. 37. 33. 42.]   [42]\n",
      "20180823   [ 2  3 23 30 39 41 19]   [ 8. 15. 16. 37. 43. 45.]   []\n",
      "20180827   [ 5  6 16 24 26 29 38]   [12. 22. 26. 37. 33. 45.]   [26]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [ 5.  9. 27. 28. 30. 43.]   [ 9 27]\n",
      "20180903   [ 4  5 13 18 39 40  3]   [ 8. 15. 20. 34. 36. 45.]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [ 9. 16. 17. 30. 37. 44.]   [17 30]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [ 9. 21. 25. 29. 35. 45.]   [9]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [17. 24. 29. 29. 35. 45.]   [17]\n",
      "20180917   [16 21 22 24 25 27  1]   [ 8. 18. 19. 37. 36. 40.]   []\n",
      "20180920   [ 5 12 18 30 32 38 22]   [ 9. 18. 32. 27. 36. 45.]   [18 32]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [ 7. 22. 19. 27. 37. 45.]   []\n",
      "20180927   [ 2 25 29 33 42 45 20]   [ 7. 18. 23. 31. 31. 45.]   [45]\n",
      "20181001   [11 15 23 24 32 40 43]   [12. 17. 16. 31. 35. 45.]   []\n",
      "20181004   [ 5 12 23 32 37 42 43]   [ 9. 18. 26. 27. 36. 44.]   []\n",
      "20181008   [17 18 23 39 43 49  2]   [ 9. 18. 26. 31. 41. 45.]   [18]\n",
      "20181011   [ 1 16 18 24 29 46 35]   [ 9. 23. 26. 31. 41. 44.]   []\n",
      "20181015   [ 1  4 24 32 35 48 20]   [ 5. 18. 16. 27. 35. 45.]   [35]\n",
      "20181018   [ 5 14 17 31 46 48 47]   [17. 16. 24. 34. 27. 40.]   [17]\n",
      "20181022   [ 5 22 24 40 43 48  2]   [10. 18. 25. 32. 38. 45.]   []\n",
      "20181025   [ 7  8 13 15 35 48 30]   [ 9. 21. 22. 27. 31. 45.]   []\n",
      "20181029   [ 2  6 10 20 28 31 30]   [11. 21. 24. 32. 38. 45.]   []\n",
      "20181101   [ 6 27 28 41 44 48 15]   [11. 16. 27. 32. 27. 42.]   [27]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [ 8. 18. 29. 39. 38. 44.]   [8]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [10. 16. 26. 31. 27. 44.]   [16 26]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [ 7. 21. 25. 36. 36. 40.]   [21]\n",
      "20181115  Predicted:  [ 8.  6. 24. 31. 36. 43.]  \n",
      "20181119  Predicted:  [ 4. 24. 24. 31. 37. 44.]  \n",
      "20181122  Predicted:  [10. 18. 26. 27. 40. 39.]  \n",
      "20181126  Predicted:  [ 8. 13. 24. 36. 38. 44.]  \n",
      "20181129  Predicted:  [11. 24. 16. 31. 36. 40.]  \n",
      "20181203  Predicted:  [ 9. 18. 26. 32. 27. 42.]  \n",
      "20181206  Predicted:  [ 8. 25. 16. 27. 37. 44.]  \n",
      "20181210  Predicted:  [ 7. 22. 26. 33. 42. 45.]  \n",
      "20181213  Predicted:  [ 7. 11. 24. 31. 41. 40.]  \n",
      "20181217  Predicted:  [ 9. 18. 19. 32. 36. 44.]  \n",
      "20181220  Predicted:  [ 6. 18. 16. 34. 36. 45.]  \n",
      "20181224  Predicted:  [ 8. 14. 12. 33. 33. 44.]  \n",
      "20181227  Predicted:  [ 9. 14. 24. 31. 32. 44.]  \n",
      "20181231  Predicted:  [10. 18. 29. 31. 36. 45.]  \n"
     ]
    }
   ],
   "source": [
    "#Keep track of all results\n",
    "#df_predictions = []\n",
    "\n",
    "#print(df_predictions)\n",
    "#mtr = MyTotoResearch(algo_no=1)\n",
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'L','M','S','R','E','A','V' ,'J','U','K']\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "    return X\n",
    "\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "test_data = mtr.get_test_data()\n",
    "X = mtr.modified_dataset(getAllData(test_data)) #\n",
    "\n",
    "print(len(df_predictions))\n",
    "for n in range(len(df_predictions)):\n",
    "    print( mtr.getAccuracyCount(np.array(df_predictions[n])))\n",
    "    mtr.print_predictions(df_predictions[n])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
