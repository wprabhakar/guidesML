{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:4900: ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/jovyan/.keras/keras.json' mode='r' encoding='UTF-8'>\n",
      "  _config = json.load(open(_config_path))\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#Predict smallest Number\n",
    "\n",
    "#!conda install -n mldds -c anaconda joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"Cores: \", num_cores)\n",
    "\n",
    "import time\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': num_cores} )\n",
    "# sess = tf.Session(config=config) \n",
    "# keras.backend.set_session(sess)\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from MyTotoResearchv4 import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllData(df):\n",
    "    drop_cols = ['T', 'D', 'N1','N2','N3','N4','N5','N6','N7','L','M','S','R','E','A','V' ,'J','U']\n",
    "    drop_cols = ['D', 'N1','N2','N3','N4','N5','N6','N7', 'Ph', 'il', 'age', 'dist', 'adia', 'sundist', 'sunadia' ]\n",
    "\n",
    "#     Ph         1521 non-null float64\n",
    "# il         1521 non-null float64\n",
    "# age        1521 non-null float64\n",
    "# dist       1521 non-null float64\n",
    "# adia       1521 non-null float64\n",
    "# sundist    1521 non-null float64\n",
    "# sunadia    1521 non-null float64\n",
    "\n",
    "#    drop_cols = ['T', 'D', 'M','S','R','E','A','V' ,'J','U']\n",
    "\n",
    "\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "\n",
    "#     df1 = df[['N1','N2','N3','N4','N5','N6','N7']]\n",
    "#     X['smallest'] = df1.min(axis=1)\n",
    "#     X['biggest'] = df1.max(axis=1)\n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MyTotoResearch algo_no:  1\n",
      "1521\n",
      "             D  N1  N2  N3  N4  N5  N6  N7\n",
      "0     20040212  42  36  29  21  18  10   3\n",
      "1     20040216  45  41  40  39  22   8   6\n",
      "2     20040219  36  35  21  17  15   8   5\n",
      "3     20040223  39  38  28  23  21  20   6\n",
      "4     20040226  44  40  26  25  16  10   3\n",
      "5     20040301  29  28  27  25  22  20  14\n",
      "6     20040304  43  41  40  25   7   6   2\n",
      "7     20040308  44  42  21  19  18  17   2\n",
      "8     20040311  43  36  34  26  24  18  10\n",
      "9     20040315  45  35  32  16  13   9   1\n",
      "10    20040318  43  42  40  31  21  17   6\n",
      "11    20040322  35  28  27  23  22  21  16\n",
      "12    20040325  43  38  37  20  18  13   6\n",
      "13    20040329  32  24  19   7   6   2   1\n",
      "14    20040401  40  39  31  28  27   9   3\n",
      "15    20040405  33  16  15  13  12   7   4\n",
      "16    20040408  39  36  33  30  25  11   4\n",
      "17    20040412  37  32  29  16  10   8   2\n",
      "18    20040415  34  32  26  19   9   3   2\n",
      "19    20040419  45  39  36  26  18  15  10\n",
      "20    20040422  37  26  23  14   8   6   5\n",
      "21    20040426  41  37  25  24  18  15   7\n",
      "22    20040429  43  32  31  22  18  10   6\n",
      "23    20040503  37  33  20  12   9   4   3\n",
      "24    20040506  34  30  27  23  20  11   5\n",
      "25    20040510  41  21  19  16   8   6   2\n",
      "26    20040513  45  35  24  21  16  13  11\n",
      "27    20040517  28  21  17  13  10   6   2\n",
      "28    20040520  45  36  32  25  23  20  17\n",
      "29    20040524  44  40  33  21  16   7   6\n",
      "...        ...  ..  ..  ..  ..  ..  ..  ..\n",
      "1491  20180827  38  29  26  24  16   6   5\n",
      "1492  20180823  41  39  30  23  19   3   2\n",
      "1493  20180820  42  40  38  25  10   9   2\n",
      "1494  20180816  36  33  32  25  23  22  20\n",
      "1495  20180813  36  22  17  16   6   3   1\n",
      "1496  20180809  42  39  28  23  20  16  13\n",
      "1497  20180806  40  36  27  20  18  15   7\n",
      "1498  20180802  46  41  35  27  15  10   1\n",
      "1499  20180730  43  41  20  19  10   8   7\n",
      "1500  20180726  40  37  28  17  13   9   1\n",
      "1501  20180723  40  39  28  26  23  12   2\n",
      "1502  20180719  46  45  37  35  23  14  13\n",
      "1503  20180716  47  32  24  22  19   8   4\n",
      "1504  20180712  41  40  32  25  15  10   4\n",
      "1505  20180709  43  39  38  33  31  23   6\n",
      "1506  20180705  39  34  32  30  28  11   8\n",
      "1507  20180702  38  35  33  26  23  13  12\n",
      "1508  20180625  48  44  38  25   9   3   2\n",
      "1509  20180621  46  35  30  24  15   6   4\n",
      "1510  20180618  43  26  25  23  22  15  11\n",
      "1511  20180614  48  42  35  31  29   4   1\n",
      "1512  20180611  49  44  37  34  30  25  16\n",
      "1513  20180607  42  39  37  31  29  20  12\n",
      "1514  20180604  45  43  37  31  27  22  20\n",
      "1515  20180531  49  47  33  26  24  13  11\n",
      "1516  20180528  44  30  28  27   9   5   2\n",
      "1517  20180524  42  36  34  26  25  16  11\n",
      "1518  20180521  44  37  30  17  16  10   8\n",
      "1519  20180517  37  35  29  25  21  13   7\n",
      "1520  20180514  49  46  45  29  24  17   5\n",
      "\n",
      "[1521 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "mtr = MyTotoResearch(algo_no=1)\n",
    "lresult, df = mtr.load_totodata()\n",
    "\n",
    "X = mtr.modified_dataset(getAllData(df)) #\n",
    "\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #X.feature_names\n",
    "# #X = df.drop(drop_cols, axis=1)\n",
    "# df1 = df[['N1','N2','N3','N4','N5','N6','N7']]\n",
    "# y = pd.DataFrame()\n",
    "# y['Smallest'] = df1.min(axis=1)\n",
    "# l_encoder = LabelEncoder()\n",
    "# y['Smallest'] = l_encoder.fit_transform(y['Smallest'])\n",
    "\n",
    "# y\n",
    "\n",
    "# t_X = pd.DataFrame()\n",
    "# t_X['M'] = (X['S']+X['M'])%360.0\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(t_X)\n",
    "\n",
    "# #X_scaled = scaler.transform(t_X)\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# clf = SVC(max_iter=50000, tol=1e-5,\n",
    "#                      random_state=8, gamma='scale')\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# clf = LinearRegression()\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# # clf = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "# #        early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "# #        l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=10000,\n",
    "# #        n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "# #        power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "# #        validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "# clf.fit(X_scaled, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_scaled, y,color='g')\n",
    "# #plt.plot(X, clf.predict(t_X),color='b')\n",
    "\n",
    "# #plt.scatter(y, X, color='r')\n",
    "# #plt.plot(y, X, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Predicted'] = clf.predict(X_scaled)\n",
    "# df['Y'] = y\n",
    "# #df['Y'] = l_encoder.inverse_transform(y)\n",
    "\n",
    "\n",
    "# print(df.loc[:,['Predicted', 'Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.learndatasci.com/tutorials/predicting-housing-prices-linear-regression-using-python-pandas-statsmodels/\n",
    "    \n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.formula.api import ols\n",
    "# from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# %matplotlib inline\n",
    "# sns.set_style(\"darkgrid\")\n",
    "\n",
    "# X['Smallest'] = df1.min(axis=1)\n",
    "\n",
    "\n",
    "# # fit our model with .fit() and show results\n",
    "# # we use statsmodels' formula API to invoke the syntax below,\n",
    "# # where we write out the formula using ~\n",
    "# p_model = ols(\"Smallest ~ L + S + M + R + A + E + V + J\", data=X).fit()\n",
    "\n",
    "# # summarize our model\n",
    "# p_model_summary = p_model.summary()\n",
    "\n",
    "# # convert our table to HTML and add colors to headers for explanatory purposes\n",
    "# HTML(\n",
    "# (p_model_summary\n",
    "#     .as_html()\n",
    "#     .replace('<th>  Adj. R-squared:    </th>', '<th style=\"background-color:#aec7e8;\"> Adj. R-squared: </th>')\n",
    "#     .replace('<th>coef</th>', '<th style=\"background-color:#ffbb78;\">coef</th>')\n",
    "#     .replace('<th>std err</th>', '<th style=\"background-color:#c7e9c0;\">std err</th>')\n",
    "#     .replace('<th>P>|t|</th>', '<th style=\"background-color:#bcbddc;\">P>|t|</th>')\n",
    "#     .replace('<th>[0.025</th>    <th>0.975]</th>', '<th style=\"background-color:#ff9896;\">[0.025</th>    <th style=\"background-color:#ff9896;\">0.975]</th>'))\n",
    "# )\n",
    "\n",
    "# # This produces our four regression plots for total_unemployed\n",
    "\n",
    "# fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "# # pass in the model as the first parameter, then specify the \n",
    "# # predictor variable we want to analyze\n",
    "# fig = plt.figure(figsize=(20,12))\n",
    "# fig = sm.graphics.plot_partregress_grid(p_model, fig=fig)\n",
    "\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.loc[:,['V']]\n",
    "# X[X['J'] < 0] \n",
    "# from sklearn import linear_model\n",
    "# clf = linear_model.Ridge(alpha=.5)\n",
    "# clf = linear_model.Lasso()\n",
    "# clf = linear_model.BayesianRidge()\n",
    "\n",
    "# clf.fit(X_scaled, y)\n",
    "# df['Predicted'] = clf.predict(X_scaled)\n",
    "# df['Y'] = y\n",
    "# #df['Y'] = l_encoder.inverse_transform(y)\n",
    "\n",
    "\n",
    "# print(df.loc[:,['Predicted', 'Y']])\n",
    "#df.loc[:,['T','N1','N2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:55: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# #X.feature_names\n",
    "# #X = df.drop(drop_cols, axis=1)\n",
    "# df1 = df[['T','N1','N2','N3','N4','N5','N6','N7']]\n",
    "# print(df.head())\n",
    "# y = pd.DataFrame(index=df.index)\n",
    "# y['N1'] = df['N1']\n",
    "# #df1.min(axis=1)\n",
    "# l_encoder = LabelEncoder()\n",
    "# y['N1'] = l_encoder.fit_transform(y['N1'])\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # scaler.fit(X)\n",
    "\n",
    "# # X_scaled = scaler.transform(X)\n",
    "# X_scaled = X\n",
    "\n",
    "# model.fit(X_scaled, y)\n",
    "\n",
    "# #result = df[['N1']].copy()\n",
    "# result = pd.DataFrame(index=df.index)\n",
    "# result['N1'] = y\n",
    "# result['N1_P'] = model.predict(X_scaled).round()\n",
    "# #print(result.round(['Smallest_P']))\n",
    "\n",
    "\n",
    "# #print(result)\n",
    "\n",
    "\n",
    "# y = pd.DataFrame(index=df.index)\n",
    "# y['N2'] = df['N2']\n",
    "# #df1.max(axis=1)\n",
    "# l_encoder = LabelEncoder()\n",
    "# y['N2'] = l_encoder.fit_transform(y['N2'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "# # X_scaled = scaler.transform(X)\n",
    "# X_scaled = X\n",
    "\n",
    "# model.fit(X_scaled, y)\n",
    "# result['N2'] = y\n",
    "# result['N2_P'] = model.predict(X_scaled).round()\n",
    "\n",
    "# print(result)\n",
    "\n",
    "# print(X_scaled.info())\n",
    "\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "X_scaled = X\n",
    "\n",
    "l_encoder = LabelEncoder()\n",
    "result = pd.DataFrame(index=df.index)\n",
    "result['T'] = df['T']\n",
    "\n",
    "test_data = mtr.get_test_data()\n",
    "\n",
    "import array as arr\n",
    "\n",
    "model_store = []\n",
    "\n",
    "for i in range(1,8):\n",
    "    y = pd.DataFrame(index=df.index)\n",
    "    y['N'+str(i)] = df['N'+str(i)]\n",
    "#    y['N'+str(i)] = l_encoder.fit_transform(df['N'+str(i)])\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=4)),\n",
    "                        ('linear', LinearRegression(fit_intercept=False))])\n",
    "    #                   ('linear', LinearRegression())])\n",
    "    model.fit(X_scaled, y)\n",
    "    model_store.append(model)\n",
    "#    result['N'+str(i)] = y\n",
    "    result['N'+str(i)+'_P'] = model.predict(X_scaled).round()\n",
    "#     result['N'+str(i)+'_P0'] = result['N'+str(i)+'_P']-1\n",
    "#     result['N'+str(i)+'_P1'] = result['N'+str(i)+'_P']+1\n",
    "\n",
    "\n",
    "\n",
    "#print(result)\n",
    "\n",
    "#df['Predicted'] = model.predict(X_scaled)\n",
    "#df['Y'] = y\n",
    "#df['Y'] = l_encoder.inverse_transform(y)\n",
    "\n",
    "#print(df.loc[:,['Predicted', 'Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['T', 'N1_P', 'N2_P', 'N3_P', 'N4_P', 'N5_P', 'N6_P', 'N7_P'], dtype='object')\n",
      "Accuracy:  75.47169811320755\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = result.columns #['N'+str(i)+'_P' for i in range(1,8)]\n",
    "print(result.columns)\n",
    "# d_T = ['T']\n",
    "# columns = columns + d_T\n",
    "my_prediction = pd.DataFrame(result, columns=columns)\n",
    "\n",
    "# my_prediction['N1_P0'] = my_prediction['N1_P']-1\n",
    "# my_prediction['N2_P0'] = my_prediction['N2_P']-1\n",
    "# my_prediction['N3_P0'] = my_prediction['N3_P']-1\n",
    "# my_prediction['N4_P0'] = my_prediction['N4_P']-1\n",
    "# my_prediction['N5_P0'] = my_prediction['N5_P']-1\n",
    "# my_prediction['N6_P0'] = my_prediction['N6_P']-1\n",
    "# my_prediction['N7_P0'] = my_prediction['N7_P']-1\n",
    "\n",
    "\n",
    "# my_prediction['N1_P1'] = my_prediction['N1_P']+1\n",
    "# my_prediction['N2_P1'] = my_prediction['N2_P']+1\n",
    "# my_prediction['N3_P1'] = my_prediction['N3_P']+1\n",
    "# my_prediction['N4_P1'] = my_prediction['N4_P']+1\n",
    "# my_prediction['N5_P1'] = my_prediction['N5_P']+1\n",
    "# my_prediction['N6_P1'] = my_prediction['N6_P']+1\n",
    "# my_prediction['N7_P1'] = my_prediction['N7_P']+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for col in columns:\n",
    "    my_prediction[col] = my_prediction[col].apply(lambda x: int(x) if x == x else \"\")\n",
    "    \n",
    "#print(my_prediction)\n",
    "print ( \"Accuracy: \",  mtr.getAccuracyCount(np.array(my_prediction)))\n",
    "mtr.plot_matched_counts(my_prediction.values)\n",
    "\n",
    "#mtr.print_predictions(my_prediction.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180514   [17 24 29 45 46 49  5]   [43 35 26 24 14 11  3]   [24]\n",
      "20180517   [ 7 21 25 29 35 37 13]   [43 35 26 24 14 11  4]   [35]\n",
      "20180521   [ 8 10 16 30 37 44 17]   [43 36 27 24 15 11  4]   []\n",
      "20180524   [11 25 26 34 36 42 16]   [43 37 28 25 16 11  4]   [11 16 25]\n",
      "20180528   [ 5  9 27 28 30 44  2]   [43 38 30 25 17 11  5]   [ 5 30]\n",
      "20180531   [11 13 24 26 47 49 33]   [43 38 31 26 18 12  5]   [26]\n",
      "20180604   [20 22 31 37 43 45 27]   [44 39 32 26 20 12  6]   [20]\n",
      "20180607   [12 20 29 31 37 39 42]   [44 40 34 27 21 12  7]   [12]\n",
      "20180611   [16 25 30 37 44 49 34]   [43 37 29 24 16 11  5]   [16 37]\n",
      "20180614   [ 4 29 31 35 42 48  1]   [43 37 29 24 17 11  6]   [29]\n",
      "20180618   [11 15 22 23 26 43 25]   [43 38 30 25 18 11  6]   [11 25 43]\n",
      "20180621   [ 4  6 15 24 30 35 46]   [44 38 31 25 19 12  7]   []\n",
      "20180625   [ 2  5 25 38 44 48  9]   [44 39 32 26 20 12  7]   [44]\n",
      "20180628   [ 2  7 22 27 40 47 48]   [44 40 33 26 21 12  7]   [ 7 40]\n",
      "20180702   [12 13 26 33 35 38 23]   [45 41 35 27 22 13  8]   [13 35]\n",
      "20180705   [ 8 11 28 30 32 34 39]   [45 42 36 27 23 13  8]   [8]\n",
      "20180709   [ 6 23 31 38 39 43 33]   [44 37 30 24 17 11  6]   [6]\n",
      "20180712   [ 4 15 25 32 40 41 10]   [44 37 30 24 17 12  7]   []\n",
      "20180716   [ 4  8 19 24 32 47 22]   [44 38 31 25 18 12  7]   []\n",
      "20180719   [13 14 23 35 37 46 45]   [44 38 31 25 19 12  7]   []\n",
      "20180723   [ 2 23 26 28 39 40 12]   [45 39 32 26 20 12  7]   [12 26 39]\n",
      "20180726   [ 1  9 13 17 28 40 37]   [45 39 33 26 20 12  7]   []\n",
      "20180730   [ 8 10 19 20 41 43  7]   [45 40 34 27 21 13  8]   [8]\n",
      "20180802   [ 1 10 15 27 41 46 35]   [46 41 35 27 22 13  8]   [27 35 41 46]\n",
      "20180806   [ 7 18 20 27 36 40 15]   [44 37 29 24 16 12  6]   []\n",
      "20180809   [13 16 20 23 39 42 28]   [44 37 30 24 17 12  6]   []\n",
      "20180813   [ 1  3  6 16 22 36 17]   [44 37 30 25 17 12  6]   [ 6 17]\n",
      "20180816   [22 23 25 32 33 36 20]   [45 37 31 25 18 12  6]   [25]\n",
      "20180820   [ 9 10 25 38 40 42  2]   [45 38 31 26 19 12  6]   [38]\n",
      "20180823   [ 2  3 23 30 39 41 19]   [45 38 32 26 19 12  6]   [19]\n",
      "20180827   [ 5  6 16 24 26 29 38]   [46 39 33 27 20 12  6]   [6]\n",
      "20180830   [ 3  9 27 29 31 40 46]   [45 37 30 24 17 12  5]   []\n",
      "20180903   [ 4  5 13 18 39 40  3]   [45 37 30 24 17 12  6]   []\n",
      "20180906   [ 2 15 17 20 23 30 45]   [45 38 31 25 18 12  6]   [45]\n",
      "20180910   [ 2  6  9 15 40 43 18]   [45 38 32 25 18 12  6]   [ 6 18]\n",
      "20180913   [ 6 16 17 40 44 48 34]   [45 39 32 25 19 12  6]   [6]\n",
      "20180917   [16 21 22 24 25 27  1]   [45 40 33 26 20 12  6]   []\n",
      "20180920   [ 5 12 18 30 32 38 22]   [46 40 34 26 21 12  7]   [12]\n",
      "20180924   [ 6  8 17 24 29 47 34]   [46 41 36 27 22 13  7]   []\n",
      "20180927   [ 2 25 29 33 42 45 20]   [45 39 32 25 18 12  6]   [25 45]\n",
      "20181001   [11 15 23 24 32 40 43]   [45 39 32 25 19 12  6]   [32]\n",
      "20181004   [ 5 12 23 32 37 42 43]   [45 39 33 25 19 12  7]   [12]\n",
      "20181008   [17 18 23 39 43 49  2]   [45 40 33 25 20 12  7]   []\n",
      "20181011   [ 1 16 18 24 29 46 35]   [45 40 34 26 21 12  7]   []\n",
      "20181015   [ 1  4 24 32 35 48 20]   [45 41 35 26 22 13  8]   [35]\n",
      "20181018   [ 5 14 17 31 46 48 47]   [46 42 36 26 23 13  8]   [46]\n",
      "20181022   [ 5 22 24 40 43 48  2]   [46 43 38 27 24 14  9]   [24 43]\n",
      "20181025   [ 7  8 13 15 35 48 30]   [45 39 33 25 19 12  7]   [7]\n",
      "20181029   [ 2  6 10 20 28 31 30]   [44 40 34 25 20 12  7]   [20]\n",
      "20181101   [ 6 27 28 41 44 48 15]   [44 40 34 25 20 13  7]   [44]\n",
      "20181105   [ 3  8 14 28 43 49 26]   [44 40 35 26 21 13  8]   [ 8 26]\n",
      "20181108   [ 8 13 16 26 28 38 46]   [44 41 36 26 22 13  8]   [ 8 13 26]\n",
      "20181112   [ 4 12 21 34 41 47 33]   [45 42 37 26 23 13  9]   []\n",
      "20181115  Predicted:  [45 42 38 26 24 14  9]  \n",
      "20181119  Predicted:  [45 44 39 27 26 14 10]  \n",
      "20181122  Predicted:  [44 40 34 26 20 13  7]  \n",
      "20181126  Predicted:  [44 41 35 26 21 13  8]  \n",
      "20181129  Predicted:  [44 41 36 26 21 13  8]  \n",
      "20181203  Predicted:  [44 42 37 26 22 13  8]  \n",
      "20181206  Predicted:  [44 42 37 26 23 13  9]  \n",
      "20181210  Predicted:  [44 43 39 27 24 13  9]  \n",
      "20181213  Predicted:  [45 43 40 27 25 13  9]  \n",
      "20181217  Predicted:  [45 44 41 27 26 14 10]  \n",
      "20181220  Predicted:  [44 42 36 26 21 13  8]  \n",
      "20181224  Predicted:  [44 42 37 26 21 13  8]  \n",
      "20181227  Predicted:  [44 42 37 26 22 13  8]  \n",
      "20181231  Predicted:  [44 42 38 26 23 13  9]  \n"
     ]
    }
   ],
   "source": [
    "test_data = mtr.get_test_data()\n",
    "#X_test = mtr.modified_dataset(getAllData(test_data)) #\n",
    "X_test = test_data\n",
    "#scaler.fit(X_test)\n",
    "#X_test_scaled = scaler.transform(X_test[X.columns])\n",
    "X_test_scaled = X_test[X.columns]\n",
    "test_result = pd.DataFrame(index=X_test.index)\n",
    "test_result['T'] = X_test_scaled['T']\n",
    "\n",
    "for i in range(1,8):\n",
    "    test_result['N'+str(i)+'_P'] = model_store[i-1].predict(X_test_scaled).round()\n",
    "#     test_result['N'+str(i)+'_P0'] = test_result['N'+str(i)+'_P']-1\n",
    "#     test_result['N'+str(i)+'_P1'] = test_result['N'+str(i)+'_P']+1\n",
    "\n",
    "\n",
    "#mtr.print_result(test_result)\n",
    "mtr.print_predictions(test_result.astype(int))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
