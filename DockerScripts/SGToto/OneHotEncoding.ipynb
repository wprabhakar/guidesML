{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SGH.csv', 'PPv3.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import utils, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier, Ridge\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "#from skmultilearn.adapt import MLkNN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "#from sklearn.linear_model import RidgeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Compare Algorithms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "#warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings\n",
    "#warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "\n",
    "seed = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(prediction, actual):\n",
    "    matched = []\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "        matched.append(len(set(p.astype(int)) & set(a)))\n",
    "    return matched\n",
    "\n",
    "def getPercent(prediction, actual, n):\n",
    "    matched = []\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "        matched.append(set(p.astype(int)) & set(a))\n",
    "    return sum(len(num) > n for num in matched)/len(matched)*100.00\n",
    "\n",
    "def getCounts(prediction, actual):\n",
    "    matched = []\n",
    "    N = [0,0,0,0,0,0,0,0]\n",
    "    if len(prediction) == 0: return N\n",
    "    for (a,p) in zip(actual, prediction):\n",
    "        matched.append(set(p.astype(int)) & set(a))\n",
    "    if len(matched) == 0:\n",
    "        return N\n",
    "    N[0] = sum(len(num) > 0 for num in matched)/len(matched)*100.00\n",
    "    N[1] = sum(len(num) > 1 for num in matched)/len(matched)*100.00\n",
    "    N[2] = sum(len(num) > 2 for num in matched)/len(matched)*100.00\n",
    "    N[3] = sum(len(num) > 3 for num in matched)/len(matched)*100.00\n",
    "    N[4] = sum(len(num) > 4 for num in matched)/len(matched)*100.00\n",
    "    N[5] = sum(len(num) > 5 for num in matched)/len(matched)*100.00\n",
    "    N[6] = sum(len(num) > 6 for num in matched)/len(matched)*100.00\n",
    "    N[7] = sum(len(num) > 7 for num in matched)/len(matched)*100.00\n",
    "#    matched.extend(N)\n",
    "    return N\n",
    "\n",
    "\n",
    "def getAccuracy1dCount(prediction, actual):\n",
    "    iMatched = 0\n",
    "    print(len(prediction))\n",
    "    for i in range(0,len(prediction)):\n",
    "        if prediction[i] == actual[i]:\n",
    "            iMatched = iMatched +1\n",
    "    return iMatched\n",
    "\n",
    "def getAccuracy1dPercentCorrect(prediction, actual):\n",
    "    iMatched = 0\n",
    "    print(len(prediction))\n",
    "    for i in range(0,len(prediction)):\n",
    "        if prediction[i] == actual[i]:\n",
    "            iMatched = iMatched +1\n",
    "    return iMatched/len(prediction) * 100.0\n",
    "\n",
    "\n",
    "def getAccuracyCount(prediction, actual):\n",
    "    matched = []\n",
    "    if len(prediction) == 0: return 0\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "#        print ( \"p: \", p, \" a: \", a, (set(p.astype(int)) & set(a)) )\n",
    "        matched.append((set(p.astype(int)) & set(a)))\n",
    "    return sum(len(num) > 0 for num in matched)/len(matched)*100.00\n",
    "\n",
    "def getIntersection(p1, p2):\n",
    "    return [reduce(np.intersect1d, (p.astype(int), a.astype(int))) for (p,a) in zip(p1, p2)]\n",
    "\n",
    "def getUnion(p1, p2):\n",
    "    if len(p1) == 0: return p2\n",
    "    return [reduce(np.union1d, (p.astype(int), a.astype(int))) for (p,a) in zip(p1, p2)]\n",
    "\n",
    "def getUnion1dArray(p1,p2):\n",
    "    return reduce(np.union1d, (p1,p2))\n",
    "\n",
    "def getIntersection1dArray(prediction, actual):\n",
    "    iMatched = 0\n",
    "#     return reduce(np.intersect1d,([prediction,actual]))\n",
    "#     for idx, i in enumerate(prediction):\n",
    "#       if prediction[idx] == actual[idx]:\n",
    "#         iMatched = iMatched + 1\n",
    "#     return iMatched\n",
    "\n",
    "# def getAccuracy1dCount(prediction, actual):\n",
    "#     iMatched = 0\n",
    "#     for idx in enumerate(prediction):\n",
    "#       if prediction[idx] == actual[idx]:\n",
    "#         iMatched = iMatched + 1\n",
    "#     return iMatched\n",
    "\n",
    "\n",
    "\n",
    "def unionPrediction(ff):\n",
    "    predicted = []\n",
    "    for i, f in enumerate(ff):\n",
    "#        i_index = name_.index(sInputDir + f + '.csv')        \n",
    "        i_index = name_.index(f)        \n",
    "        if i == 0: predicted = list_[i_index][cols].values\n",
    "        if i > 0:\n",
    "            predicted = getUnion(predicted,list_[i_index][cols].values)\n",
    "    return predicted\n",
    "\n",
    "def getMatches(prediction, actual):\n",
    "    matched = []\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "        print ( len(p), \"** p: \", p, \" a: \", a, (set(p.astype(int)) & set(a)) )\n",
    "        matched.append((set(p.astype(int)) & set(a)))\n",
    "    return matched\n",
    "\n",
    "def getMatchedCount(prediction, actual):\n",
    "    return getAccuracyCount(prediction, actual)\n",
    "\n",
    "def printPredictions ( prediction, actual ):\n",
    "    for (p,a) in zip(prediction, actual):\n",
    "        print ( '[',len(set(p.astype(int) )&set(a.astype(int))),'/',len(p),'',set(p.astype(int) ), ' ', set(a.astype(int)), ' ', set(p.astype(int) )&set(a.astype(int)))\n",
    "\n",
    "def bins_labels(bins, **kwargs):\n",
    "    bin_w = (max(bins) - min(bins)) / (len(bins) - 1)\n",
    "    plt.xticks(np.arange(min(bins)+bin_w/2, max(bins), bin_w), bins, **kwargs)\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "def getColums (idx):\n",
    "    return list(os.path.splitext(basename(name_[idx]))[0][2:])\n",
    "\n",
    "\n",
    "def showResult(str_alg, prediction, actual ):\n",
    "    print( str_alg, \" Accuracy predict 1 in 7: \", getAccuracy(prediction, actual))\n",
    "\n",
    "def printResult(predictions, actual):\n",
    "    df_result=pd.DataFrame({ 'Predicted':list(predictions), 'Actual':list(actual)})\n",
    "    print(df_result)  \n",
    "    \n",
    "def getStdDeviationOfPrediction(ytestPredicted, y_test):\n",
    "    print(\"Removing invalid predictions ( < 0 )\")\n",
    "    ind2remove = np.where(ytestPredicted <= 0)[0]\n",
    "    ytestPredictedFinal = np.delete(ytestPredicted, ind2remove)\n",
    "    y_testFinal = np.delete(y_test, ind2remove)\n",
    "    iM = getAccuracy1dCount(y_testFinal, ytestPredictedFinal)\n",
    "    print(iM)   \n",
    "    print(np.std(ytestPredictedFinal-y_testFinal))\n",
    "\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             T           L  Lg  Lt  Ls  Lb           S  Sg  St  Ss ...  \\\n",
      "1547  20181217  300.014568   7   5   3   3  359.526457   6   3   7 ...   \n",
      "1548  20181220  302.236280   7   5  12  11   40.189495   4   2   2 ...   \n",
      "1549  20181224  305.200567   7   5   1   6   98.931481   2   7   4 ...   \n",
      "1550  20181227  307.425821   7  11  11   7  142.704093   1   4   7 ...   \n",
      "1551  20181231  310.396111   7  11   6  11  197.112557   4  11   4 ...   \n",
      "\n",
      "               U  Ug  Ut  Us  Ub           K  Kg  Kt  Ks  Kb  \n",
      "1547  255.692043   6   4   1  11  274.279218   7   1   7   2  \n",
      "1548  256.040966   6   4   1   3  274.120357   7   1   7   1  \n",
      "1549  256.509451   6   4   2  11  273.908541   7   1   7   4  \n",
      "1550  256.862581   6   4   2   7  273.749679   7   1   7  12  \n",
      "1551  257.334785   6   4   5   5  273.537864   7   1   7   3  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "1521\n",
      "[[ 3. 10. 18. ... 29. 36. 42.]\n",
      " [ 6.  8. 22. ... 40. 41. 45.]\n",
      " [ 5.  8. 15. ... 21. 35. 36.]\n",
      " ...\n",
      " [ 8. 10. 16. ... 30. 37. 44.]\n",
      " [ 7. 13. 21. ... 29. 35. 37.]\n",
      " [ 5. 17. 24. ... 45. 46. 49.]]\n",
      "[[ 3. 10. 18. ... 29. 36. 42.]\n",
      " [ 6.  8. 22. ... 40. 41. 45.]\n",
      " [ 5.  8. 15. ... 21. 35. 36.]\n",
      " ...\n",
      " [ 8. 10. 16. ... 30. 37. 44.]\n",
      " [ 7. 13. 21. ... 29. 35. 37.]\n",
      " [ 5. 17. 24. ... 45. 46. 49.]]\n",
      "Printing\n",
      "[[10.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " ...\n",
      " [10.]\n",
      " [13.]\n",
      " [17.]]\n",
      "[10  8  8 ... 10 13 17]\n"
     ]
    }
   ],
   "source": [
    "pp = pd.read_csv('../input/PPv3.csv')\n",
    "print(pp.tail())\n",
    "\n",
    "lr = pd.read_csv('../input/SGH.csv')\n",
    "#print(lr.describe())\n",
    "\n",
    "#print(lr)\n",
    "\n",
    "#print(len(lr))\n",
    "#lr = lr.sort_values(by=['D'])\n",
    "#lr = lr.drop_duplicates () ;\n",
    "print(len(lr))\n",
    "cols = ['D', 'N1','N2','N3','N4','N5','N6','N7']\n",
    "lr = lr[cols]\n",
    "#print(lr.head(30))\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "df = pd.concat([pp, lr], axis=1, sort=False)\n",
    "df = df.dropna()\n",
    "#print(len(df))\n",
    "#df.head()\n",
    "df.reset_index().drop(['D'], axis=1)\n",
    "\n",
    "cols = ['N1','N2','N3','N4','N5','N6','N7']\n",
    "lr = df[cols]\n",
    "\n",
    "\n",
    "# cols = ['L','M','S','R','E','A','V' ,'J','U']\n",
    "# cols = ['L', 'M', 'R', 'J', 'U']\n",
    "# X = df[cols]\n",
    "\n",
    "X = df\n",
    "#Remove T, D and Results\n",
    "drop_cols = ['T','D','N1','N2','N3','N4','N5','N6','N7','L','M','S','R','E','A','V' ,'J','U','K']\n",
    "X = X.drop(drop_cols, axis=1)\n",
    "related_X = X\n",
    "dataset = related_X\n",
    "\n",
    "lresult = np.sort(lr.values[:, ::-1])\n",
    "print(lresult)\n",
    "\n",
    "col_n = 2  #Column Number interested\n",
    "print(lresult)\n",
    "aa = np.delete(lresult, np.s_[col_n:], axis=1)  \n",
    "aa = np.delete(aa, np.s_[0:col_n-1], axis=1)  \n",
    "print('Printing')\n",
    "print(aa)\n",
    "#Convert 2d array to Dataframe\n",
    "y = pd.DataFrame(aa, columns=list('N'))\n",
    "y.head()\n",
    "y = aa.astype(int).ravel()\n",
    "print ( y )\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n",
    "#print(model.summary())\n",
    "corr = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3. 10. 18. ... 29. 36. 42.]\n",
      " [ 6.  8. 22. ... 40. 41. 45.]\n",
      " [ 5.  8. 15. ... 21. 35. 36.]\n",
      " ...\n",
      " [ 8. 10. 16. ... 30. 37. 44.]\n",
      " [ 7. 13. 21. ... 29. 35. 37.]\n",
      " [ 5. 17. 24. ... 45. 46. 49.]]\n",
      "[3 6 5 ... 8 7 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "col_n = 1  #Column Number interested\n",
    "print(lresult)\n",
    "aa = np.delete(lresult, np.s_[col_n:], axis=1)  \n",
    "aa = np.delete(aa, np.s_[0:col_n-1], axis=1)  \n",
    "\n",
    "# 1. INSTANTIATE\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(aa)\n",
    "\n",
    "# 3. Transform\n",
    "onehotlabels = enc.transform(aa).toarray()\n",
    "onehotlabels.shape\n",
    "#print(onehotlabels)\n",
    "\n",
    "#Convert 2d array to Dataframe\n",
    "y = pd.DataFrame(aa, columns=list('N'))\n",
    "y.head()\n",
    "y = aa.astype(int).ravel()\n",
    "print ( y )\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on <class 'pandas.core.indexes.numeric.Int64Index'> with these indexers [[[0. 0. 1. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 1.]]] of <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f09db90de2c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehotlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   3970\u001b[0m         \"\"\"\n\u001b[1;32m   3971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3974\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   2046\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m         \u001b[0mslice_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iloc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_slice_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# if we are accessing via lowered dim, use the last dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_convert_slice_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   1704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'iloc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m             return slice(self._validate_indexer('slice', key.start, kind),\n\u001b[0;32m-> 1706\u001b[0;31m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m                          self._validate_indexer('slice', key.step, kind))\n\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_indexer\u001b[0;34m(self, form, key, kind)\u001b[0m\n\u001b[1;32m   4143\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4144\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'iloc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'getitem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4145\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_invalid_indexer\u001b[0;34m(self, form, key)\u001b[0m\n\u001b[1;32m   1861\u001b[0m                         \"indexers [{key}] of {kind}\".format(\n\u001b[1;32m   1862\u001b[0m                             \u001b[0mform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                             kind=type(key)))\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot do slice indexing on <class 'pandas.core.indexes.numeric.Int64Index'> with these indexers [[[0. 0. 1. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 1.]]] of <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "df.head(onehotlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 5 ... 8 7 5]\n",
      "(1368, 40) (1368,)\n",
      "(153, 40) (153,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64 were all converted to float64 by the scale function.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#MultiOutput\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#y = lresult\n",
    "print(y)\n",
    "#Input dataset, y\n",
    "scaled_X = preprocessing.scale(dataset)\n",
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y.astype(int), test_size=0.1, shuffle=False)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "# Necessary imports: \n",
    "#from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "oModelList = [\n",
    "    MLPClassifier(hidden_layer_sizes=(300000), max_iter=1000, alpha=0.1,\n",
    "                           activation='relu', solver='lbfgs', early_stopping=True, verbose=False, shuffle=False, random_state=21,tol=0.000001),\n",
    "\n",
    "#     MLPRegressor(\n",
    "#         hidden_layer_sizes=(250,125,63,32,16,8,4),  activation='relu', solver='lbfgs', alpha=0.1, batch_size='auto',\n",
    "#         learning_rate='adaptive', learning_rate_init=0.1, power_t=0.5, max_iter=1000, shuffle=False,\n",
    "#         random_state=9, tol=0.000001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "#         early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    ]\n",
    "\n",
    "prediction_results = []\n",
    "i = 0\n",
    "for m in oModelList:\n",
    "    # m = MLPRegressor(\n",
    "    #     hidden_layer_sizes=(10,10),  activation='tanh', solver='lbfgs', alpha=0.001, batch_size='auto',\n",
    "    #     learning_rate='constant', learning_rate_init=0.1, power_t=0.5, max_iter=1000, shuffle=False,\n",
    "    #     random_state=9, tol=0.000001, verbose=10, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    #     early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    model = m.fit(X_train, y_train) #[list(item) for item in y_train])\n",
    "    ytrainPredicted = m.predict(X_train).astype(int)\n",
    "\n",
    "    iM = getAccuracy1dCount(y_train, ytrainPredicted)\n",
    "    print(iM)   \n",
    "    print(np.std(ytrainPredicted-y_train))\n",
    "    getStdDeviationOfPrediction(ytrainPredicted,y_train)\n",
    "\n",
    "    #ytestPredicted = m.predict(X_test)\n",
    "    ytestPredicted = m.predict(X_test).astype(int) #, [list(item) for item in y_train])\n",
    "\n",
    "    print(ytestPredicted)\n",
    "    print(y_test)\n",
    "    \n",
    "    ytestPredicted[ytestPredicted < 0] = 0\n",
    "    \n",
    "    iM = getAccuracy1dCount(y_test, ytestPredicted)\n",
    "    print(iM)   \n",
    "    print(np.std(ytestPredicted-y_test))\n",
    "    getStdDeviationOfPrediction(ytestPredicted,y_test)\n",
    "    \n",
    "#    training_score = (getAccuracyCount(ytrainPredicted, y_train))\n",
    "#    testing_score = (getAccuracyCount(ytestPredicted, y_test))\n",
    "#    total_score = (training_score + testing_score) #- ( training_score - testing_score )\n",
    "\n",
    "#    i = i + 1\n",
    "#    print ( i, \" Atleast 1 matched: \", total_score, ' Training: ', training_score, '(', len(ytrainPredicted), ') Test: ', testing_score, '(', len(ytestPredicted), ')')\n",
    "#    print(len(ytestPredicted),ytestPredicted)\n",
    "#    prediction_results.append(ytestPredicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
