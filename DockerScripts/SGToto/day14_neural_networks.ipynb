{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## Keras\n",
    "Keras Introduction: https://keras.io/\n",
    "\n",
    "Keras Cheatsheet: https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf\n",
    "\n",
    "Keras FAQ: https://keras.io/getting-started/faq/\n",
    "\n",
    "Keras Sequential API: https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about Tensorflow?\n",
    "\n",
    "Tensorflow is available as a \"backend\" for Keras. By default, Keras will use Tensorflow to perform deep learning operations.\n",
    "\n",
    "More about backends here: https://keras.io/backend/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Differences between Keras and Scikit-Learn\n",
    "\n",
    "|Sklearn|Keras|\n",
    "|--|--|\n",
    "|Use for Machine Learning and limited Deep Learning (MLPClassifier, MLPRegressor)|Use only for Deep Learning|\n",
    "|Scope: Linear Regression, Logistic Regression, Support Vector Machines, KMeans, PCA, etc|Scope: Deep Learning layers such as Dense, Convolutional, Recurrent|\n",
    "|Only SGDRegressor, SGDClassifier,  MLP* do gradient descent|Exclusively uses gradient descent and back propagation|\n",
    "|Not designed for long-haul training|Designed for long-haul training, supports saving and resuming training|\n",
    "|Limited support for incremental fit|Always fits incrementally, unless you recompile network|\n",
    "|Does not support GPU|Supports GPU|\n",
    "|Does not support Tensorflow|Supports Tensorflow through a backend|\n",
    "|Provides learning_curve() function for learning curve|Uses [Tensorboard](https://www.tensorflow.org/guide/summaries_and_tensorboard) for learning curve|\n",
    "|Provides cross_validate() function for cross validation|Cross-validation is not supported, use validation split that is built into fit()|\n",
    "|Supports fit with univariate y output only|Supports fit with univariate and multi-variate y output. For classification, y must be one-hot (more in the workshop)|\n",
    "\n",
    "There are other minor differences between how the two libraries work. We'll highlight it along the way.\n",
    "\n",
    "**Caution**: always consult documentation (don't assume Keras works like Scikit-learn, otherwise you waste time debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Machine Learning Workflow\n",
    "\n",
    "1. Problem Definition\n",
    "    - Same as you normally would for any machine learning problem. The key difference with Keras is in the choice of neural networks as the model.\n",
    "\n",
    "2. Data Engineering\n",
    "    - Use pandas as you normally would\n",
    "\n",
    "3. Feature Engineering\n",
    "    - Use sklearn as you normally would\n",
    "\n",
    "4. Model Engineering\n",
    "    \n",
    "    a. Define initial neural net\n",
    "        - Define model architecture, such as the input shapes, output shapes, and neural network layers\n",
    "        - model.compile to pick optimiser, loss function, metrics\n",
    "\n",
    "    b. Setup training callbacks:\n",
    "        - Learning curve using Tensorboard\n",
    "        - Early stopping\n",
    "        - [Optional] Model checkpoints to automatically save weights after every epoch\n",
    "    \n",
    "    c. Train model:\n",
    "        - model.fit(): Unlike sklearn, fit() is cumulative (continues progress if you it call repeatedly)\n",
    "\n",
    "        sklearn:\n",
    "        ```\n",
    "            model = SGDRegressor()\n",
    "            model.fit(X_train, y_train)\n",
    "            model.fit(X_train, y_train) # RESTARTS from scratch\n",
    "        ```\n",
    "\n",
    "         Keras:\n",
    "         ```\n",
    "             model.compile()\n",
    "             model.fit(X_train, y_train) \n",
    "             model.fit(X_train, y_train) # RESUMES training from previously\n",
    "         ```\n",
    "         \n",
    "5. Evaluation metrics\n",
    "    - Keras: model.evaluate() - similar to model.score() in sklearn\n",
    "    - Evaluation metrics in sklearn are more comprehensive. Use them here (e.g. classification_report)\n",
    "\n",
    "6. Deployment\n",
    "    - model.save()\n",
    "    - load_model()\n",
    "    - model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we'll walk through a simple Keras example to understand how to use it:\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Keras includes some built-in datasets that are useful for learning and practice.\n",
    "\n",
    "https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape # 60000 rows, 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c85283f2e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0]) # display first image (first row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras requires the targets to be categorical (one-hot)\n",
    "# vectors rather than class (label) vectors\n",
    "# This means that we need to convert the target\n",
    "# before passing it to fit() if doing multi-class classification\n",
    "\n",
    "# convert class vectors to categorical vectors\n",
    "# 5 to [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.to_categorical(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "This is an example dataset, so not much feature engineering is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model engineering\n",
    "\n",
    "To run tensorboard for viewing the Learning Curve\n",
    "\n",
    "- Launch another Anaconda Prompt (because tensorboard will run in its own console):\n",
    "\n",
    "```\n",
    "(base) conda activate mldds\n",
    "(mldds) cd folder\\to\\this\\notebook\n",
    "(mldds)tensorboard --logdir=logs --host=0.0.0.0\n",
    "```\n",
    "\n",
    "If this is the first time you are launching Tensorboard, you will not see any sessions until you call model.fit():\n",
    "\n",
    "```\n",
    "tensorboard = TensorBoard(log_dir='./logs/mnist_mlp/%d' % time.time())\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "                    callbacks=[tensorboard], validation_split=.25)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Flatten from 28x28 to 784 (because we are using MLP)\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "# Scale from 0-255 into 0-1\n",
    "# Scaling is generally recommended for neural networks\n",
    "# for faster convergence\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# input: 784, output: 512 => 784 x 512 weights + 512 bias\n",
    "# (512 neurons)\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# input: 512, output: 512 => 512 x 512 weights + 512 bias\n",
    "# (512 neurons)\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# input: 512, output: 10 => 512 x 10 weights\n",
    "# (10 neurons)\n",
    "# softmax converts a set of outputs to probabilities that add up to 1\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "# Param # is W + bias\n",
    "# Dense: input_shape x output_shape + output_shape\n",
    "#  (where input_shape = previous layer's output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.2156 - acc: 0.9333 - val_loss: 0.0955 - val_acc: 0.9688\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.0820 - acc: 0.9745 - val_loss: 0.0695 - val_acc: 0.9788\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.0526 - acc: 0.9839 - val_loss: 0.0769 - val_acc: 0.9782\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 0.0390 - acc: 0.9881 - val_loss: 0.0753 - val_acc: 0.9797\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.0290 - acc: 0.9907 - val_loss: 0.0873 - val_acc: 0.9792\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.0231 - acc: 0.9925 - val_loss: 0.0899 - val_acc: 0.9793\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0831 - val_acc: 0.9806\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.0173 - acc: 0.9949 - val_loss: 0.0823 - val_acc: 0.9842\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.1034 - val_acc: 0.9815\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1054 - val_acc: 0.9809\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.1350 - val_acc: 0.9784\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.1299 - val_acc: 0.9805\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.1164 - val_acc: 0.9822\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.1349 - val_acc: 0.9821\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.1221 - val_acc: 0.9835\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.0065 - acc: 0.9983 - val_loss: 0.1294 - val_acc: 0.9818\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1367 - val_acc: 0.9827\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.1410 - val_acc: 0.9827\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.1329 - val_acc: 0.9837\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.1344 - val_acc: 0.9831\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "import time\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs/mnist_mlp/%d' % time.time())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy']) # Tensorboard will display\n",
    "                                    # acc in addition to loss\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard],\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'dense_7', 'trainable': True, 'batch_input_shape': (None, 784), 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "[array([[ 0.02564431, -0.06388538,  0.02835713, ..., -0.00719504,\n",
      "         0.05518425, -0.01405415],\n",
      "       [-0.04950299, -0.00668305,  0.03048456, ..., -0.0527034 ,\n",
      "         0.00403973, -0.04335593],\n",
      "       [-0.02468992, -0.05374638, -0.06377932, ...,  0.03566092,\n",
      "         0.03457918, -0.04891454],\n",
      "       ...,\n",
      "       [ 0.04762988, -0.04055057, -0.05506435, ...,  0.0059512 ,\n",
      "         0.04801223, -0.04815359],\n",
      "       [-0.00781066,  0.05070905, -0.04100019, ..., -0.04242464,\n",
      "        -0.04651281,  0.0592605 ],\n",
      "       [ 0.04241592, -0.04015601,  0.00722501, ...,  0.032215  ,\n",
      "         0.06482086, -0.05962532]], dtype=float32), array([-0.007967  , -0.06462041, -0.04258786,  0.00178106, -0.02555114,\n",
      "       -0.09825879, -0.09373864, -0.02405463, -0.03367423, -0.07037202,\n",
      "       -0.06015784,  0.00395043, -0.08657689, -0.0440181 , -0.00633133,\n",
      "       -0.0826285 , -0.02702717, -0.01188636, -0.00512394, -0.0229769 ,\n",
      "        0.0266817 , -0.15567648,  0.08551915, -0.0422235 , -0.05009031,\n",
      "        0.05705982,  0.0228752 , -0.02300691, -0.08070733, -0.03156633,\n",
      "       -0.1709863 ,  0.00979893, -0.03332335,  0.03477797, -0.10186792,\n",
      "       -0.05558641, -0.07342727, -0.0124191 , -0.06433327, -0.08460155,\n",
      "        0.05031874, -0.08506633, -0.07494214, -0.09795613, -0.02700963,\n",
      "       -0.08765274, -0.06060889, -0.03108417, -0.0536936 , -0.06062597,\n",
      "       -0.08118989,  0.06316814, -0.07148024, -0.03152323, -0.04646318,\n",
      "       -0.05056209, -0.07841002, -0.04847453, -0.00998946,  0.00771284,\n",
      "        0.01162604,  0.02456218, -0.15352057, -0.08586564,  0.02607192,\n",
      "       -0.01925892, -0.05704372, -0.06959578, -0.09413463, -0.09244889,\n",
      "        0.06711917, -0.06532739, -0.09177005,  0.00881313, -0.10954838,\n",
      "        0.05361566, -0.00109287, -0.0319989 ,  0.07336093, -0.05132915,\n",
      "       -0.02942068, -0.11681152, -0.04208938, -0.04168511, -0.14941274,\n",
      "       -0.09135619, -0.0044896 ,  0.02657774, -0.04416838, -0.02052617,\n",
      "       -0.02916867,  0.02305843, -0.07515767, -0.05366985, -0.10021412,\n",
      "       -0.07776063, -0.10608397, -0.02230944, -0.02197062, -0.07975783,\n",
      "       -0.10022579, -0.13516293, -0.04630212, -0.11115599, -0.07116078,\n",
      "       -0.10073398, -0.039871  , -0.07401354, -0.10312877, -0.11881337,\n",
      "       -0.00165514, -0.01348905, -0.11115944, -0.05141847, -0.03367801,\n",
      "        0.01961517, -0.03068963, -0.05966665,  0.01949108, -0.02547884,\n",
      "       -0.1014393 , -0.05624742, -0.04671736, -0.03733971, -0.06568768,\n",
      "       -0.08069625,  0.01259363, -0.11624022, -0.03111118,  0.00870059,\n",
      "       -0.02557925, -0.11393911, -0.00695576, -0.0456123 , -0.05558484,\n",
      "       -0.07995114, -0.01991319, -0.07612323, -0.09145046, -0.04245955,\n",
      "       -0.0023617 , -0.00885784, -0.0132436 , -0.07847539, -0.07977329,\n",
      "        0.02418737,  0.01611468, -0.14432874, -0.03230767, -0.01293011,\n",
      "       -0.04522931, -0.08283991,  0.10238039,  0.00889985, -0.0636903 ,\n",
      "       -0.00768376,  0.03989531, -0.04219165, -0.01466435, -0.05308272,\n",
      "       -0.10378517, -0.07898772, -0.0349125 , -0.02052491, -0.0078613 ,\n",
      "        0.0095887 ,  0.01589413, -0.0686819 , -0.07129575,  0.02301927,\n",
      "       -0.19015028, -0.05437608, -0.03600096,  0.01242346, -0.11494843,\n",
      "       -0.01247605, -0.04743382, -0.00411187,  0.00894058, -0.09652428,\n",
      "       -0.05737529, -0.09753363, -0.04199805, -0.06888895, -0.18163686,\n",
      "       -0.00728223, -0.02043655, -0.07918611, -0.0974125 , -0.01374278,\n",
      "        0.01703405, -0.08386754, -0.08286516,  0.00369362,  0.0187609 ,\n",
      "       -0.0635312 , -0.03006776, -0.0444154 , -0.08066772, -0.11384013,\n",
      "       -0.01262497, -0.06016369,  0.09868554, -0.09472811, -0.03209181,\n",
      "        0.05845183, -0.07529575, -0.0235007 , -0.05680709, -0.07882725,\n",
      "       -0.03093613, -0.12917106, -0.08256701, -0.05797982, -0.01128995,\n",
      "        0.02276784, -0.02961755,  0.02389191, -0.03145697, -0.01877299,\n",
      "       -0.0498394 , -0.1599372 , -0.06374637, -0.06442986,  0.00632573,\n",
      "       -0.1074599 , -0.12844253, -0.07169179,  0.02446137, -0.11803777,\n",
      "       -0.08772723, -0.04542325, -0.00224873,  0.05985224, -0.04287764,\n",
      "       -0.10678444, -0.00738763, -0.0034822 , -0.081902  , -0.02655965,\n",
      "       -0.02085176, -0.01762696, -0.11664674, -0.05530217,  0.00048521,\n",
      "        0.02864053, -0.11153486, -0.08058809,  0.01939605,  0.04186447,\n",
      "       -0.11120538, -0.01389945, -0.02757193,  0.02617245, -0.06905138,\n",
      "        0.12996674, -0.06498587,  0.02441338,  0.00371286, -0.02405054,\n",
      "       -0.04375559, -0.04609172, -0.07699262, -0.08299497, -0.03261915,\n",
      "       -0.05006875, -0.03682111, -0.03612635, -0.09175929, -0.03880169,\n",
      "       -0.13154364, -0.01350937, -0.04917224, -0.03959674, -0.02385603,\n",
      "       -0.08465912, -0.04761222, -0.0794261 , -0.03523761,  0.03860326,\n",
      "       -0.05977541, -0.05549477,  0.04441186, -0.01298473, -0.12212697,\n",
      "       -0.07545535, -0.06925459, -0.10636369,  0.02164888, -0.02968734,\n",
      "        0.05400885, -0.10193768, -0.01998764, -0.05019382, -0.13319226,\n",
      "       -0.08885974, -0.04165957, -0.09277558, -0.0587671 , -0.08393021,\n",
      "       -0.05843596, -0.04017407, -0.0029934 , -0.10817896, -0.05158951,\n",
      "       -0.02909599, -0.01944507, -0.03016781,  0.01712695, -0.02744557,\n",
      "       -0.06682801, -0.09026664, -0.04273359, -0.01008643, -0.06193849,\n",
      "        0.02579568, -0.024975  , -0.10148767, -0.06369551,  0.0244593 ,\n",
      "       -0.01934177, -0.03670045, -0.08583638, -0.07060934, -0.01527148,\n",
      "       -0.11917398, -0.0839665 , -0.10055187,  0.00339066, -0.11713768,\n",
      "       -0.01195736, -0.04553106, -0.08631015, -0.10717357, -0.00920961,\n",
      "        0.02380321, -0.0103228 ,  0.05881094, -0.06522699,  0.01170509,\n",
      "       -0.09977876, -0.05328193, -0.07043891, -0.0868784 , -0.01037699,\n",
      "       -0.03303231, -0.0313376 , -0.00774001, -0.01785498, -0.08383916,\n",
      "        0.0129233 , -0.02092544, -0.06288844, -0.04922631, -0.04354639,\n",
      "       -0.0110991 , -0.02098228, -0.08618698, -0.08422385, -0.0025072 ,\n",
      "       -0.06480853, -0.12116476, -0.00742928, -0.02459329,  0.00535729,\n",
      "       -0.09433322, -0.07071235, -0.03941226, -0.09368262, -0.05556819,\n",
      "       -0.0565391 , -0.00428009, -0.10417299, -0.03899259,  0.02061389,\n",
      "       -0.04626654, -0.07147285, -0.01560977,  0.05215425,  0.00714525,\n",
      "       -0.04286532, -0.03028792, -0.05426921, -0.05472014, -0.02782745,\n",
      "        0.05649932, -0.04813702,  0.07343151, -0.02529815,  0.01275615,\n",
      "       -0.02392113, -0.08764249, -0.10353003,  0.02637107, -0.04838069,\n",
      "       -0.03086324, -0.1480136 , -0.03990545,  0.03947827, -0.03476324,\n",
      "       -0.05476028, -0.00519287, -0.11109173, -0.03258323, -0.11486474,\n",
      "       -0.08309153, -0.03054843, -0.02659199, -0.02649462, -0.0685331 ,\n",
      "       -0.07255149, -0.03385882,  0.03195072, -0.08283842,  0.01804909,\n",
      "        0.00479568, -0.07312154,  0.01503539, -0.05023493, -0.01260534,\n",
      "       -0.04354528, -0.03297213, -0.07915159, -0.10760944, -0.03543263,\n",
      "       -0.04655921, -0.11063867, -0.06818043, -0.07548191, -0.04926941,\n",
      "       -0.00310031, -0.06059642, -0.01340074, -0.11026441, -0.02468748,\n",
      "        0.02658931, -0.06854331, -0.10095595, -0.0185056 , -0.00103481,\n",
      "       -0.05443933, -0.07531529, -0.06318042, -0.01077873, -0.06928885,\n",
      "       -0.08755977, -0.07970241, -0.06583889, -0.09505901,  0.01765545,\n",
      "       -0.01015987,  0.08378103, -0.07017425, -0.06150259, -0.01275178,\n",
      "       -0.02258267, -0.05918045, -0.13077566, -0.0192653 , -0.01615288,\n",
      "        0.03535423, -0.09429142,  0.04377379, -0.04036725,  0.02842358,\n",
      "       -0.13472268, -0.11226198, -0.04349708, -0.02139168, -0.07002419,\n",
      "        0.04694039, -0.05228535, -0.01794175, -0.04131388, -0.13862301,\n",
      "       -0.07592679, -0.05388704, -0.08375534, -0.00434249, -0.01593942,\n",
      "       -0.00960137, -0.03446788, -0.01931873, -0.03161554, -0.10882667,\n",
      "       -0.05561213,  0.02665184, -0.08244054, -0.10158034, -0.04382579,\n",
      "       -0.01956105, -0.07291846,  0.02715067, -0.08114132, -0.03679878,\n",
      "       -0.0277109 , -0.08972275,  0.01062578, -0.01806261, -0.04017335,\n",
      "        0.0286657 , -0.01429807, -0.05220031, -0.11033907, -0.01544144,\n",
      "       -0.05276684, -0.01374038, -0.09314298, -0.04550608, -0.05343786,\n",
      "       -0.00095815, -0.04413058], dtype=float32)]\n",
      "{'name': 'dense_8', 'trainable': True, 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "[array([[-0.09037933,  0.04723812, -0.03792006, ...,  0.0124902 ,\n",
      "        -0.06182105, -0.02318341],\n",
      "       [-0.0491956 ,  0.00312872,  0.12994367, ..., -0.04821734,\n",
      "         0.15658619, -0.0161285 ],\n",
      "       [-0.18243675, -0.15187806,  0.01679836, ..., -0.06068414,\n",
      "        -0.05664734, -0.04410881],\n",
      "       ...,\n",
      "       [-0.01243892,  0.11789247,  0.02996535, ...,  0.05727449,\n",
      "        -0.06986126, -0.02087138],\n",
      "       [ 0.19517532, -0.06295659, -0.02005206, ...,  0.02791455,\n",
      "        -0.11748063, -0.1516524 ],\n",
      "       [-0.13128987,  0.03776658,  0.13978839, ...,  0.05192117,\n",
      "        -0.01347008, -0.08259983]], dtype=float32), array([-9.39826369e-02,  1.27316443e-02, -1.20741948e-01, -1.00291304e-01,\n",
      "       -4.49374728e-02,  5.98401278e-02, -1.51510984e-01, -1.26723439e-01,\n",
      "       -1.20546058e-01, -1.02837175e-01, -1.16305351e-01, -2.93140039e-02,\n",
      "       -1.11654095e-01, -1.07946105e-01, -8.86993706e-02, -1.21241264e-01,\n",
      "       -3.96758132e-02, -1.36313468e-01, -3.23927030e-02, -5.48599809e-02,\n",
      "       -1.27945632e-01, -1.32593066e-01, -1.42948881e-01, -7.91775621e-03,\n",
      "       -8.17191303e-02,  3.63865821e-03, -5.16131371e-02, -7.80635774e-02,\n",
      "       -2.44377702e-02, -9.85490382e-02, -6.34517819e-02, -5.74314892e-02,\n",
      "       -1.29317805e-01, -3.23910825e-02, -7.01931864e-02, -1.06947407e-01,\n",
      "       -7.33871236e-02, -5.26993163e-02, -3.38941813e-02,  1.39333764e-02,\n",
      "       -2.93241851e-02, -4.86815609e-02, -5.54006249e-02, -3.10066454e-02,\n",
      "       -1.84454452e-02, -1.54536039e-01, -7.65959844e-02, -3.32555398e-02,\n",
      "        1.06257573e-02, -1.16856605e-01, -5.27261347e-02, -3.90615724e-02,\n",
      "       -2.12188214e-02,  4.36979672e-03,  5.63107478e-03, -4.70610261e-02,\n",
      "       -6.67038783e-02, -8.92617926e-02, -1.54494032e-01, -8.96483883e-02,\n",
      "       -8.21300745e-02, -7.59385750e-02, -4.91230786e-02, -3.69463265e-02,\n",
      "       -7.71382153e-02, -8.38563293e-02, -7.43120387e-02, -1.76793113e-01,\n",
      "        3.04662567e-02, -5.87444119e-02, -7.20384866e-02, -2.70973947e-02,\n",
      "        1.62041299e-02, -6.59097359e-02, -8.32468420e-02, -9.72048417e-02,\n",
      "       -5.88605478e-02, -2.89601162e-02, -1.96450531e-01, -1.09041370e-01,\n",
      "       -9.33973119e-02,  6.75560907e-03, -2.00906657e-02, -2.45097540e-02,\n",
      "       -8.80398229e-02,  6.65604882e-03, -3.12192161e-02, -1.22776054e-01,\n",
      "       -1.11208633e-01, -5.13720699e-02, -1.58852641e-03, -2.04800460e-02,\n",
      "       -1.85220260e-02, -9.47499089e-03,  1.49098942e-02, -6.76590204e-02,\n",
      "       -2.04215162e-02, -2.32984871e-02, -1.04645059e-01, -1.02028832e-01,\n",
      "       -1.18256826e-02, -2.09650025e-02, -7.61246681e-02, -3.67800146e-02,\n",
      "        4.69106343e-03, -5.29836342e-02, -1.52502768e-02,  2.04252228e-02,\n",
      "       -5.90227246e-02, -6.02679551e-02, -3.98124196e-02, -1.51830269e-02,\n",
      "       -7.60996714e-02, -1.41324922e-01, -8.46810043e-02, -6.48879111e-02,\n",
      "       -8.19487721e-02, -4.26569134e-02, -5.32491617e-02, -5.90648986e-02,\n",
      "       -6.77420944e-02, -1.37066856e-01, -8.71521011e-02, -1.39722452e-01,\n",
      "        4.23718337e-03, -1.50621329e-02, -4.64030541e-02, -1.47355065e-01,\n",
      "       -9.68877673e-02, -8.71355906e-02, -9.58051234e-02, -8.15394148e-02,\n",
      "       -2.29452290e-02, -3.48252468e-02, -7.84809887e-02, -1.02785237e-01,\n",
      "       -4.33138907e-02, -3.29615548e-02, -6.87627541e-03, -9.75816920e-02,\n",
      "       -2.94756889e-02, -1.19593106e-02,  3.48156728e-02, -1.09393388e-01,\n",
      "       -4.40707467e-02, -6.36951849e-02, -1.34268463e-01, -1.20657697e-01,\n",
      "       -1.77300960e-01, -8.34631249e-02, -4.69366238e-02, -9.85875428e-02,\n",
      "        1.39478743e-02, -1.22539222e-01, -4.73630056e-02, -8.03090408e-02,\n",
      "       -2.10694522e-02, -4.92421016e-02, -9.82667878e-02, -1.80678278e-01,\n",
      "        8.11679102e-03, -1.53062165e-01, -2.43768618e-02, -2.34144442e-02,\n",
      "       -1.09520383e-01,  3.19363736e-02, -1.04314826e-01, -5.30660525e-02,\n",
      "       -8.52092132e-02, -9.62050557e-02,  9.76765435e-03, -1.07305208e-02,\n",
      "       -9.38119739e-02, -4.47989851e-02, -3.72014865e-02, -2.35269926e-02,\n",
      "       -8.10847208e-02, -6.03497922e-02, -9.31673869e-02, -8.99893120e-02,\n",
      "       -1.67252287e-01, -1.24860011e-01, -3.04565132e-02, -8.25722665e-02,\n",
      "       -1.36176124e-02, -1.19124733e-01, -3.34770530e-02, -1.30532295e-01,\n",
      "       -5.57346456e-02, -1.16488256e-01, -1.96708459e-02, -8.74195620e-02,\n",
      "       -6.02054931e-02, -9.19157267e-03, -9.08606201e-02, -3.48644331e-02,\n",
      "       -4.03446481e-02, -8.94877389e-02, -7.09625706e-02, -8.11131075e-02,\n",
      "       -8.29152837e-02, -7.60755464e-02, -6.02046028e-02,  2.18525622e-02,\n",
      "       -9.11202729e-02, -8.40372220e-02, -5.41971140e-02, -9.15678293e-02,\n",
      "        1.54950535e-02,  4.34998572e-02, -1.96294617e-02, -7.29873553e-02,\n",
      "       -2.74783988e-02, -1.71381757e-01, -1.69097744e-02, -1.29830986e-01,\n",
      "       -1.13426685e-01, -1.49410591e-02, -1.96283385e-01, -1.15422271e-01,\n",
      "        2.66937129e-02, -1.15104496e-01,  5.14245629e-02, -8.23154002e-02,\n",
      "        1.51652722e-02, -4.09138687e-02,  6.29884452e-02, -8.98347199e-02,\n",
      "       -1.00758277e-01, -9.56166387e-02, -9.92180482e-02, -1.35824144e-01,\n",
      "       -1.25297178e-02, -2.64167953e-02, -4.98605110e-02, -2.76613496e-02,\n",
      "        5.70611134e-02, -1.06200725e-01, -7.93921351e-02, -8.17823261e-02,\n",
      "       -5.51886559e-02,  1.99066512e-02, -1.80053022e-02, -1.48335099e-01,\n",
      "       -9.61824432e-02, -5.82206994e-02, -5.29908761e-02,  3.86631722e-03,\n",
      "       -1.37587428e-01, -3.61794755e-02, -1.33393360e-02, -1.01308562e-01,\n",
      "       -1.24363326e-01, -8.50299466e-03, -6.04832694e-02, -5.08353040e-02,\n",
      "       -6.66735470e-02, -1.44383863e-01, -4.45782021e-02, -6.51891306e-02,\n",
      "       -1.47863254e-01, -2.16541421e-02, -1.07551187e-01, -1.46077707e-01,\n",
      "       -2.44965144e-02, -7.60228410e-02, -1.91866141e-02, -1.54752389e-01,\n",
      "       -3.81335616e-02, -4.12801541e-02, -1.57549530e-01, -5.82718961e-02,\n",
      "       -5.99852949e-02, -1.69503235e-03, -1.14147350e-01, -1.39466166e-01,\n",
      "       -1.53279901e-01, -4.03726958e-02, -1.28973529e-01, -3.46501358e-02,\n",
      "       -9.87491384e-02, -7.60240927e-02,  1.25001604e-02, -3.89392376e-02,\n",
      "       -3.74451354e-02, -8.18949640e-02, -1.48260891e-01, -1.06369078e-01,\n",
      "        1.76503435e-02, -9.88204703e-02, -1.26276910e-01, -8.01043361e-02,\n",
      "       -7.13451207e-02, -1.02166176e-01, -5.00948690e-02, -3.04493215e-02,\n",
      "       -4.42154221e-02, -8.08208156e-03, -1.38022453e-01, -1.92578025e-02,\n",
      "       -5.92236295e-02, -9.16160867e-02, -4.17599678e-02, -8.53174105e-02,\n",
      "       -5.93969934e-02, -3.56918648e-02,  6.81094900e-02, -6.43084124e-02,\n",
      "       -4.85355817e-02,  7.64980018e-02, -1.16317004e-01, -4.98659201e-02,\n",
      "       -2.88749337e-02,  4.01903763e-02, -2.47309841e-02, -1.02575600e-01,\n",
      "       -3.67793478e-02, -9.84119847e-02, -9.87335965e-02, -1.32256728e-02,\n",
      "       -4.17654142e-02, -2.62922794e-02, -5.51677793e-02, -2.92500108e-02,\n",
      "       -8.94909445e-03,  2.94926763e-02, -1.02691747e-01,  3.75240929e-02,\n",
      "        1.34673109e-02,  1.30830351e-02, -9.32643712e-02, -1.11747406e-01,\n",
      "       -6.71827570e-02, -1.49679244e-01, -2.91121360e-02, -1.31431818e-01,\n",
      "       -3.48032787e-02, -1.00747190e-01, -8.21315497e-02, -6.00758307e-02,\n",
      "       -6.06672578e-02, -1.15882121e-01, -1.09372728e-01, -8.50568414e-02,\n",
      "       -5.02025224e-02, -8.46011788e-02, -8.29283968e-02, -7.84582645e-02,\n",
      "        4.35076989e-02, -5.08847982e-02, -6.72292784e-02, -5.16169108e-02,\n",
      "       -1.07821725e-01, -2.42872369e-02, -3.23826298e-02, -1.20216506e-02,\n",
      "       -7.43136406e-02, -8.40427652e-02, -7.84436390e-02, -3.04968469e-02,\n",
      "        1.90998148e-02, -5.47441691e-02, -4.37139310e-02, -7.70642757e-02,\n",
      "       -4.33305912e-02, -2.94354782e-02, -2.35812981e-02, -9.36518088e-02,\n",
      "        4.14051972e-02, -8.60399753e-02, -8.05276539e-03, -3.25946659e-02,\n",
      "       -4.87950854e-02, -1.03320509e-01, -4.69000787e-02, -5.17534018e-02,\n",
      "       -8.43448713e-02, -1.55873343e-01, -3.28909941e-02, -5.89728951e-02,\n",
      "        2.52786186e-03, -4.85696830e-02, -4.55468334e-02, -1.27871245e-01,\n",
      "        1.07106250e-02, -3.63594815e-02,  3.96297872e-03, -4.82893810e-02,\n",
      "       -8.28170553e-02, -6.08733762e-03, -7.38958940e-02, -4.84309904e-02,\n",
      "       -1.02863282e-01, -7.07045421e-02, -1.19918145e-01, -8.66759419e-02,\n",
      "       -1.17371224e-01, -6.88541383e-02, -7.21435845e-02, -8.86654779e-02,\n",
      "       -1.10824592e-01, -1.10456385e-01,  3.45212780e-02, -7.24722147e-02,\n",
      "        2.23457944e-02,  3.59772518e-02, -6.60680979e-02, -8.48939046e-02,\n",
      "       -1.13566555e-01, -1.61448872e-04, -6.58638701e-02, -8.13057795e-02,\n",
      "       -5.94581030e-02, -8.57727155e-02, -9.34792608e-02, -8.70892778e-02,\n",
      "        2.24522762e-02, -1.00169010e-01, -1.56519823e-02,  7.69538153e-03,\n",
      "       -6.29751831e-02, -8.61470103e-02, -1.63662329e-01, -4.89216186e-02,\n",
      "        1.25238374e-02, -1.29329979e-01, -1.46715969e-01, -8.54824856e-02,\n",
      "       -9.08166766e-02, -6.41133785e-02, -2.60461122e-03, -8.31809565e-02,\n",
      "       -6.56651929e-02, -4.57460061e-02, -7.08705261e-02, -7.88778290e-02,\n",
      "       -4.14118469e-02, -3.16144936e-02,  9.44464374e-03, -3.10149305e-02,\n",
      "       -1.74393713e-01, -7.92700574e-02, -8.29891041e-02,  1.19569777e-02,\n",
      "       -1.34820968e-01, -8.56406018e-02, -3.13562900e-02, -5.92608675e-02,\n",
      "       -6.14885539e-02, -1.44091532e-01, -4.04372104e-02, -9.31175575e-02,\n",
      "        6.82672532e-03, -3.34978774e-02, -8.33776668e-02, -1.02832168e-01,\n",
      "       -6.40551597e-02, -1.17376864e-01, -6.67064497e-03, -1.07813008e-01,\n",
      "       -6.89320415e-02, -8.37325901e-02, -6.22011609e-02, -7.61270225e-02,\n",
      "       -3.61203738e-02, -6.20675907e-02, -9.58391353e-02, -1.19397484e-01,\n",
      "       -6.87148795e-02, -3.38323079e-02, -4.58040163e-02, -1.19351320e-01,\n",
      "        6.02626801e-02, -1.74223274e-01, -1.73713788e-01, -5.57329059e-02,\n",
      "       -2.57482082e-02,  1.23916660e-02,  2.26246510e-02, -1.85503989e-01,\n",
      "        2.46148370e-02, -4.97371033e-02, -7.68861100e-02, -6.21647537e-02,\n",
      "       -6.10718653e-02, -9.20506492e-02, -4.53271717e-03, -9.75402296e-02,\n",
      "       -3.69631164e-02, -7.58508816e-02, -7.43128955e-02, -3.64849120e-02,\n",
      "        2.28458121e-02, -2.31915899e-02, -5.50647862e-02, -4.47098278e-02,\n",
      "       -6.95917085e-02, -1.08356498e-01, -6.89209253e-02, -4.57658768e-02,\n",
      "       -4.99855168e-02, -1.12441238e-02, -6.17005117e-02, -1.98392309e-02,\n",
      "       -7.29597509e-02, -1.00112997e-01, -1.21439863e-02, -4.64215167e-02,\n",
      "       -6.39561862e-02, -5.40861003e-02, -9.83794406e-03,  1.11004747e-02],\n",
      "      dtype=float32)]\n",
      "{'name': 'dense_9', 'trainable': True, 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "[array([[ 0.04478456, -0.20806563,  0.02704057, ..., -0.2653204 ,\n",
      "        -0.05012143, -0.35084838],\n",
      "       [-0.03920392, -0.40164205, -0.08033747, ..., -0.3290324 ,\n",
      "        -0.05035315, -0.16441262],\n",
      "       [-0.02635911,  0.08603948, -0.02731608, ..., -0.2542434 ,\n",
      "        -0.16672696, -0.30547667],\n",
      "       ...,\n",
      "       [-0.0140204 , -0.44476208, -0.1137692 , ..., -0.19156417,\n",
      "         0.06252151,  0.04081567],\n",
      "       [-0.10187536,  0.04065154,  0.00372371, ..., -0.17577167,\n",
      "         0.03941363, -0.14664668],\n",
      "       [-0.06120083, -0.013121  ,  0.02253372, ..., -0.10784965,\n",
      "         0.02562486,  0.00437737]], dtype=float32), array([-0.07522906, -0.09537528, -0.0714751 , -0.01582666, -0.04069076,\n",
      "       -0.04948924, -0.03698105, -0.078598  ,  0.0852282 ,  0.00574608],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.get_config())\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for display, un-flatten to 28x28\n",
    "plt.imshow(X_test[7].reshape(28, 28))\n",
    "\n",
    "# argmax converts one-hot to the value (which is the maximum index)\n",
    "# [0 .... 0 1] => 9 (9 is the 9th index in the one-hot array)\n",
    "print(y_test[7].argmax())\n",
    "\n",
    "# need the flattened (784) shape for predict because the model\n",
    "# expects it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before feeding into Keras, we need to reshape\n",
    "# input into (batch_index, 784)\n",
    "\n",
    "# Typical error when forgetting to reshape:\n",
    "#\n",
    "# ValueError: Error when checking input: expected dense_7_input \n",
    "# to have shape (784,) but got array with shape (1,)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape to (1, anything)\n",
    "pred = model.predict(X_test[7].reshape(1, -1)) # can also .reshape(1, 784)\n",
    "pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test[7].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test) # return labels so that\n",
    "                                       # sklearn metrics work\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truth needs to be converted from one-hot to labels again\n",
    "# so that sklearn metrics work\n",
    "y_test.argmax(axis=1) # column-wise, axis=1 (10 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.99      0.98      0.98      1032\n",
      "           3       0.98      0.99      0.98      1010\n",
      "           4       0.99      0.98      0.98       982\n",
      "           5       0.98      0.98      0.98       892\n",
      "           6       0.98      0.99      0.98       958\n",
      "           7       0.99      0.98      0.98      1028\n",
      "           8       0.97      0.98      0.98       974\n",
      "           9       0.98      0.98      0.98      1009\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
